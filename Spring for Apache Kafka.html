<!DOCTYPE html>
<!-- saved from url=(0070)https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!--[if IE]><meta http-equiv="X-UA-Compatible" content="IE=edge"><![endif]-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 1.5.8">
<meta name="author" content="Gary Russell, Artem Bilan, Biju Kunjummen, Jay Bryant">
<title>Spring for Apache Kafka</title>
<link rel="stylesheet" href="./Spring for Apache Kafka_files/spring.css">
<link rel="stylesheet" href="./Spring for Apache Kafka_files/font-awesome.min.css">
<style>#header #revnumber{display:none}</style>
</head>
<body id="spring-kafka-reference" class="book toc2 toc-left"><div><div id="header-spring">
<h1>
<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0" y="0" viewBox="0 0 245.8 45.3" style="enable-background:new 0 0 245.8 45.3;" xml:space="preserve">
<g id="logos">
<g>
<path class="st0" d="M39.4,3.7c-0.6,1.5-1.4,2.8-2.3,4c-3.9-4-9.3-6.4-15.2-6.4c-11.7,0-21.3,9.5-21.3,21.3
c0,6.2,2.6,11.7,6.8,15.6l0.8,0.7c3.7,3.1,8.5,5,13.7,5c11.2,0,20.4-8.7,21.2-19.8C43.7,18.7,42.1,11.8,39.4,3.7z M10.5,38.3
c-0.6,0.8-1.8,0.9-2.6,0.3C7.1,37.9,7,36.8,7.6,36c0.6-0.8,1.8-0.9,2.6-0.3C11,36.4,11.1,37.5,10.5,38.3z M39.3,31.9
c-5.2,7-16.5,4.6-23.6,5c0,0-1.3,0.1-2.6,0.3c0,0,0.5-0.2,1.1-0.4c5-1.7,7.4-2.1,10.5-3.7c5.8-3,11.5-9.4,12.7-16.1
c-2.2,6.4-8.9,12-14.9,14.2c-4.2,1.5-11.7,3-11.7,3c0,0-0.3-0.2-0.3-0.2c-5.1-2.5-5.3-13.6,4-17.1c4.1-1.6,8-0.7,12.4-1.8
C31.6,14.1,37,10.6,39.2,6C41.7,13.3,44.7,24.8,39.3,31.9z"></path>
<g>
<path class="st0" d="M55.2,30.9c-0.5-0.3-0.9-0.9-0.9-1.6c0-1.1,0.8-1.9,1.9-1.9c0.4,0,0.7,0.1,1,0.3c2,1.3,4.1,2,5.9,2
c2,0,3.2-0.9,3.2-2.2v-0.1c0-1.6-2.2-2.2-4.6-2.9c-3-0.9-6.5-2.1-6.5-6.1v-0.1c0-3.9,3.2-6.3,7.4-6.3c2.2,0,4.5,0.6,6.5,1.7
c0.7,0.4,1.1,1,1.1,1.8c0,1.1-0.9,1.9-2,1.9c-0.4,0-0.6-0.1-0.9-0.2c-1.7-0.9-3.4-1.4-4.9-1.4c-1.8,0-2.9,0.9-2.9,2v0.1
c0,1.5,2.2,2.2,4.7,2.9c3,0.9,6.4,2.3,6.4,6v0.1c0,4.3-3.4,6.5-7.7,6.5C60.4,33.3,57.6,32.5,55.2,30.9z"></path>
<path class="st0" d="M72.5,14.3c0-1.3,1-2.4,2.3-2.4c1.3,0,2.4,1.1,2.4,2.4v1.4c1.5-2.2,3.7-3.9,7-3.9c4.8,0,9.6,3.8,9.6,10.7
v0.1c0,6.8-4.7,10.7-9.6,10.7c-3.4,0-5.6-1.7-7-3.6V37c0,1.3-1.1,2.4-2.4,2.4c-1.3,0-2.3-1-2.3-2.4V14.3z M89.1,22.7L89.1,22.7
c0-4.1-2.7-6.7-5.9-6.7c-3.2,0-6,2.7-6,6.6v0.1c0,4,2.8,6.6,6,6.6C86.4,29.3,89.1,26.7,89.1,22.7z"></path>
<path class="st0" d="M95.7,14.3c0-1.3,1-2.4,2.3-2.4c1.3,0,2.4,1.1,2.4,2.4v1.1c0.2-1.8,3.1-3.5,5.2-3.5c1.5,0,2.3,1,2.3,2.3
c0,1.3-0.8,2.1-1.9,2.3c-3.4,0.6-5.7,3.5-5.7,7.6V31c0,1.3-1.1,2.3-2.4,2.3c-1.3,0-2.3-1-2.3-2.3V14.3z"></path>
<path class="st0" d="M109.7,14.3c0-1.3,1-2.4,2.3-2.4c1.3,0,2.4,1.1,2.4,2.4V31c0,1.3-1.1,2.3-2.4,2.3c-1.3,0-2.3-1-2.3-2.3V14.3
z"></path>
<path class="st0" d="M116.9,14.3c0-1.3,1-2.4,2.3-2.4c1.3,0,2.4,1.1,2.4,2.4v1c1.3-1.9,3.2-3.4,6.5-3.4c4.7,0,7.4,3.1,7.4,7.9V31
c0,1.3-1,2.3-2.3,2.3c-1.3,0-2.4-1-2.4-2.3v-9.7c0-3.2-1.6-5-4.4-5c-2.7,0-4.7,1.9-4.7,5.1V31c0,1.3-1.1,2.3-2.4,2.3
c-1.3,0-2.3-1-2.3-2.3V14.3z"></path>
<path class="st0" d="M156.2,11.9c-1.3,0-2.4,1.1-2.4,2.4v1.4c-1.5-2.2-3.7-3.9-7-3.9c-4.9,0-9.6,3.8-9.6,10.7v0.1
c0,6.8,4.7,10.7,9.6,10.7c3.4,0,5.6-1.7,7-3.6c-0.2,3.7-2.5,5.7-6.5,5.7c-2.4,0-4.5-0.6-6.3-1.6c-0.2-0.1-0.5-0.2-0.9-0.2
c-1.1,0-2,0.9-2,2c0,0.9,0.5,1.6,1.3,1.9c2.5,1.2,5.1,1.8,8,1.8c3.7,0,6.6-0.9,8.5-2.8c1.7-1.7,2.7-4.3,2.7-7.8V14.3
C158.5,13,157.5,11.9,156.2,11.9z M147.9,29.2c-3.2,0-5.9-2.5-5.9-6.6v-0.1c0-4,2.7-6.6,5.9-6.6c3.2,0,6,2.7,6,6.6v0.1
C153.9,26.6,151.1,29.2,147.9,29.2z"></path>
<path class="st0" d="M114.5,6.3c0,1.3-1.1,2.4-2.4,2.4c-1.3,0-2.4-1.1-2.4-2.4c0-1.3,1.1-2.4,2.4-2.4
C113.4,3.9,114.5,4.9,114.5,6.3z"></path>
</g>
</g>
<g class="st1">
<g>
<g>
<g>
<path class="st2" d="M200.1,21.1H198V19h2.1V21.1z M200.1,32.9H198V22.6h2.1V32.9z"></path>
</g>
<g>
<g>
<path class="st2" d="M212.5,22.6l-3,8.9c-0.5,1.5-1.4,1.6-2.2,1.6c-1.1,0-1.8-0.5-2.2-1.6l-2.5-7.4h-1v-1.5h2.6l2.6,8.3
c0.1,0.4,0.2,0.6,0.5,0.6c0.3,0,0.4-0.2,0.5-0.6l2.6-8.3H212.5z"></path>
<path class="st2" d="M217.8,22.6c2.8,0,4.7,1.8,4.7,4.5v1.6c0,2.6-1.9,4.5-4.7,4.5c-2.8,0-4.7-1.8-4.7-4.5v-1.6
C213,24.4,215,22.6,217.8,22.6 M217.8,31.4c1.7,0,2.7-1.3,2.7-2.8v-1.6c0-1.5-1-2.8-2.7-2.8c-1.8,0-2.7,1.3-2.7,2.8v1.6
C215.1,30.2,216,31.4,217.8,31.4"></path>
<path class="st2" d="M239.6,22.9c-1.1-0.3-2.7-0.5-4-0.5c-2.8,0-4.6,1.8-4.6,4.6v1.1c0,2.9,1.7,4.7,4.6,4.7c0.1,0,0.6,0,0.8,0
v-1.7c-0.1,0-0.7,0-0.8,0c-1.5,0-2.6-1.2-2.6-2.9v-1.1c0-1.8,1-2.9,2.6-2.9c0.7,0,1.7,0.1,2.1,0.1l0.1,0l0,8.6h2.1v-9.6
C240,23.1,240,23,239.6,22.9"></path>
<rect x="242.1" y="19" class="st2" width="2.1" height="13.9"></rect>
<path class="st2" d="M190.5,19h-3.8v13.9h2.2V20.9h1.3c0.3,0,0.5,0,0.8,0c1.9,0,2.9,0.8,2.9,2.3c0,0.1,0,0.1,0,0.2
c0,1.4-0.8,2.3-2.9,2.3c-0.2,0-0.4,0-0.6,0c0,0.5,0,1.5,0,1.9c0.2,0,0.4,0,0.6,0c3,0,5.2-1.2,5.2-4.2c0-0.1,0-0.1,0-0.2
C196.2,20.2,193.9,19,190.5,19"></path>
<path class="st2" d="M226.3,20.4v2.2h3.5v1.7h-3.5v6c0,0.9,0.6,1,1.5,1h2v1.7H227c-2,0-2.9-0.8-2.9-2.6v-9.6L226.3,20.4z"></path>
</g>
</g>
</g>
</g>
<g>
<path class="st2" d="M167.7,32.9v-10h1.1v3.8c0.6-0.8,1.5-1.3,2.4-1.3c1.9,0,3.2,1.5,3.2,3.8c0,2.4-1.3,3.8-3.2,3.8
c-1,0-1.9-0.5-2.4-1.3v1.1H167.7z M171,32.1c1.5,0,2.3-1.2,2.3-2.8c0-1.6-0.9-2.8-2.3-2.8c-0.9,0-1.8,0.5-2.2,1.2v3.3
C169.2,31.6,170.1,32.1,171,32.1z"></path>
<path class="st2" d="M175.9,34.7c0.2,0.1,0.4,0.1,0.6,0.1c0.5,0,0.8-0.2,1.1-0.8l0.5-1.1l-3-7.3h1.2l2.4,5.9l2.4-5.9h1.2
l-3.6,8.7c-0.4,1-1.2,1.5-2.1,1.5c-0.2,0-0.6,0-0.8-0.1L175.9,34.7z"></path>
</g>
</g>
</g>
</svg>

</h1>
</div></div>
<div id="header">
<h1>Spring for Apache Kafka</h1>
<div class="details">
<span id="author" class="author">Gary Russell</span><br>
<span id="author2" class="author">Artem Bilan</span><br>
<span id="author3" class="author">Biju Kunjummen</span><br>
<span id="author4" class="author">Jay Bryant</span><br>
<span id="revnumber">version 2.3.4.RELEASE</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="mobile-toc">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#preface">1. Preface</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#whats-new-part">2. What’s new?</a>
<ul class="sectlevel2">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-kafka-intro-new">2.1. What’s New in 2.3 Since 2.2</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-tricks-and-examples">2.1.1. Tips, Tricks and Examples</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-2.2">2.1.2. Kafka Client Version</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#classpackage-changes">2.1.3. Class/Package Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuration-changes">2.1.4. Configuration Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-and-consumer-factory-changes">2.1.5. Producer and Consumer Factory Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-container-changes">2.1.6. Listener Container Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#errorhandler-changes">2.1.7. ErrorHandler Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#topicbuilder">2.1.8. TopicBuilder</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-changes">2.1.9. Kafka Streams Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json-component-changes">2.1.10. JSON Component Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate">2.1.11. ReplyingKafkaTemplate</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregatingreplyingkafkatemplate">2.1.12. AggregatingReplyingKafkaTemplate</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-changes">2.1.13. Transaction Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-delegating-serializerdeserializer">2.1.14. New Delegating Serializer/Deserializer</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-retrying-deserializer">2.1.15. New Retrying Deserializer</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-function-for-recovering-from-deserializing-errors">2.1.16. New function for recovering from deserializing errors</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embeddedkafkabroker-changes">2.1.17. EmbeddedKafkaBroker Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate-changes">2.1.18. ReplyingKafkaTemplate Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapper-changes">2.1.19. Header Mapper Changes</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#introduction">3. Introduction</a>
<ul class="sectlevel2">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#quick-tour">3.1. Quick Tour for the Impatient</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#compatibility">3.1.1. Compatibility</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#a-very-very-quick-example">3.1.2. A Very, Very Quick Example</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#with-java-configuration">3.1.3. With Java Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#even-quicker-with-spring-boot">3.1.4. Even Quicker, with Spring Boot</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#reference">4. Reference</a>
<ul class="sectlevel2">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka">4.1. Using Spring for Apache Kafka</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics">4.1.1. Configuring Topics</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#sending-messages">4.1.2. Sending Messages</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template">Using <code>KafkaTemplate</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-factory">Using <code>DefaultKafkaProducerFactory</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template">Using <code>ReplyingKafkaTemplate</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregating-request-reply">Aggregating Multiple Replies</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#receiving-messages">4.1.3. Receiving Messages</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners">Message Listeners</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listener-container">Message Listener Containers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-annotation"><code>@KafkaListener</code> Annotation</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-group-id">Obtaining the Consumer <code>group.id</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-thread-naming">Container Thread Naming</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-meta"><code>@KafkaListener</code> as a Meta Annotation</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-level-kafkalistener"><code>@KafkaListener</code> on a Class</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-lifecycle"><code>@KafkaListener</code> Lifecycle Management</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-validation"><code>@KafkaListener</code> <code>@Payload</code> Validation</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#rebalance-listeners">Rebalancing Listeners</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-send-to">Forwarding Listener Results using <code>@SendTo</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#filtering-messages">Filtering Messages</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deliveries">Retrying Deliveries</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry">Stateful Retry</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#events">4.1.4. Application Events</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#idle-containers">Detecting Idle and Non-Responsive Consumers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#topicpartition-initial-offset">Topic/Partition Initial Offset</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek">Seeking to a Specific Offset</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory">Container factory</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#thread-safety">Thread Safety</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#micrometer">Monitoring Listener Performance</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions">4.1.5. Transactions</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-2">Overview</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-kafkatransactionmanager">Using <code>KafkaTransactionManager</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactional-listener-container-and-exactly-once-processing">Transactional Listener Container and Exactly Once Processing</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-synchronization">Transaction Synchronization</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chained-transaction-manager">Using <code>ChainedKafkaTransactionManager</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkatemplate-local-transactions"><code>KafkaTemplate</code> Local Transactions</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-id-prefix"><code>transactionIdPrefix</code></a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#interceptors">4.1.6. Wiring Spring Beans into Producer/Consumer Interceptors</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pause-resume">4.1.7. Pausing and Resuming Listener Containers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">4.1.8. Serialization, Deserialization, and Message Conversion</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-3">Overview</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json">JSON</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes-mapping-types">Mapping Types</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#delegating-serialization">Delegating Serializer and Deserializer</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deserialization">Retrying Deserializer</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#messaging-message-conversion">Spring Messaging Message Conversion</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handling-deserializer">Using <code>ErrorHandlingDeserializer</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#payload-conversion-with-batch">Payload Conversion with Batch Listeners</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#conversionservice-customization"><code>ConversionService</code> Customization</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#headers">4.1.9. Message Headers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tombstones">4.1.10. Null Payloads and Log Compaction of 'Tombstone' Records</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-error-handling">4.1.11. Handling Exceptions</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-error-handlers">Listener Error Handlers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handlers">Container Error Handlers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#consumer-aware-container-error-handlers">Consumer-Aware Container Error Handlers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-stopping-error-handlers">Container Stopping Error Handlers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback">After-rollback Processor</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters">Publishing Dead-letter Records</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos">4.1.12. Kerberos</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-kafka-streams">4.2. Kafka Streams Support</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#basics">4.2.1. Basics</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-management">4.2.2. Spring Management</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serde">4.2.3. Streams JSON Serialization and Deserialization</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-kafkastreamsbrancher">4.2.4. Using <code>KafkaStreamsBrancher</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-config">4.2.5. Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-header-enricher">4.2.6. Header Enricher</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-messaging">4.2.7. <code>MessagingTransformer</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-deser-recovery">4.2.8. Recovery from Deserialization Exceptions</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-example">4.2.9. Kafka Streams Example</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#testing">4.3. Testing Applications</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#junit">4.3.1. JUnit</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics-2">4.3.2. Configuring Topics</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-the-same-brokers-for-multiple-test-classes">4.3.3. Using the Same Brokers for Multiple Test Classes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-annotation">4.3.4. @EmbeddedKafka Annotation</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-junit5">4.3.5. @EmbeddedKafka Annotation with JUnit5</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-broker-in-springboottest-annotations">4.3.6. Embedded Broker in <code>@SpringBootTest</code> Annotations</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-junit4-class-rule">JUnit4 Class Rule</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-embeddedkafka-annotation"><code>@EmbeddedKafka</code> Annotation or <code>EmbeddedKafkaBroker</code> Bean</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#hamcrest-matchers">4.3.7. Hamcrest Matchers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#assertj-conditions">4.3.8. AssertJ Conditions</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#example">4.3.9. Example</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-n-tricks">5. Tips, Tricks and Examples</a>
<ul class="sectlevel2">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tip-assign-all-parts">5.1. Manually Assigning All Partitions</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#ex-jdbc-sync">5.2. Example of Transaction Synchronization</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-integration">6. Spring Integration</a>
<ul class="sectlevel2">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-kafka">6.1. Spring Integration for Apache Kafka</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-4">6.1.1. Overview</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-in-sik">6.1.2. What’s new in Spring Integration for Apache Kafka (version 3.2)</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound">6.1.3. Outbound Channel Adapter</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration">Java Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration">Java DSL Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration">XML Configuration</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound">6.1.4. Message-driven Channel Adapter</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-2">Java Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-2">Java DSL Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-2">XML Configuration</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-pollable">6.1.5. Inbound Channel Adapter</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-3">Java Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-3">Java DSL Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-3">XML Configuration</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound-gateway">6.1.6. Outbound Gateway</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-4">Java Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-4">Java DSL Configuration</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-4">XML Configuration</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-gateway">6.1.7. Inbound Gateway</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-5">XML Configuration</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-conversion">6.1.8. Message Conversion</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-tombstones">6.1.9. Null Payloads and Log Compaction 'Tombstone' Records</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-integration">6.1.10. Calling a Spring Integration flow from a <code>KStream</code></a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#whats-new-in-spring-integration-for-apache-kafka">6.1.11. What’s New in Spring Integration for Apache Kafka</a>
<ul class="sectlevel4">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-2-x">3.2.x</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-1-x">3.1.x</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-0-x">3.0.x</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-3-x">2.3.x</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-2-x">2.2.x</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-1-x">2.1.x</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-0-x">2.0.x</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#resources">7. Other Resources</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#history">Appendix A: Change History</a>
<ul class="sectlevel2">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#migration">A.1. Changes between 2.1 and 2.2</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-2.0">A.1.1. Kafka Client Version</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-and-package-changes">A.1.2. Class and Package Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback-processing">A.1.3. After Rollback Processing</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#concurrentkafkalistenercontainerfactory-changes">A.1.4. <code>ConcurrentKafkaListenerContainerFactory</code> Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-container-changes-2">A.1.5. Listener Container Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes">A.1.6. @KafkaListener Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapping-changes">A.1.7. Header Mapping Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-changes">A.1.8. Embedded Kafka Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#jsonserializerdeserializer-enhancements">A.1.9. JsonSerializer/Deserializer Enhancements</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-changes-2">A.1.10. Kafka Streams Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactional-id">A.1.11. Transactional ID</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-2-0-and-2-1">A.2. Changes between 2.0 and 2.1</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-1.0">A.2.1. Kafka Client Version</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json-improvements">A.2.2. JSON Improvements</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-stopping-error-handlers-2">A.2.3. Container Stopping Error Handlers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pausing-and-resuming-containers">A.2.4. Pausing and Resuming Containers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry-2">A.2.5. Stateful Retry</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#client-id">A.2.6. Client ID</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#logging-offset-commits">A.2.7. Logging Offset Commits</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#default-kafkahandler">A.2.8. Default @KafkaHandler</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate-2">A.2.9. ReplyingKafkaTemplate</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chainedkafkatransactionmanager">A.2.10. ChainedKafkaTransactionManager</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#migration-guide-from-2-0">A.2.11. Migration Guide from 2.0</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-3-and-2-0">A.3. Changes Between 1.3 and 2.0</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-framework-and-java-versions">A.3.1. Spring Framework and Java Versions</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes-2">A.3.2. <code>@KafkaListener</code> Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners-2">A.3.3. Message Listeners</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-consumerawarerebalancelistener">A.3.4. Using <code>ConsumerAwareRebalanceListener</code></a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-2-and-1-3">A.4. Changes Between 1.2 and 1.3</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-transactions">A.4.1. Support for Transactions</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-headers">A.4.2. Support for Headers</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#creating-topics">A.4.3. Creating Topics</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-kafka-timestamps">A.4.4. Support for Kafka Timestamps</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes-3">A.4.5. <code>@KafkaListener</code> Changes</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embeddedkafka-annotation">A.4.6. <code>@EmbeddedKafka</code> Annotation</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos-configuration">A.4.7. Kerberos Configuration</a></li>
</ul>
</li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-1-and-1-2">A.5. Changes between 1.1 and 1.2</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-0-and-1-1">A.6. Changes between 1.0 and 1.1</a>
<ul class="sectlevel3">
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client">A.6.1. Kafka Client</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#batch-listeners-2">A.6.2. Batch Listeners</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#null-payloads">A.6.3. Null Payloads</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#initial-offset">A.6.4. Initial Offset</a></li>
<li><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-2">A.6.5. Seek</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<div id="tocbot" class="js-toc desktop-toc"><ol class="toc-list "><li class="toc-list-item is-active-li"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#preface" class="toc-link node-name--H2  is-active-link">1. Preface</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#whats-new-part" class="toc-link node-name--H2 ">2. What’s new?</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-kafka-intro-new" class="toc-link node-name--H3 ">2.1. What’s New in 2.3 Since 2.2</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-tricks-and-examples" class="toc-link node-name--H4 ">2.1.1. Tips, Tricks and Examples</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-2.2" class="toc-link node-name--H4 ">2.1.2. Kafka Client Version</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#classpackage-changes" class="toc-link node-name--H4 ">2.1.3. Class/Package Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuration-changes" class="toc-link node-name--H4 ">2.1.4. Configuration Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-and-consumer-factory-changes" class="toc-link node-name--H4 ">2.1.5. Producer and Consumer Factory Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-container-changes" class="toc-link node-name--H4 ">2.1.6. Listener Container Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#errorhandler-changes" class="toc-link node-name--H4 ">2.1.7. ErrorHandler Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#topicbuilder" class="toc-link node-name--H4 ">2.1.8. TopicBuilder</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-changes" class="toc-link node-name--H4 ">2.1.9. Kafka Streams Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json-component-changes" class="toc-link node-name--H4 ">2.1.10. JSON Component Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate" class="toc-link node-name--H4 ">2.1.11. ReplyingKafkaTemplate</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregatingreplyingkafkatemplate" class="toc-link node-name--H4 ">2.1.12. AggregatingReplyingKafkaTemplate</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-changes" class="toc-link node-name--H4 ">2.1.13. Transaction Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-delegating-serializerdeserializer" class="toc-link node-name--H4 ">2.1.14. New Delegating Serializer/Deserializer</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-retrying-deserializer" class="toc-link node-name--H4 ">2.1.15. New Retrying Deserializer</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-function-for-recovering-from-deserializing-errors" class="toc-link node-name--H4 ">2.1.16. New function for recovering from deserializing errors</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embeddedkafkabroker-changes" class="toc-link node-name--H4 ">2.1.17. EmbeddedKafkaBroker Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate-changes" class="toc-link node-name--H4 ">2.1.18. ReplyingKafkaTemplate Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapper-changes" class="toc-link node-name--H4 ">2.1.19. Header Mapper Changes</a></li></ol></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#introduction" class="toc-link node-name--H2 ">3. Introduction</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#quick-tour" class="toc-link node-name--H3 ">3.1. Quick Tour for the Impatient</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#compatibility" class="toc-link node-name--H4 ">3.1.1. Compatibility</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#a-very-very-quick-example" class="toc-link node-name--H4 ">3.1.2. A Very, Very Quick Example</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#with-java-configuration" class="toc-link node-name--H4 ">3.1.3. With Java Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#even-quicker-with-spring-boot" class="toc-link node-name--H4 ">3.1.4. Even Quicker, with Spring Boot</a></li></ol></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#reference" class="toc-link node-name--H2 ">4. Reference</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka" class="toc-link node-name--H3 ">4.1. Using Spring for Apache Kafka</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics" class="toc-link node-name--H4 ">4.1.1. Configuring Topics</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#sending-messages" class="toc-link node-name--H4 ">4.1.2. Sending Messages</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template" class="toc-link node-name--H5 ">Using KafkaTemplate</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-factory" class="toc-link node-name--H5 ">Using DefaultKafkaProducerFactory</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template" class="toc-link node-name--H5 ">Using ReplyingKafkaTemplate</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregating-request-reply" class="toc-link node-name--H5 ">Aggregating Multiple Replies</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#receiving-messages" class="toc-link node-name--H4 ">4.1.3. Receiving Messages</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners" class="toc-link node-name--H5 ">Message Listeners</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listener-container" class="toc-link node-name--H5 ">Message Listener Containers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-annotation" class="toc-link node-name--H5 ">@KafkaListener Annotation</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-group-id" class="toc-link node-name--H5 ">Obtaining the Consumer group.id</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-thread-naming" class="toc-link node-name--H5 ">Container Thread Naming</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-meta" class="toc-link node-name--H5 ">@KafkaListener as a Meta Annotation</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-level-kafkalistener" class="toc-link node-name--H5 ">@KafkaListener on a Class</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-lifecycle" class="toc-link node-name--H5 ">@KafkaListener Lifecycle Management</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-validation" class="toc-link node-name--H5 ">@KafkaListener @Payload Validation</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#rebalance-listeners" class="toc-link node-name--H5 ">Rebalancing Listeners</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-send-to" class="toc-link node-name--H5 ">Forwarding Listener Results using @SendTo</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#filtering-messages" class="toc-link node-name--H5 ">Filtering Messages</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deliveries" class="toc-link node-name--H5 ">Retrying Deliveries</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry" class="toc-link node-name--H5 ">Stateful Retry</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#events" class="toc-link node-name--H4 ">4.1.4. Application Events</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#idle-containers" class="toc-link node-name--H5 ">Detecting Idle and Non-Responsive Consumers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#topicpartition-initial-offset" class="toc-link node-name--H5 ">Topic/Partition Initial Offset</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek" class="toc-link node-name--H5 ">Seeking to a Specific Offset</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory" class="toc-link node-name--H5 ">Container factory</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#thread-safety" class="toc-link node-name--H5 ">Thread Safety</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#micrometer" class="toc-link node-name--H5 ">Monitoring Listener Performance</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions" class="toc-link node-name--H4 ">4.1.5. Transactions</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-2" class="toc-link node-name--H5 ">Overview</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-kafkatransactionmanager" class="toc-link node-name--H5 ">Using KafkaTransactionManager</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactional-listener-container-and-exactly-once-processing" class="toc-link node-name--H5 ">Transactional Listener Container and Exactly Once Processing</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-synchronization" class="toc-link node-name--H5 ">Transaction Synchronization</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chained-transaction-manager" class="toc-link node-name--H5 ">Using ChainedKafkaTransactionManager</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkatemplate-local-transactions" class="toc-link node-name--H5 ">KafkaTemplate Local Transactions</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-id-prefix" class="toc-link node-name--H5 ">transactionIdPrefix</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#interceptors" class="toc-link node-name--H4 ">4.1.6. Wiring Spring Beans into Producer/Consumer Interceptors</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pause-resume" class="toc-link node-name--H4 ">4.1.7. Pausing and Resuming Listener Containers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes" class="toc-link node-name--H4 ">4.1.8. Serialization, Deserialization, and Message Conversion</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-3" class="toc-link node-name--H5 ">Overview</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json" class="toc-link node-name--H5 ">JSON</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes-mapping-types" class="toc-link node-name--H5 ">Mapping Types</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#delegating-serialization" class="toc-link node-name--H5 ">Delegating Serializer and Deserializer</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deserialization" class="toc-link node-name--H5 ">Retrying Deserializer</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#messaging-message-conversion" class="toc-link node-name--H5 ">Spring Messaging Message Conversion</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handling-deserializer" class="toc-link node-name--H5 ">Using ErrorHandlingDeserializer</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#payload-conversion-with-batch" class="toc-link node-name--H5 ">Payload Conversion with Batch Listeners</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#conversionservice-customization" class="toc-link node-name--H5 ">ConversionService Customization</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#headers" class="toc-link node-name--H4 ">4.1.9. Message Headers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tombstones" class="toc-link node-name--H4 ">4.1.10. Null Payloads and Log Compaction of 'Tombstone' Records</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-error-handling" class="toc-link node-name--H4 ">4.1.11. Handling Exceptions</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-error-handlers" class="toc-link node-name--H5 ">Listener Error Handlers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handlers" class="toc-link node-name--H5 ">Container Error Handlers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#consumer-aware-container-error-handlers" class="toc-link node-name--H5 ">Consumer-Aware Container Error Handlers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current" class="toc-link node-name--H5 ">Seek To Current Container Error Handlers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-stopping-error-handlers" class="toc-link node-name--H5 ">Container Stopping Error Handlers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback" class="toc-link node-name--H5 ">After-rollback Processor</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters" class="toc-link node-name--H5 ">Publishing Dead-letter Records</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos" class="toc-link node-name--H4 ">4.1.12. Kerberos</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-kafka-streams" class="toc-link node-name--H3 ">4.2. Kafka Streams Support</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#basics" class="toc-link node-name--H4 ">4.2.1. Basics</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-management" class="toc-link node-name--H4 ">4.2.2. Spring Management</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serde" class="toc-link node-name--H4 ">4.2.3. Streams JSON Serialization and Deserialization</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-kafkastreamsbrancher" class="toc-link node-name--H4 ">4.2.4. Using KafkaStreamsBrancher</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-config" class="toc-link node-name--H4 ">4.2.5. Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-header-enricher" class="toc-link node-name--H4 ">4.2.6. Header Enricher</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-messaging" class="toc-link node-name--H4 ">4.2.7. MessagingTransformer</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-deser-recovery" class="toc-link node-name--H4 ">4.2.8. Recovery from Deserialization Exceptions</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-example" class="toc-link node-name--H4 ">4.2.9. Kafka Streams Example</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#testing" class="toc-link node-name--H3 ">4.3. Testing Applications</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#junit" class="toc-link node-name--H4 ">4.3.1. JUnit</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics-2" class="toc-link node-name--H4 ">4.3.2. Configuring Topics</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-the-same-brokers-for-multiple-test-classes" class="toc-link node-name--H4 ">4.3.3. Using the Same Brokers for Multiple Test Classes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-annotation" class="toc-link node-name--H4 ">4.3.4. @EmbeddedKafka Annotation</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-junit5" class="toc-link node-name--H4 ">4.3.5. @EmbeddedKafka Annotation with JUnit5</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-broker-in-springboottest-annotations" class="toc-link node-name--H4 ">4.3.6. Embedded Broker in @SpringBootTest Annotations</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-junit4-class-rule" class="toc-link node-name--H5 ">JUnit4 Class Rule</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-embeddedkafka-annotation" class="toc-link node-name--H5 ">@EmbeddedKafka Annotation or EmbeddedKafkaBroker Bean</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#hamcrest-matchers" class="toc-link node-name--H4 ">4.3.7. Hamcrest Matchers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#assertj-conditions" class="toc-link node-name--H4 ">4.3.8. AssertJ Conditions</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#example" class="toc-link node-name--H4 ">4.3.9. Example</a></li></ol></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-n-tricks" class="toc-link node-name--H2 ">5. Tips, Tricks and Examples</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tip-assign-all-parts" class="toc-link node-name--H3 ">5.1. Manually Assigning All Partitions</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#ex-jdbc-sync" class="toc-link node-name--H3 ">5.2. Example of Transaction Synchronization</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-integration" class="toc-link node-name--H2 ">6. Spring Integration</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-kafka" class="toc-link node-name--H3 ">6.1. Spring Integration for Apache Kafka</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-4" class="toc-link node-name--H4 ">6.1.1. Overview</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-in-sik" class="toc-link node-name--H4 ">6.1.2. What’s new in Spring Integration for Apache Kafka (version 3.2)</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound" class="toc-link node-name--H4 ">6.1.3. Outbound Channel Adapter</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration" class="toc-link node-name--H5 ">Java Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration" class="toc-link node-name--H5 ">Java DSL Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration" class="toc-link node-name--H5 ">XML Configuration</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound" class="toc-link node-name--H4 ">6.1.4. Message-driven Channel Adapter</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-2" class="toc-link node-name--H5 ">Java Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-2" class="toc-link node-name--H5 ">Java DSL Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-2" class="toc-link node-name--H5 ">XML Configuration</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-pollable" class="toc-link node-name--H4 ">6.1.5. Inbound Channel Adapter</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-3" class="toc-link node-name--H5 ">Java Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-3" class="toc-link node-name--H5 ">Java DSL Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-3" class="toc-link node-name--H5 ">XML Configuration</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound-gateway" class="toc-link node-name--H4 ">6.1.6. Outbound Gateway</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-4" class="toc-link node-name--H5 ">Java Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-4" class="toc-link node-name--H5 ">Java DSL Configuration</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-4" class="toc-link node-name--H5 ">XML Configuration</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-gateway" class="toc-link node-name--H4 ">6.1.7. Inbound Gateway</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-5" class="toc-link node-name--H5 ">XML Configuration</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-conversion" class="toc-link node-name--H4 ">6.1.8. Message Conversion</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-tombstones" class="toc-link node-name--H4 ">6.1.9. Null Payloads and Log Compaction 'Tombstone' Records</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-integration" class="toc-link node-name--H4 ">6.1.10. Calling a Spring Integration flow from a KStream</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#whats-new-in-spring-integration-for-apache-kafka" class="toc-link node-name--H4 ">6.1.11. What’s New in Spring Integration for Apache Kafka</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-2-x" class="toc-link node-name--H5 ">3.2.x</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-1-x" class="toc-link node-name--H5 ">3.1.x</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-0-x" class="toc-link node-name--H5 ">3.0.x</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-3-x" class="toc-link node-name--H5 ">2.3.x</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-2-x" class="toc-link node-name--H5 ">2.2.x</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-1-x" class="toc-link node-name--H5 ">2.1.x</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-0-x" class="toc-link node-name--H5 ">2.0.x</a></li></ol></li></ol></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#resources" class="toc-link node-name--H2 ">7. Other Resources</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#history" class="toc-link node-name--H2 ">Appendix A: Change History</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#migration" class="toc-link node-name--H3 ">A.1. Changes between 2.1 and 2.2</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-2.0" class="toc-link node-name--H4 ">A.1.1. Kafka Client Version</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-and-package-changes" class="toc-link node-name--H4 ">A.1.2. Class and Package Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback-processing" class="toc-link node-name--H4 ">A.1.3. After Rollback Processing</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#concurrentkafkalistenercontainerfactory-changes" class="toc-link node-name--H4 ">A.1.4. ConcurrentKafkaListenerContainerFactory Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-container-changes-2" class="toc-link node-name--H4 ">A.1.5. Listener Container Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes" class="toc-link node-name--H4 ">A.1.6. @KafkaListener Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapping-changes" class="toc-link node-name--H4 ">A.1.7. Header Mapping Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-changes" class="toc-link node-name--H4 ">A.1.8. Embedded Kafka Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#jsonserializerdeserializer-enhancements" class="toc-link node-name--H4 ">A.1.9. JsonSerializer/Deserializer Enhancements</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-changes-2" class="toc-link node-name--H4 ">A.1.10. Kafka Streams Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactional-id" class="toc-link node-name--H4 ">A.1.11. Transactional ID</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-2-0-and-2-1" class="toc-link node-name--H3 ">A.2. Changes between 2.0 and 2.1</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-1.0" class="toc-link node-name--H4 ">A.2.1. Kafka Client Version</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json-improvements" class="toc-link node-name--H4 ">A.2.2. JSON Improvements</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-stopping-error-handlers-2" class="toc-link node-name--H4 ">A.2.3. Container Stopping Error Handlers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pausing-and-resuming-containers" class="toc-link node-name--H4 ">A.2.4. Pausing and Resuming Containers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry-2" class="toc-link node-name--H4 ">A.2.5. Stateful Retry</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#client-id" class="toc-link node-name--H4 ">A.2.6. Client ID</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#logging-offset-commits" class="toc-link node-name--H4 ">A.2.7. Logging Offset Commits</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#default-kafkahandler" class="toc-link node-name--H4 ">A.2.8. Default @KafkaHandler</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate-2" class="toc-link node-name--H4 ">A.2.9. ReplyingKafkaTemplate</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chainedkafkatransactionmanager" class="toc-link node-name--H4 ">A.2.10. ChainedKafkaTransactionManager</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#migration-guide-from-2-0" class="toc-link node-name--H4 ">A.2.11. Migration Guide from 2.0</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-3-and-2-0" class="toc-link node-name--H3 ">A.3. Changes Between 1.3 and 2.0</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-framework-and-java-versions" class="toc-link node-name--H4 ">A.3.1. Spring Framework and Java Versions</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes-2" class="toc-link node-name--H4 ">A.3.2. @KafkaListener Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners-2" class="toc-link node-name--H4 ">A.3.3. Message Listeners</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-consumerawarerebalancelistener" class="toc-link node-name--H4 ">A.3.4. Using ConsumerAwareRebalanceListener</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-2-and-1-3" class="toc-link node-name--H3 ">A.4. Changes Between 1.2 and 1.3</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-transactions" class="toc-link node-name--H4 ">A.4.1. Support for Transactions</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-headers" class="toc-link node-name--H4 ">A.4.2. Support for Headers</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#creating-topics" class="toc-link node-name--H4 ">A.4.3. Creating Topics</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-kafka-timestamps" class="toc-link node-name--H4 ">A.4.4. Support for Kafka Timestamps</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes-3" class="toc-link node-name--H4 ">A.4.5. @KafkaListener Changes</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embeddedkafka-annotation" class="toc-link node-name--H4 ">A.4.6. @EmbeddedKafka Annotation</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos-configuration" class="toc-link node-name--H4 ">A.4.7. Kerberos Configuration</a></li></ol></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-1-and-1-2" class="toc-link node-name--H3 ">A.5. Changes between 1.1 and 1.2</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-0-and-1-1" class="toc-link node-name--H3 ">A.6. Changes between 1.0 and 1.1</a><ol class="toc-list  is-collapsible is-collapsed"><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client" class="toc-link node-name--H4 ">A.6.1. Kafka Client</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#batch-listeners-2" class="toc-link node-name--H4 ">A.6.2. Batch Listeners</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#null-payloads" class="toc-link node-name--H4 ">A.6.3. Null Payloads</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#initial-offset" class="toc-link node-name--H4 ">A.6.4. Initial Offset</a></li><li class="toc-list-item"><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-2" class="toc-link node-name--H4 ">A.6.5. Seek</a></li></ol></li></ol></li></ol></div></div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><strong>2.3.4.RELEASE</strong></p>
</div>
<div class="paragraph">
<p>© 2016 - 2019 by Pivotal Software, Inc.</p>
</div>
<div class="paragraph">
<p>Copies of this document may be made for your own use and for distribution to others, provided that you do not charge any fee for such copies and further provided that each copy contains this Copyright Notice, whether distributed in print or electronically.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="preface"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#preface"></a>1. Preface</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The Spring for Apache Kafka project applies core Spring concepts to the development of Kafka-based messaging solutions.
We provide a “template” as a high-level abstraction for sending messages.
We also provide support for Message-driven POJOs.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="whats-new-part"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#whats-new-part"></a>2. What’s new?</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="spring-kafka-intro-new"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-kafka-intro-new"></a>2.1. What’s New in 2.3 Since 2.2</h3>
<div class="paragraph">
<p>This section covers the changes made from version 2.2 to version 2.3.</p>
</div>
<div class="paragraph">
<p>Also see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-in-sik">What’s new in Spring Integration for Apache Kafka (version 3.2)</a>.</p>
</div>
<div class="sect3">
<h4 id="tips-tricks-and-examples"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-tricks-and-examples"></a>2.1.1. Tips, Tricks and Examples</h4>
<div class="paragraph">
<p>A new chapter <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-n-tricks">Tips, Tricks and Examples</a> has been added.
Please submit GitHub issues and/or pull requests for additional entries in that chapter.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafka-client-2.2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-2.2"></a>2.1.2. Kafka Client Version</h4>
<div class="paragraph">
<p>This version requires the 2.3.0 <code>kafka-clients</code> or higher.</p>
</div>
</div>
<div class="sect3">
<h4 id="classpackage-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#classpackage-changes"></a>2.1.3. Class/Package Changes</h4>
<div class="paragraph">
<p><code>TopicPartitionInitialOffset</code> is deprecated in favor of <code>TopicPartitionOffset</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="configuration-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuration-changes"></a>2.1.4. Configuration Changes</h4>
<div class="paragraph">
<p>Starting with version 2.3.4, the <code>missingTopicsFatal</code> container property is false by default.
When this is true, the application fails to start if the broker is down; many users were affected by this change; given that Kafka is a high-availability platform, we did not anticipate that starting an application with no active brokers would be a common use case.</p>
</div>
</div>
<div class="sect3">
<h4 id="producer-and-consumer-factory-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-and-consumer-factory-changes"></a>2.1.5. Producer and Consumer Factory Changes</h4>
<div class="paragraph">
<p>The <code>DefaultKafkaProducerFactory</code> can now be configured to create a producer per thread.
You can also provide <code>Supplier&lt;Serializer&gt;</code> instances in the constructor as an alternative to either configured classes (which require no-arg constructors), or constructing with <code>Serializer</code> instances, which are then shared between all Producers.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-factory">Using <code>DefaultKafkaProducerFactory</code></a> for more information.</p>
</div>
<div class="paragraph">
<p>The same option is available with <code>Supplier&lt;Deserializer&gt;</code> instances in <code>DefaultKafkaConsumerFactory</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-container">Using <code>KafkaMessageListenerContainer</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="listener-container-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-container-changes"></a>2.1.6. Listener Container Changes</h4>
<div class="paragraph">
<p>Previously, error handlers received <code>ListenerExecutionFailedException</code> (with the actual listener exception as the <code>cause</code>) when the listener was invoked using a listener adapter (such as <code>@KafkaListener</code> s).
Exceptions thrown by native <code>GenericMessageListener</code> s were passed to the error handler unchanged.
Now a <code>ListenerExecutionFailedException</code> is always the argument (with the actual listener exception as the <code>cause</code>), which provides access to the container’s <code>group.id</code> property.</p>
</div>
<div class="paragraph">
<p>Because the listener container has it’s own mechanism for committing offsets, it prefers the Kafka <code>ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG</code> to be <code>false</code>.
It now sets it to false automatically unless specifically set in the consumer factory or the container’s consumer property overrides.</p>
</div>
<div class="paragraph">
<p>The <code>ackOnError</code> property is now <code>false</code> by default.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a> for more information.</p>
</div>
<div class="paragraph">
<p>It is now possible to obtain the consumer’s <code>group.id</code> property in the listener method.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-group-id">Obtaining the Consumer <code>group.id</code></a> for more information.</p>
</div>
<div class="paragraph">
<p>The container has a new property <code>recordInterceptor</code> allowing records to be inspected or modified before invoking the listener.
A <code>CompositeRecordInterceptor</code> is also provided in case you need to invoke multiple interceptors.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listener-container">Message Listener Containers</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>ConsumerSeekAware</code> has new methods allowing you to perform seeks relative to the beginning, end, or current position and to seek to the first offset greater than or equal to a time stamp.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek">Seeking to a Specific Offset</a> for more information.</p>
</div>
<div class="paragraph">
<p>A convenience class <code>AbstractConsumerSeekAware</code> is now provided to simplify seeking.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek">Seeking to a Specific Offset</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>ContainerProperties</code> provides an <code>idleBetweenPolls</code> option to let the main loop in the listener container to sleep between <code>KafkaConsumer.poll()</code> calls.
See its JavaDocs and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-container">Using <code>KafkaMessageListenerContainer</code></a> for more information.</p>
</div>
<div class="paragraph">
<p>When using <code>AckMode.MANUAL</code> (or <code>MANUAL_IMMEDIATE</code>) you can now cause a redelivery by calling <code>nack</code> on the <code>Acknowledgment</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">Committing Offsets</a> for more information.</p>
</div>
<div class="paragraph">
<p>Listener performance can now be monitored using Micrometer <code>Timer</code> s.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#micrometer">Monitoring Listener Performance</a> for more information.</p>
</div>
<div class="paragraph">
<p>The containers now publish additional consumer lifecyle events relating to startup.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#events">Application Events</a> for more information.</p>
</div>
<div class="paragraph">
<p>Transactional batch listeners can now support zombie fencing.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions">Transactions</a> for more information.</p>
</div>
<div class="paragraph">
<p>The listener container factory can now be configured with a <code>ContainerCustomizer</code> to further configure each container after it has been created and configured.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory">Container factory</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="errorhandler-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#errorhandler-changes"></a>2.1.7. ErrorHandler Changes</h4>
<div class="paragraph">
<p>The <code>SeekToCurrentErrorHandler</code> now treats certain exceptions as fatal and disables retry for those, invoking the recoverer on first failure.</p>
</div>
<div class="paragraph">
<p>The <code>SeekToCurrentErrorHandler</code> and <code>SeekToCurrentBatchErrorHandler</code> can now be configured to apply a <code>BackOff</code> (thread sleep) between delivery attempts.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3.2, recovered records' offsets will be committed when the error handler returns after recovering a failed record.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>DeadLetterPublishingRecoverer</code>, when used in conjunction with an <code>ErrorHandlingDeserializer2</code>, now sets the payload of the message sent to the dead-letter topic, to the original value that could not be deserialized.
Previously, it was <code>null</code> and user code needed to extract the <code>DeserializationException</code> from the message headers.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters">Publishing Dead-letter Records</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="topicbuilder"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#topicbuilder"></a>2.1.8. TopicBuilder</h4>
<div class="paragraph">
<p>A new class <code>TopicBuilder</code> is provided for more convenient creation of <code>NewTopic</code> <code>@Bean</code> s for automatic topic provisioning.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics">Configuring Topics</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafka-streams-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-changes"></a>2.1.9. Kafka Streams Changes</h4>
<div class="paragraph">
<p>You can now perform additional configuration of the <code>StreamsBuilderFactoryBean</code> created by <code>@EnableKafkaStreams</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-config">Streams Configuration</a> for more information.</p>
</div>
<div class="paragraph">
<p>A <code>RecoveringDeserializationExceptionHandler</code> is now provided which allows records with deserialization errors to be recovered.
It can be used in conjunction with a <code>DeadLetterPublishingRecoverer</code> to send these records to a dead-letter topic.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-deser-recovery">Recovery from Deserialization Exceptions</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>HeaderEnricher</code> transformer has been provided, using SpEL to generate the header values.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-header-enricher">Header Enricher</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>MessagingTransformer</code> has been provided.
This allows a Kafka streams topology to interact with a spring-messaging component, such as a Spring Integration flow.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-messaging"><code>MessagingTransformer</code></a> and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-integration">Calling a Spring Integration flow from a <code>KStream</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="json-component-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json-component-changes"></a>2.1.10. JSON Component Changes</h4>
<div class="paragraph">
<p>Now all the JSON-aware components are configured by default with a Jackson <code>ObjectMapper</code> produced by the <code>JacksonUtils.enhancedObjectMapper()</code>.
The <code>JsonDeserializer</code> now provides <code>TypeReference</code>-based constructors for better handling of target generic container types.
Also a <code>JacksonMimeTypeModule</code> has been introduced for serialization of <code>org.springframework.util.MimeType</code> to plain string.
See its JavaDocs and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a> for more information.</p>
</div>
<div class="paragraph">
<p>A <code>ByteArrayJsonMessageConverter</code> has been provided as well as a new super class for all Json converters, <code>JsonMessageConverter</code>.
Also, a <code>StringOrBytesSerializer</code> is now available; it can serialize <code>byte[]</code>, <code>Bytes</code> and <code>String</code> values in <code>ProducerRecord</code> s.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#messaging-message-conversion">Spring Messaging Message Conversion</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>JsonSerializer</code>, <code>JsonDeserializer</code> and <code>JsonSerde</code> now have fluent APIs to make programmatic configuration simpler.
See the javadocs, <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a>, and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serde">Streams JSON Serialization and Deserialization</a> for more informaion.</p>
</div>
</div>
<div class="sect3">
<h4 id="replyingkafkatemplate"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate"></a>2.1.11. ReplyingKafkaTemplate</h4>
<div class="paragraph">
<p>When a reply times out, the future is completed exceptionally with a <code>KafkaReplyTimeoutException</code> instead of a <code>KafkaException</code>.</p>
</div>
<div class="paragraph">
<p>Also, an overloaded <code>sendAndReceive</code> method is now provided that allows specifying the reply timeout on a per message basis.</p>
</div>
</div>
<div class="sect3">
<h4 id="aggregatingreplyingkafkatemplate"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregatingreplyingkafkatemplate"></a>2.1.12. AggregatingReplyingKafkaTemplate</h4>
<div class="paragraph">
<p>Extends the <code>ReplyingKafkaTemplate</code> by aggregating replies from multiple receivers.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregating-request-reply">Aggregating Multiple Replies</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="transaction-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-changes"></a>2.1.13. Transaction Changes</h4>
<div class="paragraph">
<p>You can now override the producer factory’s <code>transactionIdPrefix</code> on the <code>KafkaTemplate</code> and <code>KafkaTransactionManager</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-id-prefix"><code>transactionIdPrefix</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="new-delegating-serializerdeserializer"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-delegating-serializerdeserializer"></a>2.1.14. New Delegating Serializer/Deserializer</h4>
<div class="paragraph">
<p>The framework now provides a delegating <code>Serializer</code> and <code>Deserializer</code>, utilizing a header to enable producing and consuming records with multiple key/value types.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#delegating-serialization">Delegating Serializer and Deserializer</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="new-retrying-deserializer"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-retrying-deserializer"></a>2.1.15. New Retrying Deserializer</h4>
<div class="paragraph">
<p>The framework now provides a delegating <code>RetryingDeserializer</code>, to retry serialization when transient errors such as network problems might occur.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deserialization">Retrying Deserializer</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="new-function-for-recovering-from-deserializing-errors"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-function-for-recovering-from-deserializing-errors"></a>2.1.16. New function for recovering from deserializing errors</h4>
<div class="paragraph">
<p><code>ErrorHandlingDeserializer2</code> now uses a POJO (<code>FailedDeserializationInfo</code>) for passing all the contextual information around a deserialization error.
This enables the code to access to extra information that was missing in the old <code>BiFunction&lt;byte[], Headers, T&gt; failedDeserializationFunction</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="embeddedkafkabroker-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embeddedkafkabroker-changes"></a>2.1.17. EmbeddedKafkaBroker Changes</h4>
<div class="paragraph">
<p>You can now override the default broker list property name in the annotation.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-embeddedkafka-annotation"><code>@EmbeddedKafka</code> Annotation or <code>EmbeddedKafkaBroker</code> Bean</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="replyingkafkatemplate-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate-changes"></a>2.1.18. ReplyingKafkaTemplate Changes</h4>
<div class="paragraph">
<p>You can now customize the header names for correlation, reply topic and reply partition.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template">Using <code>ReplyingKafkaTemplate</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="header-mapper-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapper-changes"></a>2.1.19. Header Mapper Changes</h4>
<div class="paragraph">
<p>The <code>DefaultKafkaHeaderMapper</code> no longer encodes simple String-valued headers as JSON.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapping">[header-mapping]</a> for more information.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#introduction"></a>3. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This first part of the reference documentation is a high-level overview of Spring for Apache Kafka and the underlying concepts and some code snippets that can help you get up and running as quickly as possible.</p>
</div>
<div class="sect2">
<h3 id="quick-tour"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#quick-tour"></a>3.1. Quick Tour for the Impatient</h3>
<div class="paragraph">
<p>This is the five-minute tour to get started with Spring Kafka.</p>
</div>
<div class="paragraph">
<p>Prerequisites: You must install and run Apache Kafka.
Then you must grab the spring-kafka JAR and all of its dependencies.
The easiest way to do that is to declare a dependency in your build tool.
The following example shows how to do so with Maven:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.3.4.RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to do so with Gradle:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">compile <span class="hljs-string">'org.springframework.kafka:spring-kafka:2.3.4.RELEASE'</span></code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
When using Spring Boot, omit the version and Boot will automatically bring in the correct version that is compatible with your Boot version:
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.kafka<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-kafka<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to do so with Gradle:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-groovy hljs" data-lang="groovy">compile <span class="hljs-string">'org.springframework.kafka:spring-kafka'</span></code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="compatibility"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#compatibility"></a>3.1.1. Compatibility</h4>
<div class="paragraph">
<p>This quick tour works with the following versions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Apache Kafka Clients 2.2.0</p>
</li>
<li>
<p>Spring Framework 5.2.x</p>
</li>
<li>
<p>Minimum Java version: 8</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="a-very-very-quick-example"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#a-very-very-quick-example"></a>3.1.2. A Very, Very Quick Example</h4>
<div class="paragraph">
<p>As the following example shows, you can use plain Java to send and receive a message:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Test</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testAutoCommit</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>{
    logger.info(<span class="hljs-string">"Start auto"</span>);
    ContainerProperties containerProps = <span class="hljs-keyword">new</span> ContainerProperties(<span class="hljs-string">"topic1"</span>, <span class="hljs-string">"topic2"</span>);
    <span class="hljs-keyword">final</span> CountDownLatch latch = <span class="hljs-keyword">new</span> CountDownLatch(<span class="hljs-number">4</span>);
    containerProps.setMessageListener(<span class="hljs-keyword">new</span> MessageListener&lt;Integer, String&gt;() {

        <span class="hljs-meta">@Override</span>
        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(ConsumerRecord&lt;Integer, String&gt; message)</span> </span>{
            logger.info(<span class="hljs-string">"received: "</span> + message);
            latch.countDown();
        }

    });
    KafkaMessageListenerContainer&lt;Integer, String&gt; container = createContainer(containerProps);
    container.setBeanName(<span class="hljs-string">"testAuto"</span>);
    container.start();
    Thread.sleep(<span class="hljs-number">1000</span>); <span class="hljs-comment">// wait a bit for the container to start</span>
    KafkaTemplate&lt;Integer, String&gt; template = createTemplate();
    template.setDefaultTopic(topic1);
    template.sendDefault(<span class="hljs-number">0</span>, <span class="hljs-string">"foo"</span>);
    template.sendDefault(<span class="hljs-number">2</span>, <span class="hljs-string">"bar"</span>);
    template.sendDefault(<span class="hljs-number">0</span>, <span class="hljs-string">"baz"</span>);
    template.sendDefault(<span class="hljs-number">2</span>, <span class="hljs-string">"qux"</span>);
    template.flush();
    assertTrue(latch.await(<span class="hljs-number">60</span>, TimeUnit.SECONDS));
    container.stop();
    logger.info(<span class="hljs-string">"Stop auto"</span>);

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">private</span> KafkaMessageListenerContainer&lt;Integer, String&gt; <span class="hljs-title">createContainer</span><span class="hljs-params">(
                        ContainerProperties containerProps)</span> </span>{
    Map&lt;String, Object&gt; props = consumerProps();
    DefaultKafkaConsumerFactory&lt;Integer, String&gt; cf =
                            <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;Integer, String&gt;(props);
    KafkaMessageListenerContainer&lt;Integer, String&gt; container =
                            <span class="hljs-keyword">new</span> KafkaMessageListenerContainer&lt;&gt;(cf, containerProps);
    <span class="hljs-keyword">return</span> container;
}

<span class="hljs-function"><span class="hljs-keyword">private</span> KafkaTemplate&lt;Integer, String&gt; <span class="hljs-title">createTemplate</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; senderProps = senderProps();
    ProducerFactory&lt;Integer, String&gt; pf =
              <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;Integer, String&gt;(senderProps);
    KafkaTemplate&lt;Integer, String&gt; template = <span class="hljs-keyword">new</span> KafkaTemplate&lt;&gt;(pf);
    <span class="hljs-keyword">return</span> template;
}

<span class="hljs-function"><span class="hljs-keyword">private</span> Map&lt;String, Object&gt; <span class="hljs-title">consumerProps</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">"localhost:9092"</span>);
    props.put(ConsumerConfig.GROUP_ID_CONFIG, group);
    props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class="hljs-keyword">true</span>);
    props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, <span class="hljs-string">"100"</span>);
    props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, <span class="hljs-string">"15000"</span>);
    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class);
    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
    <span class="hljs-keyword">return</span> props;
}

<span class="hljs-function"><span class="hljs-keyword">private</span> Map&lt;String, Object&gt; <span class="hljs-title">senderProps</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">"localhost:9092"</span>);
    props.put(ProducerConfig.RETRIES_CONFIG, <span class="hljs-number">0</span>);
    props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="hljs-number">16384</span>);
    props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="hljs-number">1</span>);
    props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="hljs-number">33554432</span>);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    <span class="hljs-keyword">return</span> props;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="with-java-configuration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#with-java-configuration"></a>3.1.3. With Java Configuration</h4>
<div class="paragraph">
<p>You can do the same work as appears in the previous example with Spring configuration in Java.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Autowired</span>
<span class="hljs-keyword">private</span> Listener listener;

<span class="hljs-meta">@Autowired</span>
<span class="hljs-keyword">private</span> KafkaTemplate&lt;Integer, String&gt; template;

<span class="hljs-meta">@Test</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testSimple</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>{
    template.send(<span class="hljs-string">"annotated1"</span>, <span class="hljs-number">0</span>, <span class="hljs-string">"foo"</span>);
    template.flush();
    assertTrue(<span class="hljs-keyword">this</span>.listener.latch1.await(<span class="hljs-number">10</span>, TimeUnit.SECONDS));
}

<span class="hljs-meta">@Configuration</span>
<span class="hljs-meta">@EnableKafka</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Config</span> </span>{

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function">ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt;
                        <span class="hljs-title">kafkaListenerContainerFactory</span><span class="hljs-params">()</span> </span>{
        ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
                                <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
        factory.setConsumerFactory(consumerFactory());
        <span class="hljs-keyword">return</span> factory;
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerFactory&lt;Integer, String&gt; <span class="hljs-title">consumerFactory</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs());
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> Map&lt;String, Object&gt; <span class="hljs-title">consumerConfigs</span><span class="hljs-params">()</span> </span>{
        Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, embeddedKafka.getBrokersAsString());
        ...
        <span class="hljs-keyword">return</span> props;
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> Listener <span class="hljs-title">listener</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Listener();
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ProducerFactory&lt;Integer, String&gt; <span class="hljs-title">producerFactory</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> Map&lt;String, Object&gt; <span class="hljs-title">producerConfigs</span><span class="hljs-params">()</span> </span>{
        Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, embeddedKafka.getBrokersAsString());
        ...
        <span class="hljs-keyword">return</span> props;
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> KafkaTemplate&lt;Integer, String&gt; <span class="hljs-title">kafkaTemplate</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaTemplate&lt;Integer, String&gt;(producerFactory());
    }

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Listener</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> CountDownLatch latch1 = <span class="hljs-keyword">new</span> CountDownLatch(<span class="hljs-number">1</span>);

    <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"foo"</span>, topics = <span class="hljs-string">"annotated1"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen1</span><span class="hljs-params">(String foo)</span> </span>{
        <span class="hljs-keyword">this</span>.latch1.countDown();
    }

}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="even-quicker-with-spring-boot"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#even-quicker-with-spring-boot"></a>3.1.4. Even Quicker, with Spring Boot</h4>
<div class="paragraph">
<p>Spring Boot can make things even simpler.
The following Spring Boot application sends three messages to a topic, receives them, and stops:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Application</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">CommandLineRunner</span> </span>{

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Logger logger = LoggerFactory.getLogger(Application.class);

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(Application.class, args).close();
    }

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> KafkaTemplate&lt;String, String&gt; template;

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> CountDownLatch latch = <span class="hljs-keyword">new</span> CountDownLatch(<span class="hljs-number">3</span>);

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">run</span><span class="hljs-params">(String... args)</span> <span class="hljs-keyword">throws</span> Exception </span>{
        <span class="hljs-keyword">this</span>.template.send(<span class="hljs-string">"myTopic"</span>, <span class="hljs-string">"foo1"</span>);
        <span class="hljs-keyword">this</span>.template.send(<span class="hljs-string">"myTopic"</span>, <span class="hljs-string">"foo2"</span>);
        <span class="hljs-keyword">this</span>.template.send(<span class="hljs-string">"myTopic"</span>, <span class="hljs-string">"foo3"</span>);
        latch.await(<span class="hljs-number">60</span>, TimeUnit.SECONDS);
        logger.info(<span class="hljs-string">"All received"</span>);
    }

    <span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"myTopic"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(ConsumerRecord&lt;?, ?&gt; cr)</span> <span class="hljs-keyword">throws</span> Exception </span>{
        logger.info(cr.toString());
        latch.countDown();
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Boot takes care of most of the configuration.
When we use a local broker, the only properties we need are the following:</p>
</div>
<div class="exampleblock">
<div class="title">Example 1. application.properties</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="hljs gradle">spring.kafka.consumer.<span class="hljs-keyword">group</span>-id=foo
spring.kafka.consumer.auto-offset-reset=earliest</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>We need the first property because we are using group management to assign topic partitions to consumers, so we need a group.
The second property ensures the new consumer group gets the messages we sent, because the container might start after the sends have completed.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="reference"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#reference"></a>4. Reference</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This part of the reference documentation details the various components that comprise Spring for Apache Kafka.
The <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka">main chapter</a> covers the core classes to develop a Kafka application with Spring.</p>
</div>
<div class="sect2">
<h3 id="kafka"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka"></a>4.1. Using Spring for Apache Kafka</h3>
<div class="paragraph">
<p>This section offers detailed explanations of the various concerns that impact using Spring for Apache Kafka.
For a quick but less detailed introduction, see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#quick-tour">Quick Tour for the Impatient</a>.</p>
</div>
<div class="sect3">
<h4 id="configuring-topics"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics"></a>4.1.1. Configuring Topics</h4>
<div class="paragraph">
<p>If you define a <code>KafkaAdmin</code> bean in your application context, it can automatically add topics to the broker.
To do so, you can add a <code>NewTopic</code> <code>@Bean</code> for each topic to the application context.
Version 2.3 introduced a new class <code>TopicBuilder</code> to make creation of such beans more convenient.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaAdmin <span class="hljs-title">admin</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; configs = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, ...);
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaAdmin(configs);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic1</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"thing1"</span>)
            .partitions(<span class="hljs-number">10</span>)
            .replicas(<span class="hljs-number">3</span>)
            .compact()
            .build();
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic2</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"thing2"</span>)
            .partitions(<span class="hljs-number">10</span>)
            .replicas(<span class="hljs-number">3</span>)
            .config(TopicConfig.COMPRESSION_TYPE_CONFIG, <span class="hljs-string">"zstd"</span>)
            .build();
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic3</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"thing3"</span>)
            .assignReplicas(<span class="hljs-number">0</span>, Arrays.asList(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
            .assignReplicas(<span class="hljs-number">1</span>, Arrays.asList(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
            .assignReplicas(<span class="hljs-number">2</span>, Arrays.asList(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>))
            .config(TopicConfig.COMPRESSION_TYPE_CONFIG, <span class="hljs-string">"zstd"</span>)
            .build();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
When using Spring Boot, a <code>KafkaAdmin</code> bean is automatically registered so you only need the <code>NewTopic</code> <code>@Bean</code> s.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>By default, if the broker is not available, a message is logged, but the context continues to load.
You can programmatically invoke the admin’s <code>initialize()</code> method to try again later.
If you wish this condition to be considered fatal, set the admin’s <code>fatalIfBrokerNotAvailable</code> property to <code>true</code>.
The context then fails to initialize.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If the broker supports it (1.0.0 or higher), the admin increases the number of partitions if it is found that an existing topic has fewer partitions than the <code>NewTopic.numPartitions</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>For more advanced features, you can use the <code>AdminClient</code> directly.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Autowired</span>
<span class="hljs-keyword">private</span> KafkaAdmin admin;

...

    AdminClient client = AdminClient.create(admin.getConfig());
    ...
    client.close();</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="sending-messages"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#sending-messages"></a>4.1.2. Sending Messages</h4>
<div class="paragraph">
<p>This section covers how to send messages.</p>
</div>
<div class="sect4">
<h5 id="kafka-template"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template"></a>Using <code>KafkaTemplate</code></h5>
<div class="paragraph">
<p>This section covers how to use <code>KafkaTemplate</code> to send messages.</p>
</div>
<div class="sect5">
<h6 id="overview"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview"></a>Overview</h6>
<div class="paragraph">
<p>The <code>KafkaTemplate</code> wraps a producer and provides convenience methods to send data to Kafka topics.
The following listing shows the relevant methods from <code>KafkaTemplate</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; sendDefault(V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; sendDefault(K key, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; sendDefault(Integer partition, K key, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; sendDefault(Integer partition, Long timestamp, K key, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, K key, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, Integer partition, K key, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(String topic, Integer partition, Long timestamp, K key, V data);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(ProducerRecord&lt;K, V&gt; record);

ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; send(Message&lt;?&gt; message);

Map&lt;MetricName, ? extends Metric&gt; metrics();

<span class="hljs-function">List&lt;PartitionInfo&gt; <span class="hljs-title">partitionsFor</span><span class="hljs-params">(String topic)</span></span>;

&lt;T&gt; <span class="hljs-function">T <span class="hljs-title">execute</span><span class="hljs-params">(ProducerCallback&lt;K, V, T&gt; callback)</span></span>;

<span class="hljs-comment">// Flush the producer.</span>

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">flush</span><span class="hljs-params">()</span></span>;

<span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">ProducerCallback</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>, <span class="hljs-title">T</span>&gt; </span>{

    <span class="hljs-function">T <span class="hljs-title">doInKafka</span><span class="hljs-params">(Producer&lt;K, V&gt; producer)</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>See the <a href="https://docs.spring.io/spring-kafka/api/org/springframework/kafka/core/KafkaTemplate.html">Javadoc</a> for more detail.</p>
</div>
<div class="paragraph">
<p>The <code>sendDefault</code> API requires that a default topic has been provided to the template.</p>
</div>
<div class="paragraph">
<p>The API takes in a <code>timestamp</code> as a parameter and stores this timestamp in the record.
How the user-provided timestamp is stored depends on the timestamp type configured on the Kafka topic.
If the topic is configured to use <code>CREATE_TIME</code>, the user specified timestamp is recorded (or generated if not specified).
If the topic is configured to use <code>LOG_APPEND_TIME</code>, the user-specified timestamp is ignored and the broker adds in the local broker time.</p>
</div>
<div class="paragraph">
<p>The <code>metrics</code> and <code>partitionsFor</code> methods delegate to the same methods on the underlying <a href="https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/Producer.html"><code>Producer</code></a>.
The <code>execute</code> method provides direct access to the underlying <a href="https://kafka.apache.org/20/javadoc/org/apache/kafka/clients/producer/Producer.html"><code>Producer</code></a>.</p>
</div>
<div class="paragraph">
<p>To use the template, you can configure a producer factory and provide it in the template’s constructor.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ProducerFactory&lt;Integer, String&gt; <span class="hljs-title">producerFactory</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> Map&lt;String, Object&gt; <span class="hljs-title">producerConfigs</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-string">"localhost:9092"</span>);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    <span class="hljs-comment">// See https://kafka.apache.org/documentation/#producerconfigs for more properties</span>
    <span class="hljs-keyword">return</span> props;
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaTemplate&lt;Integer, String&gt; <span class="hljs-title">kafkaTemplate</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaTemplate&lt;Integer, String&gt;(producerFactory());
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You can also configure the template by using standard <code>&lt;bean/&gt;</code> definitions.</p>
</div>
<div class="paragraph">
<p>Then, to use the template, you can invoke one of its methods.</p>
</div>
<div class="paragraph">
<p>When you use the methods with a <code>Message&lt;?&gt;</code> parameter, the topic, partition, and key information is provided in a message header that includes the following items:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>KafkaHeaders.TOPIC</code></p>
</li>
<li>
<p><code>KafkaHeaders.PARTITION_ID</code></p>
</li>
<li>
<p><code>KafkaHeaders.MESSAGE_KEY</code></p>
</li>
<li>
<p><code>KafkaHeaders.TIMESTAMP</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The message payload is the data.</p>
</div>
<div class="paragraph">
<p>Optionally, you can configure the <code>KafkaTemplate</code> with a <code>ProducerListener</code> to get an asynchronous callback with the results of the send (success or failure) instead of waiting for the <code>Future</code> to complete.
The following listing shows the definition of the <code>ProducerListener</code> interface:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">ProducerListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onSuccess</span><span class="hljs-params">(String topic, Integer partition, K key, V value, RecordMetadata recordMetadata)</span></span>;

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onError</span><span class="hljs-params">(String topic, Integer partition, K key, V value, Exception exception)</span></span>;

    <span class="hljs-function"><span class="hljs-keyword">boolean</span> <span class="hljs-title">isInterestedInSuccess</span><span class="hljs-params">()</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>By default, the template is configured with a <code>LoggingProducerListener</code>, which logs errors and does nothing when the send is successful.</p>
</div>
<div class="paragraph">
<p><code>onSuccess</code> is called only if <code>isInterestedInSuccess</code> returns <code>true</code>.</p>
</div>
<div class="paragraph">
<p>For convenience, the abstract <code>ProducerListenerAdapter</code> is provided in case you want to implement only one of the methods.
It returns <code>false</code> for <code>isInterestedInSuccess</code>.</p>
</div>
<div class="paragraph">
<p>Notice that the send methods return a <code>ListenableFuture&lt;SendResult&gt;</code>.
You can register a callback with the listener to receive the result of the send asynchronously.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ListenableFuture&lt;SendResult&lt;Integer, String&gt;&gt; future = template.send(<span class="hljs-string">"something"</span>);
future.addCallback(<span class="hljs-keyword">new</span> ListenableFutureCallback&lt;SendResult&lt;Integer, String&gt;&gt;() {

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onSuccess</span><span class="hljs-params">(SendResult&lt;Integer, String&gt; result)</span> </span>{
        ...
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onFailure</span><span class="hljs-params">(Throwable ex)</span> </span>{
        ...
    }

});</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p><code>SendResult</code> has two properties, a <code>ProducerRecord</code> and <code>RecordMetadata</code>.
See the Kafka API documentation for information about those objects.</p>
</div>
<div class="paragraph">
<p>If you wish to block the sending thread to await the result, you can invoke the future’s <code>get()</code> method.
You may wish to invoke <code>flush()</code> before waiting or, for convenience, the template has a constructor with an <code>autoFlush</code> parameter that causes the template to <code>flush()</code> on each send.
Note, however, that flushing likely significantly reduces performance.</p>
</div>
</div>
<div class="sect5">
<h6 id="examples"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#examples"></a>Examples</h6>
<div class="paragraph">
<p>This section shows examples of sending messages to Kafka:</p>
</div>
<div class="exampleblock">
<div class="title">Example 2. Non Blocking (Async)</div>
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">sendToKafka</span><span class="hljs-params">(<span class="hljs-keyword">final</span> MyOutputData data)</span> </span>{
    <span class="hljs-keyword">final</span> ProducerRecord&lt;String, String&gt; record = createRecord(data);

    ListenableFuture&lt;SendResult&lt;Integer, String&gt;&gt; future = template.send(record);
    future.addCallback(<span class="hljs-keyword">new</span> ListenableFutureCallback&lt;SendResult&lt;Integer, String&gt;&gt;() {

        <span class="hljs-meta">@Override</span>
        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onSuccess</span><span class="hljs-params">(SendResult&lt;Integer, String&gt; result)</span> </span>{
            handleSuccess(data);
        }

        <span class="hljs-meta">@Override</span>
        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onFailure</span><span class="hljs-params">(Throwable ex)</span> </span>{
            handleFailure(data, record, ex);
        }

    });
}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Blocking (Sync)</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">sendToKafka</span><span class="hljs-params">(<span class="hljs-keyword">final</span> MyOutputData data)</span> </span>{
    <span class="hljs-keyword">final</span> ProducerRecord&lt;String, String&gt; record = createRecord(data);

    <span class="hljs-keyword">try</span> {
        template.send(record).get(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
        handleSuccess(data);
    }
    <span class="hljs-keyword">catch</span> (ExecutionException e) {
        handleFailure(data, record, e.getCause());
    }
    <span class="hljs-keyword">catch</span> (TimeoutException | InterruptedException e) {
        handleFailure(data, record, e);
    }
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="producer-factory"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#producer-factory"></a>Using <code>DefaultKafkaProducerFactory</code></h5>
<div class="paragraph">
<p>As seen in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template">Using <code>KafkaTemplate</code></a>, a <code>ProducerFactory</code> is used to create the producer.</p>
</div>
<div class="paragraph">
<p>When not using <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions">Transactions</a>, by default, the <code>DefaultKafkaProducerFactory</code> creates a singleton producer used by all clients, as recommended in the <code>KafkaProducer</code> javadocs.
However, if you call <code>flush()</code> on the template, this can cause delays for other threads using the same producer.
Starting with version 2.3, the <code>DefaultKafkaProducerFactory</code> has a new property <code>producerPerThread</code>.
When set to <code>true</code>, the factory will create (and cache) a separate producer for each thread, to avoid this issue.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
When <code>producerPerThread</code> is <code>true</code>, user code <strong>must</strong> call <code>closeThreadBoundProducer()</code> on the factory when the producer is no longer needed.
This will physically close the producer and remove it from the <code>ThreadLocal</code>.
Calling <code>reset()</code> or <code>destroy()</code> will not clean up these producers.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>When creating a <code>DefaultKafkaProducerFactory</code>, key and/or value <code>Serializer</code> classes can be picked up from configuration by calling the constructor that only takes in a Map of properties (see example in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template">Using <code>KafkaTemplate</code></a>), or <code>Serializer</code> instances may be passed to the <code>DefaultKafkaProducerFactory</code> constructor (in which case all <code>Producer</code> s share the same instances).
Alternatively you can provide <code>Supplier&lt;Serializer&gt;</code> s (starting with version 2.3) that will be used to obtain separate <code>Serializer</code> instances for each <code>Producer</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ProducerFactory&lt;Integer, CustomValue&gt; <span class="hljs-title">producerFactory</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(producerConfigs(), <span class="hljs-keyword">null</span>, () -&gt; <span class="hljs-keyword">new</span> CustomValueSerializer());
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaTemplate&lt;Integer, CustomValue&gt; <span class="hljs-title">kafkaTemplate</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaTemplate&lt;Integer, CustomValue&gt;(producerFactory());
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="replying-template"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template"></a>Using <code>ReplyingKafkaTemplate</code></h5>
<div class="paragraph">
<p>Version 2.1.3 introduced a subclass of <code>KafkaTemplate</code> to provide request/reply semantics.
The class is named <code>ReplyingKafkaTemplate</code> and has one method (in addition to those in the superclass).
The following listing shows the method signatures:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function">RequestReplyFuture&lt;K, V, R&gt; <span class="hljs-title">sendAndReceive</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record)</span></span>;

<span class="hljs-function">RequestReplyFuture&lt;K, V, R&gt; <span class="hljs-title">sendAndReceive</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record,
    Duration replyTimeout)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The result is a <code>ListenableFuture</code> that is asynchronously populated with the result (or an exception, for a timeout).
The result also has a <code>sendFuture</code> property, which is the result of calling <code>KafkaTemplate.send()</code>.
You can use this future to determine the result of the send operation.</p>
</div>
<div class="paragraph">
<p>If the first method is used, or the <code>replyTimeout</code> argument is <code>null</code>, the template’s <code>defaultReplyTimeout</code> property is used (5 seconds by default).</p>
</div>
<div class="paragraph">
<p>The following Spring Boot application shows an example of how to use the feature:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KRequestingApplication</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(KRequestingApplication.class, args).close();
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ApplicationRunner <span class="hljs-title">runner</span><span class="hljs-params">(ReplyingKafkaTemplate&lt;String, String, String&gt; template)</span> </span>{
        <span class="hljs-keyword">return</span> args -&gt; {
            ProducerRecord&lt;String, String&gt; record = <span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(<span class="hljs-string">"kRequests"</span>, <span class="hljs-string">"foo"</span>);
            RequestReplyFuture&lt;String, String, String&gt; replyFuture = template.sendAndReceive(record);
            SendResult&lt;String, String&gt; sendResult = replyFuture.getSendFuture().get(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
            System.out.println(<span class="hljs-string">"Sent ok: "</span> + sendResult.getRecordMetadata());
            ConsumerRecord&lt;String, String&gt; consumerRecord = replyFuture.get(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
            System.out.println(<span class="hljs-string">"Return value: "</span> + consumerRecord.value());
        };
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ReplyingKafkaTemplate&lt;String, String, String&gt; <span class="hljs-title">replyingTemplate</span><span class="hljs-params">(
            ProducerFactory&lt;String, String&gt; pf,
            ConcurrentMessageListenerContainer&lt;Long, String&gt; repliesContainer)</span> </span>{

        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ReplyingKafkaTemplate&lt;&gt;(pf, repliesContainer);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ConcurrentMessageListenerContainer&lt;String, String&gt; <span class="hljs-title">repliesContainer</span><span class="hljs-params">(
            ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; containerFactory)</span> </span>{

        ConcurrentMessageListenerContainer&lt;String, String&gt; repliesContainer =
                containerFactory.createContainer(<span class="hljs-string">"replies"</span>);
        repliesContainer.getContainerProperties().setGroupId(<span class="hljs-string">"repliesGroup"</span>);
        repliesContainer.setAutoStartup(<span class="hljs-keyword">false</span>);
        <span class="hljs-keyword">return</span> repliesContainer;
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">kRequests</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"kRequests"</span>)
            .partitions(<span class="hljs-number">10</span>)
            .replicas(<span class="hljs-number">2</span>)
            .build();
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">kReplies</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"kReplies"</span>)
            .partitions(<span class="hljs-number">10</span>)
            .replicas(<span class="hljs-number">2</span>)
            .build();
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that we can use Boot’s auto-configured container factory to create the reply container.</p>
</div>
<div class="paragraph">
<p>The template sets a header (named <code>KafkaHeaders.CORRELATION_ID</code> by default), which must be echoed back by the server side.</p>
</div>
<div class="paragraph">
<p>In this case, the following <code>@KafkaListener</code> application responds:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KReplyingApplication</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(KReplyingApplication.class, args);
    }

    <span class="hljs-meta">@KafkaListener</span>(id=<span class="hljs-string">"server"</span>, topics = <span class="hljs-string">"kRequests"</span>)
    <span class="hljs-meta">@SendTo</span> <span class="hljs-comment">// use default replyTo expression</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">listen</span><span class="hljs-params">(String in)</span> </span>{
        System.out.println(<span class="hljs-string">"Server received: "</span> + in);
        <span class="hljs-keyword">return</span> in.toUpperCase();
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">kRequests</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"kRequests"</span>)
            .partitions(<span class="hljs-number">10</span>)
            .replicas(<span class="hljs-number">2</span>)
            .build();
    }

    <span class="hljs-meta">@Bean</span> <span class="hljs-comment">// not required if Jackson is on the classpath</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> MessagingMessageConverter <span class="hljs-title">simpleMapperConverter</span><span class="hljs-params">()</span> </span>{
        MessagingMessageConverter messagingMessageConverter = <span class="hljs-keyword">new</span> MessagingMessageConverter();
        messagingMessageConverter.setHeaderMapper(<span class="hljs-keyword">new</span> SimpleKafkaHeaderMapper());
        <span class="hljs-keyword">return</span> messagingMessageConverter;
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>@KafkaListener</code> infrastructure echoes the correlation ID and determines the reply topic.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-send-to">Forwarding Listener Results using <code>@SendTo</code></a> for more information about sending replies.
The template uses the default header <code>KafKaHeaders.REPLY_TOPIC</code> to indicate the topic to which the reply goes.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2, the template tries to detect the reply topic or partition from the configured reply container.
If the container is configured to listen to a single topic or a single <code>TopicPartitionOffset</code>, it is used to set the reply headers.
If the container is configured otherwise, the user must set up the reply headers.
In this case, an <code>INFO</code> log message is written during initialization.
The following example uses <code>KafkaHeaders.REPLY_TOPIC</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">record.headers().add(<span class="hljs-keyword">new</span> RecordHeader(KafkaHeaders.REPLY_TOPIC, <span class="hljs-string">"kReplies"</span>.getBytes()));</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When you configure with a single reply <code>TopicPartitionOffset</code>, you can use the same reply topic for multiple templates, as long as each instance listens on a different partition.
When configuring with a single reply topic, each instance must use a different <code>group.id</code>.
In this case, all instances receive each reply, but only the instance that sent the request finds the correlation ID.
This may be useful for auto-scaling, but with the overhead of additional network traffic and the small cost of discarding each unwanted reply.
When you use this setting, we recommend that you set the template’s <code>sharedReplyTopic</code> to <code>true</code>, which reduces the logging level of unexpected replies to DEBUG instead of the default ERROR.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If you have multiple client instances and you do not configure them as discussed in the preceding paragraph, each instance needs a dedicated reply topic.
An alternative is to set the <code>KafkaHeaders.REPLY_PARTITION</code> and use a dedicated partition for each instance.
The <code>Header</code> contains a four-byte int (big-endian).
The server must use this header to route the reply to the correct topic (<code>@KafkaListener</code> does this).
In this case, though, the reply container must not use Kafka’s group management feature and must be configured to listen on a fixed partition (by using a <code>TopicPartitionOffset</code> in its <code>ContainerProperties</code> constructor).
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>DefaultKafkaHeaderMapper</code> requires Jackson to be on the classpath (for the <code>@KafkaListener</code>).
If it is not available, the message converter has no header mapper, so you must configure a <code>MessagingMessageConverter</code> with a <code>SimpleKafkaHeaderMapper</code>, as shown earlier.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>By default, 3 headers are used:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>KafkaHeaders.CORRELATION_ID</code> - used to correlate the reply to a request</p>
</li>
<li>
<p><code>KafkaHeaders.REPLY_TOPIC</code> - used to tell the server where to reply</p>
</li>
<li>
<p><code>KafkaHeaders.REPLY_PARTITION</code> - (optional) used to tell the server which partition to reply to</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These header names are used by the <code>@KafkaListener</code> infrastructure to route the reply.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, you can customize the header names - the template has 3 properties <code>correlationHeaderName</code>, <code>replyTopicHeaderName</code>, and <code>replyPartitionHeaderName</code>.
This is useful if your server is not a Spring application (or does not use the <code>@KafkaListener</code>).</p>
</div>
</div>
<div class="sect4">
<h5 id="aggregating-request-reply"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#aggregating-request-reply"></a>Aggregating Multiple Replies</h5>
<div class="paragraph">
<p>The template in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template">Using <code>ReplyingKafkaTemplate</code></a> is strictly for a single request/reply scenario.
For cases where multiple receivers of a single message return a reply, you can use the <code>AggregatingReplyingKafkaTemplate</code>.
This is an implementation of the client-side of the <a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/BroadcastAggregate.html">Scatter-Gather Enterprise Integration Pattern</a>.</p>
</div>
<div class="paragraph">
<p>Like the <code>ReplyingKafkaTemplate</code>, the <code>AggregatingReplyingKafkaTemplate</code> constructor takes a producer factory and a listener container to receive the replies; it has a third parameter <code>Predicate&lt;Collection&lt;ConsumerRecord&lt;K, R&gt;&gt;&gt; releaseStrategy</code> which is consulted each time a reply is received; when the predicate returns <code>true</code>, the collection of <code>ConsumerRecord</code> s is used to complete the <code>Future</code> returned by the <code>sendAndReceive</code> method.</p>
</div>
<div class="paragraph">
<p>There is an additional property <code>returnPartialOnTimeout</code> (default false).
When this is set to <code>true</code>, instead of completing the future with a <code>KafkaReplyTimeoutException</code>, a partial result completes the future normally (as long as at least one reply record has been received).</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">AggregatingReplyingKafkaTemplate&lt;Integer, String, String&gt; template =
        <span class="hljs-keyword">new</span> AggregatingReplyingKafkaTemplate&lt;&gt;(producerFactory, container,
                        coll -&gt; coll.size() == releaseSize);
...
RequestReplyFuture&lt;Integer, String, Collection&lt;ConsumerRecord&lt;Integer, String&gt;&gt;&gt; future =
        template.sendAndReceive(record);
future.getSendFuture().get(<span class="hljs-number">10</span>, TimeUnit.SECONDS); <span class="hljs-comment">// send ok</span>
ConsumerRecord&lt;Integer, Collection&lt;ConsumerRecord&lt;Integer, String&gt;&gt;&gt; consumerRecord =
        future.get(<span class="hljs-number">30</span>, TimeUnit.SECONDS);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Notice that the return type is a <code>ConsumerRecord</code> with a value that is a collection of <code>ConsumerRecord</code> s.
The "outer" <code>ConsumerRecord</code> is not a "real" record, it is synthesized by the template, as a holder for the actual reply records received for the request.
When a normal release occurs (release strategy returns true), the topic is set to <code>aggregatedResults</code>; if <code>returnPartialOnTimeout</code> is true, and timeout occurs (and at least one reply record has been received), the topic is set to <code>partialResultsAfterTimeout</code>.
The template provides constant static variables for these "topic" names:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">/**
 * Pseudo topic name for the "outer" {<span class="hljs-doctag">@link</span> ConsumerRecords} that has the aggregated
 * results in its value after a normal release by the release strategy.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String AGGREGATED_RESULTS_TOPIC = <span class="hljs-string">"aggregatedResults"</span>;

<span class="hljs-comment">/**
 * Pseudo topic name for the "outer" {<span class="hljs-doctag">@link</span> ConsumerRecords} that has the aggregated
 * results in its value after a timeout.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String PARTIAL_RESULTS_AFTER_TIMEOUT_TOPIC = <span class="hljs-string">"partialResultsAfterTimeout"</span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The real <code>ConsumerRecord</code> s in the <code>Collection</code> contain the actual topic(s) from which the replies are received.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The listener container for the replies MUST be configured with <code>AckMode.MANUAL</code> or <code>AckMode.MANUAL_IMMEDIATE</code>; the consumer property <code>enable.auto.commit</code> must be <code>false</code> (the default since version 2.3).
To avoid any possibility of losing messages, the template only commits offsets when there are zero requests outstanding, i.e. when the last outstanding request is released by the release strategy.
After a rebalance, it is possible for duplicate reply deliveries; these will be ignored for any in-flight requests; you may see error log messages when duplicate replies are received for already released replies.
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="receiving-messages"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#receiving-messages"></a>4.1.3. Receiving Messages</h4>
<div class="paragraph">
<p>You can receive messages by configuring a <code>MessageListenerContainer</code> and providing a message listener or by using the <code>@KafkaListener</code> annotation.</p>
</div>
<div class="sect4">
<h5 id="message-listeners"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners"></a>Message Listeners</h5>
<div class="paragraph">
<p>When you use a <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listener-container">message listener container</a>, you must provide a listener to receive data.
There are currently eight supported interfaces for message listeners.
The following listing shows these interfaces:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">MessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="1"></i><b>(<span class="hljs-number">1</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(ConsumerRecord&lt;K, V&gt; data)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">AcknowledgingMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="2"></i><b>(<span class="hljs-number">2</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(ConsumerRecord&lt;K, V&gt; data, Acknowledgment acknowledgment)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">ConsumerAwareMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">MessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="3"></i><b>(<span class="hljs-number">3</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(ConsumerRecord&lt;K, V&gt; data, Consumer&lt;?, ?&gt; consumer)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">AcknowledgingConsumerAwareMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">MessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="4"></i><b>(<span class="hljs-number">4</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(ConsumerRecord&lt;K, V&gt; data, Acknowledgment acknowledgment, Consumer&lt;?, ?&gt; consumer)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">BatchMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="5"></i><b>(<span class="hljs-number">5</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(List&lt;ConsumerRecord&lt;K, V&gt;&gt; data)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">BatchAcknowledgingMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="6"></i><b>(<span class="hljs-number">6</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(List&lt;ConsumerRecord&lt;K, V&gt;&gt; data, Acknowledgment acknowledgment)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">BatchConsumerAwareMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">BatchMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="7"></i><b>(<span class="hljs-number">7</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(List&lt;ConsumerRecord&lt;K, V&gt;&gt; data, Consumer&lt;?, ?&gt; consumer)</span></span>;

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">BatchAcknowledgingConsumerAwareMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; <span class="hljs-keyword">extends</span> <span class="hljs-title">BatchMessageListener</span>&lt;<span class="hljs-title">K</span>, <span class="hljs-title">V</span>&gt; </span>{ <i class="conum" data-value="8"></i><b>(<span class="hljs-number">8</span>)</b>

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(List&lt;ConsumerRecord&lt;K, V&gt;&gt; data, Acknowledgment acknowledgment, Consumer&lt;?, ?&gt; consumer)</span></span>;

}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tbody><tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Use this interface for processing individual <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using auto-commit or one of the container-managed <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Use this interface for processing individual <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using one of the manual <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Use this interface for processing individual <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using auto-commit or one of the container-managed <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.
Access to the <code>Consumer</code> object is provided.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Use this interface for processing individual <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using one of the manual <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.
Access to the <code>Consumer</code> object is provided.</td>
</tr>
<tr>
<td><i class="conum" data-value="5"></i><b>5</b></td>
<td>Use this interface for processing all <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using auto-commit or one of the container-managed <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.
<code>AckMode.RECORD</code> is not supported when you use this interface, since the listener is given the complete batch.</td>
</tr>
<tr>
<td><i class="conum" data-value="6"></i><b>6</b></td>
<td>Use this interface for processing all <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using one of the manual <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.</td>
</tr>
<tr>
<td><i class="conum" data-value="7"></i><b>7</b></td>
<td>Use this interface for processing all <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using auto-commit or one of the container-managed <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.
<code>AckMode.RECORD</code> is not supported when you use this interface, since the listener is given the complete batch.
Access to the <code>Consumer</code> object is provided.</td>
</tr>
<tr>
<td><i class="conum" data-value="8"></i><b>8</b></td>
<td>Use this interface for processing all <code>ConsumerRecord</code> instances received from the Kafka consumer <code>poll()</code> operation when using one of the manual <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">commit methods</a>.
Access to the <code>Consumer</code> object is provided.</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The <code>Consumer</code> object is not thread-safe.
You must only invoke its methods on the thread that calls the listener.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="message-listener-container"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listener-container"></a>Message Listener Containers</h5>
<div class="paragraph">
<p>Two <code>MessageListenerContainer</code> implementations are provided:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>KafkaMessageListenerContainer</code></p>
</li>
<li>
<p><code>ConcurrentMessageListenerContainer</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>KafkaMessageListenerContainer</code> receives all message from all topics or partitions on a single thread.
The <code>ConcurrentMessageListenerContainer</code> delegates to one or more <code>KafkaMessageListenerContainer</code> instances to provide multi-threaded consumption.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2.7, you can add a <code>RecordInterceptor</code> to the listener container; it will be invoked before calling the listener allowing inspection or modification of the record.
If the interceptor returns null, the listener is not called.
The interceptor is not invoked when the listener is a <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#batch-listners">batch listener</a>.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, the <code>CompositeRecordInterceptor</code> can be used to invoke multiple interceptors.</p>
</div>
<div class="paragraph">
<p>By default, when using transactions, the interceptor is invoked after the transaction has started.
Starting with version 2.3.4, you can set the listener container’s <code>interceptBeforeTx</code> property to invoke the interceptor before the transaction has started instead.</p>
</div>
<div class="paragraph">
<p>No interceptor is provided for batch listeners because Kafka already provides a <code>ConsumerInterceptor</code>.</p>
</div>
<div class="sect5">
<h6 id="kafka-container"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-container"></a>Using <code>KafkaMessageListenerContainer</code></h6>
<div class="paragraph">
<p>The following constructors are available:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">KafkaMessageListenerContainer</span><span class="hljs-params">(ConsumerFactory&lt;K, V&gt; consumerFactory,
                    ContainerProperties containerProperties)</span>

<span class="hljs-keyword">public</span> <span class="hljs-title">KafkaMessageListenerContainer</span><span class="hljs-params">(ConsumerFactory&lt;K, V&gt; consumerFactory,
                    ContainerProperties containerProperties,
                    TopicPartitionOffset... topicPartitions)</span></span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Each takes a <code>ConsumerFactory</code> and information about topics and partitions, as well as other configuration in a <code>ContainerProperties</code>
object.
The second constructor is used by the <code>ConcurrentMessageListenerContainer</code> (<a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-ConcurrentMessageListenerContainer">described later</a>) to distribute <code>TopicPartitionOffset</code> across the consumer instances.
<code>ContainerProperties</code> has the following constructors:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ContainerProperties</span><span class="hljs-params">(TopicPartitionOffset... topicPartitions)</span>

<span class="hljs-keyword">public</span> <span class="hljs-title">ContainerProperties</span><span class="hljs-params">(String... topics)</span>

<span class="hljs-keyword">public</span> <span class="hljs-title">ContainerProperties</span><span class="hljs-params">(Pattern topicPattern)</span></span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The first constructor takes an array of <code>TopicPartitionOffset</code> arguments to explicitly instruct the container about which partitions to use (using the consumer <code>assign()</code> method) and with an optional initial offset.
A positive value is an absolute offset by default.
A negative value is relative to the current last offset within a partition by default.
A constructor for <code>TopicPartitionOffset</code> that takes an additional <code>boolean</code> argument is provided.
If this is <code>true</code>, the initial offsets (positive or negative) are relative to the current position for this consumer.
The offsets are applied when the container is started.
The second takes an array of topics, and Kafka allocates the partitions based on the <code>group.id</code> property — distributing partitions across the group.
The third uses a regex <code>Pattern</code> to select the topics.</p>
</div>
<div class="paragraph">
<p>To assign a <code>MessageListener</code> to a container, you can use the <code>ContainerProps.setMessageListener</code> method when creating the Container.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ContainerProperties containerProps = <span class="hljs-keyword">new</span> ContainerProperties(<span class="hljs-string">"topic1"</span>, <span class="hljs-string">"topic2"</span>);
containerProps.setMessageListener(<span class="hljs-keyword">new</span> MessageListener&lt;Integer, String&gt;() {
    ...
});
DefaultKafkaConsumerFactory&lt;Integer, String&gt; cf =
                        <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerProps());
KafkaMessageListenerContainer&lt;Integer, String&gt; container =
                        <span class="hljs-keyword">new</span> KafkaMessageListenerContainer&lt;&gt;(cf, containerProps);
<span class="hljs-keyword">return</span> container;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that when creating a <code>DefaultKafkaConsumerFactory</code>, using the constructor that just takes in the properties as above means that key and value <code>Deserializer</code> classes are picked up from configuration.
Alternatively, <code>Deserializer</code> instances may be passed to the <code>DefaultKafkaConsumerFactory</code> constructor for key and/or value, in which case all Consumers share the same instances.
Another option is to provide <code>Supplier&lt;Deserializer&gt;</code> s (starting with version 2.3) that will be used to obtain separate <code>Deserializer</code> instances for each <code>Consumer</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">DefaultKafkaConsumerFactory&lt;Integer, CustomValue&gt; cf =
                        <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerProps(), <span class="hljs-keyword">null</span>, () -&gt; <span class="hljs-keyword">new</span> CustomValueDeserializer());
KafkaMessageListenerContainer&lt;Integer, String&gt; container =
                        <span class="hljs-keyword">new</span> KafkaMessageListenerContainer&lt;&gt;(cf, containerProps);
<span class="hljs-keyword">return</span> container;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Refer to the <a href="https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/ContainerProperties.html">Javadoc</a> for <code>ContainerProperties</code> for more information about the various properties that you can set.</p>
</div>
<div class="paragraph">
<p>Since version 2.1.1, a new property called <code>logContainerConfig</code> is available.
When <code>true</code> and <code>INFO</code> logging is enabled each listener container writes a log message summarizing its configuration properties.</p>
</div>
<div class="paragraph">
<p>By default, logging of topic offset commits is performed at the <code>DEBUG</code> logging level.
Starting with version 2.1.2, a property in <code>ContainerProperties</code> called <code>commitLogLevel</code> lets you specify the log level for these messages.
For example, to change the log level to <code>INFO</code>, you can use <code>containerProperties.setCommitLogLevel(LogIfLevelEnabled.Level.INFO);</code>.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2, a new container property called <code>missingTopicsFatal</code> has been added (default: <code>true</code>).
This prevents the container from starting if any of the configured topics are not present on the broker.
It does not apply if the container is configured to listen to a topic pattern (regex).
Previously, the container threads looped within the <code>consumer.poll()</code> method waiting for the topic to appear while logging many messages.
Aside from the logs, there was no indication that there was a problem.
To restore the previous behavior, you can set the property to <code>false</code>.</p>
</div>
</div>
<div class="sect5">
<h6 id="using-ConcurrentMessageListenerContainer"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-ConcurrentMessageListenerContainer"></a>Using <code>ConcurrentMessageListenerContainer</code></h6>
<div class="paragraph">
<p>The single constructor is similar to the first <code>KafkaListenerContainer</code> constructor.
The following listing shows the constructor’s signature:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ConcurrentMessageListenerContainer</span><span class="hljs-params">(ConsumerFactory&lt;K, V&gt; consumerFactory,
                            ContainerProperties containerProperties)</span></span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>It also has a <code>concurrency</code> property.
For example, <code>container.setConcurrency(3)</code> creates three <code>KafkaMessageListenerContainer</code> instances.</p>
</div>
<div class="paragraph">
<p>For the first constructor, Kafka distributes the partitions across the consumers using its group management capabilities.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>When listening to multiple topics, the default partition distribution may not be what you expect.
For example, if you have three topics with five partitions each and you want to use <code>concurrency=15</code>, you see only five active consumers, each assigned one partition from each topic, with the other 10 consumers being idle.
This is because the default Kafka <code>PartitionAssignor</code> is the <code>RangeAssignor</code> (see its Javadoc).
For this scenario, you may want to consider using the <code>RoundRobinAssignor</code> instead, which distributes the partitions across all of the consumers.
Then, each consumer is assigned one topic or partition.
To change the <code>PartitionAssignor</code>, you can set the <code>partition.assignment.strategy</code> consumer property (<code>ConsumerConfigs.PARTITION_ASSIGNMENT_STRATEGY_CONFIG</code>) in the properties provided to the <code>DefaultKafkaConsumerFactory</code>.</p>
</div>
<div class="paragraph">
<p>When using Spring Boot, you can assign set the strategy as follows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="hljs properties"><span class="hljs-meta">spring.kafka.consumer.properties.partition.assignment.strategy</span>=<span class="hljs-string">\
org.apache.kafka.clients.consumer.RoundRobinAssignor</span></code></pre>
</div>
</div>
</div>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>For the second constructor, the <code>ConcurrentMessageListenerContainer</code> distributes the <code>TopicPartition</code> instances across the delegate <code>KafkaMessageListenerContainer</code> instances.</p>
</div>
<div class="paragraph">
<p>If, say, six <code>TopicPartition</code> instances are provided and the <code>concurrency</code> is <code>3</code>; each container gets two partitions.
For five <code>TopicPartition</code> instances, two containers get two partitions, and the third gets one.
If the <code>concurrency</code> is greater than the number of <code>TopicPartitions</code>, the <code>concurrency</code> is adjusted down such that each container gets one partition.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>client.id</code> property (if set) is appended with <code>-n</code> where <code>n</code> is the consumer instance that corresponds to the concurrency.
This is required to provide unique names for MBeans when JMX is enabled.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 1.3, the <code>MessageListenerContainer</code> provides access to the metrics of the underlying <code>KafkaConsumer</code>.
In the case of <code>ConcurrentMessageListenerContainer</code>, the <code>metrics()</code> method returns the metrics for all the target <code>KafkaMessageListenerContainer</code> instances.
The metrics are grouped into the <code>Map&lt;MetricName, ? extends Metric&gt;</code> by the <code>client-id</code> provided for the underlying <code>KafkaConsumer</code>.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, the <code>ContainerProperties</code> provides an <code>idleBetweenPolls</code> option to let the main loop in the listener container to sleep between <code>KafkaConsumer.poll()</code> calls.
An actual sleep interval is selected as the minimum from the provided option and difference between the <code>max.poll.interval.ms</code> consumer config and the current records batch processing time.</p>
</div>
</div>
<div class="sect5">
<h6 id="committing-offsets"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets"></a>Committing Offsets</h6>
<div class="paragraph">
<p>Several options are provided for committing offsets.
If the <code>enable.auto.commit</code> consumer property is <code>true</code>, Kafka auto-commits the offsets according to its configuration.
If it is <code>false</code>, the containers support several <code>AckMode</code> settings (described in the next list).
The default <code>AckMode</code> is <code>BATCH</code>.
Starting with version 2.3, the framework sets <code>enable.auto.commit</code> to <code>false</code> unless explicitly set in the configuration.
Previously, the Kafka default (<code>true</code>) was used if the property was not set.</p>
</div>
<div class="paragraph">
<p>The consumer <code>poll()</code> method returns one or more <code>ConsumerRecords</code>.
The <code>MessageListener</code> is called for each record.
The following lists describes the action taken by the container for each <code>AckMode</code>:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>RECORD</code>: Commit the offset when the listener returns after processing the record.</p>
</li>
<li>
<p><code>BATCH</code>: Commit the offset when all the records returned by the <code>poll()</code> have been processed.</p>
</li>
<li>
<p><code>TIME</code>: Commit the offset when all the records returned by the <code>poll()</code> have been processed, as long as the <code>ackTime</code> since the last commit has been exceeded.</p>
</li>
<li>
<p><code>COUNT</code>: Commit the offset when all the records returned by the <code>poll()</code> have been processed, as long as <code>ackCount</code> records have been received since the last commit.</p>
</li>
<li>
<p><code>COUNT_TIME</code>: Similar to <code>TIME</code> and <code>COUNT</code>, but the commit is performed if either condition is <code>true</code>.</p>
</li>
<li>
<p><code>MANUAL</code>: The message listener is responsible to <code>acknowledge()</code> the <code>Acknowledgment</code>.
After that, the same semantics as <code>BATCH</code> are applied.</p>
</li>
<li>
<p><code>MANUAL_IMMEDIATE</code>: Commit the offset immediately when the <code>Acknowledgment.acknowledge()</code> method is called by the listener.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>MANUAL</code>, and <code>MANUAL_IMMEDIATE</code> require the listener to be an <code>AcknowledgingMessageListener</code> or a <code>BatchAcknowledgingMessageListener</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners">Message Listeners</a>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Depending on the <code>syncCommits</code> container property, the <code>commitSync()</code> or <code>commitAsync()</code> method on the consumer is used.
<code>syncCommits</code> is <code>true</code> by default; also see <code>setSyncCommitTimeout</code>.
See <code>setCommitCallback</code> to get the results of asynchronous commits; the default callback is the <code>LoggingCommitCallback</code> which logs errors (and successes at debug level).</p>
</div>
<div class="paragraph">
<p>Because the listener container has it’s own mechanism for committing offsets, it prefers the Kafka <code>ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG</code> to be <code>false</code>.
Starting with version 2.3, it unconditionally sets it to false unless specifically set in the consumer factory or the container’s consumer property overrides.</p>
</div>
<div class="paragraph">
<p>The <code>Acknowledgment</code> has the following method:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">Acknowledgment</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">acknowledge</span><span class="hljs-params">()</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>This method gives the listener control over when offsets are committed.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, the <code>Acknowledgment</code> interface has two additional methods <code>nack(long sleep)</code> and <code>nack(int index, long sleep)</code>.
The first one is used with a record listener, the second with a batch listener.
Calling the wrong method for your listener type will throw an <code>IllegalStateException</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<code>nack()</code> can only be called on the consumer thread that invokes your listener.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>With a record listener, when <code>nack()</code> is called, any pending offsets are committed, the remaing records from the last poll are discarded, and seeks are performed on their partitions so that the failed record and unprocessed records are redelivered on the next <code>poll()</code>.
The consumer thread can be paused before redelivery, by setting the <code>sleep</code> argument.
This is similar functionality to throwing an exception when the container is configured with a <code>SeekToCurrentErrorHandler</code>.</p>
</div>
<div class="paragraph">
<p>When using a batch listener, you can specify the index within the batch where the failure occurred.
When <code>nack()</code> is called, offsets will be committed for records before the index and seeks are performed on the partitions for the failed and discarded records so that they will be redelivered on the next <code>poll()</code>.
This is an improvement over the <code>SeekToCurrentBatchErrorHandler</code>, which can only seek the entire batch for redelivery.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a> for more information.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
When using partition assignment via group management, it is important to ensure the <code>sleep</code> argument (plus the time spent processing records from the previous poll) is less than the consumer <code>max.poll.interval.ms</code> property.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect5">
<h6 id="container-auto-startup"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-auto-startup"></a>Listener Container Auto Startup</h6>
<div class="paragraph">
<p>The listener containers implement <code>SmartLifecycle</code>, and <code>autoStartup</code> is <code>true</code> by default.
The containers are started in a late phase (<code>Integer.MAX-VALUE - 100</code>).
Other components that implement <code>SmartLifecycle</code>, to handle data from listeners, should be started in an earlier phase.
The <code>- 100</code> leaves room for later phases to enable components to be auto-started after the containers.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="kafka-listener-annotation"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-annotation"></a><code>@KafkaListener</code> Annotation</h5>
<div class="paragraph">
<p>The <code>@KafkaListener</code> annotation is used to designate a bean method as a listener for a listener container.
The bean is wrapped in a <code>MessagingMessageListenerAdapter</code> configured with various features, such as converters to convert the data, if necessary, to match the method parameters.</p>
</div>
<div class="paragraph">
<p>You can configure most attributes on the annotation with SpEL by using <code>#{…​}</code> or property placeholders (<code>${…​}</code>).
See the <a href="https://docs.spring.io/spring-kafka/api/org/springframework/kafka/annotation/KafkaListener.html">Javadoc</a> for more information.</p>
</div>
<div class="sect5">
<h6 id="record-listener"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#record-listener"></a>Record Listeners</h6>
<div class="paragraph">
<p>The <code>@KafkaListener</code> annotation provides a mechanism for simple POJO listeners.
The following example shows how to use it:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Listener</span> </span>{

    <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"foo"</span>, topics = <span class="hljs-string">"myTopic"</span>, clientIdPrefix = <span class="hljs-string">"myClientId"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String data)</span> </span>{
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>This mechanism requires an <code>@EnableKafka</code> annotation on one of your <code>@Configuration</code> classes and a listener container factory, which is used to configure the underlying <code>ConcurrentMessageListenerContainer</code>.
By default, a bean with name <code>kafkaListenerContainerFactory</code> is expected.
The following example shows how to use <code>ConcurrentMessageListenerContainer</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Configuration</span>
<span class="hljs-meta">@EnableKafka</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaConfig</span> </span>{

    <span class="hljs-meta">@Bean</span>
    KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt;
                        kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
                                <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
        factory.setConsumerFactory(consumerFactory());
        factory.setConcurrency(<span class="hljs-number">3</span>);
        factory.getContainerProperties().setPollTimeout(<span class="hljs-number">3000</span>);
        <span class="hljs-keyword">return</span> factory;
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerFactory&lt;Integer, String&gt; <span class="hljs-title">consumerFactory</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs());
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> Map&lt;String, Object&gt; <span class="hljs-title">consumerConfigs</span><span class="hljs-params">()</span> </span>{
        Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, embeddedKafka.getBrokersAsString());
        ...
        <span class="hljs-keyword">return</span> props;
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Notice that, to set container properties, you must use the <code>getContainerProperties()</code> method on the factory.
It is used as a template for the actual properties injected into the container.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.1.1, you can now set the <code>client.id</code> property for consumers created by the annotation.
The <code>clientIdPrefix</code> is suffixed with <code>-n</code>, where <code>n</code> is an integer representing the container number when using concurrency.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2, you can now override the container factory’s <code>concurrency</code> and <code>autoStartup</code> properties by using properties on the annotation itself.
The properties can be simple values, property placeholders, or SpEL expressions.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"myListener"</span>, topics = <span class="hljs-string">"myTopic"</span>,
        autoStartup = <span class="hljs-string">"${listen.auto.start:true}"</span>, concurrency = <span class="hljs-string">"${listen.concurrency:3}"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String data)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You can also configure POJO listeners with explicit topics and partitions (and, optionally, their initial offsets).
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"thing2"</span>, topicPartitions =
        { <span class="hljs-meta">@TopicPartition</span>(topic = <span class="hljs-string">"topic1"</span>, partitions = { <span class="hljs-string">"0"</span>, <span class="hljs-string">"1"</span> }),
          <span class="hljs-meta">@TopicPartition</span>(topic = <span class="hljs-string">"topic2"</span>, partitions = <span class="hljs-string">"0"</span>,
             partitionOffsets = <span class="hljs-meta">@PartitionOffset</span>(partition = <span class="hljs-string">"1"</span>, initialOffset = <span class="hljs-string">"100"</span>))
        })
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(ConsumerRecord&lt;?, ?&gt; record)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You can specify each partition in the <code>partitions</code> or <code>partitionOffsets</code> attribute but not both.</p>
</div>
<div class="paragraph">
<p>As with most annotation properties, you can use SpEL expressions; for an example of how to generate a large list of partitions, see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tip-assign-all-parts">Manually Assigning All Partitions</a>.</p>
</div>
<div class="paragraph">
<p>When using manual <code>AckMode</code>, you can also provide the listener with the <code>Acknowledgment</code>.
The following example also shows how to use a different container factory.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"cat"</span>, topics = <span class="hljs-string">"myTopic"</span>,
          containerFactory = <span class="hljs-string">"kafkaManualAckListenerContainerFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String data, Acknowledgment ack)</span> </span>{
    ...
    ack.acknowledge();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Finally, metadata about the message is available from message headers.
You can use the following header names to retrieve the headers of the message:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>KafkaHeaders.OFFSET</code></p>
</li>
<li>
<p><code>KafkaHeaders.RECEIVED_MESSAGE_KEY</code></p>
</li>
<li>
<p><code>KafkaHeaders.RECEIVED_TOPIC</code></p>
</li>
<li>
<p><code>KafkaHeaders.RECEIVED_PARTITION_ID</code></p>
</li>
<li>
<p><code>KafkaHeaders.RECEIVED_TIMESTAMP</code></p>
</li>
<li>
<p><code>KafkaHeaders.TIMESTAMP_TYPE</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The following example shows how to use the headers:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"qux"</span>, topicPattern = <span class="hljs-string">"myTopic1"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(@Payload String foo,
        @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> Integer key,
        @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_PARTITION_ID)</span> <span class="hljs-keyword">int</span> partition,
        @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_TOPIC)</span> String topic,
        @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_TIMESTAMP)</span> <span class="hljs-keyword">long</span> ts
        ) </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect5">
<h6 id="batch-listeners"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#batch-listeners"></a>Batch listeners</h6>
<div class="paragraph">
<p>Starting with version 1.1, you can configure <code>@KafkaListener</code> methods to receive the entire batch of consumer records received from the consumer poll.
To configure the listener container factory to create batch listeners, you can set the <code>batchListener</code> property.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KafkaListenerContainerFactory&lt;?, ?&gt; batchFactory() {
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
            <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    factory.setConsumerFactory(consumerFactory());
    factory.setBatchListener(<span class="hljs-keyword">true</span>);  <span class="hljs-comment">// &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</span>
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to receive a list of payloads:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"list"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(List&lt;String&gt; list)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The topic, partition, offset, and so on are available in headers that parallel the payloads.
The following example shows how to use the headers:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"list"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(List&lt;String&gt; list,
        @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> List&lt;Integer&gt; keys,
        @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_PARTITION_ID)</span> List&lt;Integer&gt; partitions,
        @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_TOPIC)</span> List&lt;String&gt; topics,
        @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.OFFSET)</span> List&lt;Long&gt; offsets) </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you can receive a <code>List</code> of <code>Message&lt;?&gt;</code> objects with each offset and other details in each message, but it must be the only parameter (aside from optional <code>Acknowledgment</code>, when using manual commits, and/or <code>Consumer&lt;?, ?&gt;</code> parameters) defined on the method.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"listMsg"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen14</span><span class="hljs-params">(List&lt;Message&lt;?&gt;&gt; list)</span> </span>{
    ...
}

<span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"listMsgAck"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen15</span><span class="hljs-params">(List&lt;Message&lt;?&gt;&gt; list, Acknowledgment ack)</span> </span>{
    ...
}

<span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"listMsgAckConsumer"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen16</span><span class="hljs-params">(List&lt;Message&lt;?&gt;&gt; list, Acknowledgment ack, Consumer&lt;?, ?&gt; consumer)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>No conversion is performed on the payloads in this case.</p>
</div>
<div class="paragraph">
<p>If the <code>BatchMessagingMessageConverter</code> is configured with a <code>RecordMessageConverter</code>, you can also add a generic type to the <code>Message</code> parameter and the payloads are converted.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#payload-conversion-with-batch">Payload Conversion with Batch Listeners</a> for more information.</p>
</div>
<div class="paragraph">
<p>You can also receive a list of <code>ConsumerRecord&lt;?, ?&gt;</code> objects, but it must be the only parameter (aside from optional <code>Acknowledgment</code>, when using manual commits and <code>Consumer&lt;?, ?&gt;</code> parameters) defined on the method.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"listCRs"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(List&lt;ConsumerRecord&lt;Integer, String&gt;&gt; list)</span> </span>{
    ...
}

<span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"listCRsAck"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(List&lt;ConsumerRecord&lt;Integer, String&gt;&gt; list, Acknowledgment ack)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.2, the listener can receive the complete <code>ConsumerRecords&lt;?, ?&gt;</code> object returned by the <code>poll()</code> method, letting the listener access additional methods, such as <code>partitions()</code> (which returns the <code>TopicPartition</code> instances in the list) and <code>records(TopicPartition)</code> (which gets selective records).
Again, this must be the only parameter (aside from optional <code>Acknowledgment</code>, when using manual commits or <code>Consumer&lt;?, ?&gt;</code> parameters) on the method.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"pollResults"</span>, topics = <span class="hljs-string">"myTopic"</span>, containerFactory = <span class="hljs-string">"batchFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">pollResults</span><span class="hljs-params">(ConsumerRecords&lt;?, ?&gt; records)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If the container factory has a <code>RecordFilterStrategy</code> configured, it is ignored for <code>ConsumerRecords&lt;?, ?&gt;</code> listeners, with a <code>WARN</code> log message emitted.
Records can only be filtered with a batch listener if the <code>&lt;List&lt;?&gt;&gt;</code> form of listener is used.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect5">
<h6 id="annotation-properties"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-properties"></a>Annotation Properties</h6>
<div class="paragraph">
<p>Starting with version 2.0, the <code>id</code> property (if present) is used as the Kafka consumer <code>group.id</code> property, overriding the configured property in the consumer factory, if present.
You can also set <code>groupId</code> explicitly or set <code>idIsGroup</code> to false to restore the previous behavior of using the consumer factory <code>group.id</code>.</p>
</div>
<div class="paragraph">
<p>You can use property placeholders or SpEL expressions within most annotation properties, as the following example shows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"${some.property}"</span>)

<span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"#{someBean.someProperty}"</span>,
    groupId = <span class="hljs-string">"#{someBean.someProperty}.group"</span>)</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.1.2, the SpEL expressions support a special token: <code>__listener</code>.
It is a pseudo bean name that represents the current bean instance within which this annotation exists.</p>
</div>
<div class="paragraph">
<p>Consider the following example:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> Listener <span class="hljs-title">listener1</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Listener(<span class="hljs-string">"topic1"</span>);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> Listener <span class="hljs-title">listener2</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Listener(<span class="hljs-string">"topic2"</span>);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Given the beans in the previous example, we can then use the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Listener</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String topic;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Listener</span><span class="hljs-params">(String topic)</span> </span>{
        <span class="hljs-keyword">this</span>.topic = topic;
    }

    <span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"#{__listener.topic}"</span>,
        groupId = <span class="hljs-string">"#{__listener.topic}.group"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(...)</span> </span>{
        ...
    }

    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getTopic</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.topic;
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>If, in the unlikely event that you have an actual bean called <code>__listener</code>, you can change the expression token byusing the <code>beanRef</code> attribute.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(beanRef = <span class="hljs-string">"__x"</span>, topics = <span class="hljs-string">"#{__x.topic}"</span>,
    groupId = <span class="hljs-string">"#{__x.topic}.group"</span>)</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.2.4, you can specify Kafka consumer properties directly on the annotation, these will override any properties with the same name configured in the consumer factory. You <strong>cannot</strong> specify the <code>group.id</code> and <code>client.id</code> properties this way; they will be ignored; use the <code>groupId</code> and <code>clientIdPrefix</code> annotation properties for those.</p>
</div>
<div class="paragraph">
<p>The properties are specified as individual strings with the normal Java <code>Properties</code> file format: <code>foo:bar</code>, <code>foo=bar</code>, or <code>foo bar</code>.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"myTopic"</span>, groupId=<span class="hljs-string">"group"</span>, properties= {
    <span class="hljs-string">"max.poll.interval.ms:60000"</span>,
    ConsumerConfig.MAX_POLL_RECORDS_CONFIG + <span class="hljs-string">"=100"</span>
})</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="listener-group-id"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-group-id"></a>Obtaining the Consumer <code>group.id</code></h5>
<div class="paragraph">
<p>When running the same listener code in multiple containers, it may be useful to be able to determine which container (identified by its <code>group.id</code> consumer property) that a record came from.</p>
</div>
<div class="paragraph">
<p>You can call <code>KafkaUtils.getConsumerGroupId()</code> on the listener thread to do this.
Alternatively, you can access the group id in a method parameter.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"bar"</span>, topicPattern = <span class="hljs-string">"${topicTwo:annotated2}"</span>, exposeGroupId = <span class="hljs-string">"${always:true}"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listener</span><span class="hljs-params">(@Payload String foo,
        @Header(KafkaHeaders.GROUP_ID)</span> String groupId) </span>{
...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
This is available in record listeners and batch listeners that receive a <code>List&lt;?&gt;</code> of records.
It is <strong>not</strong> available in a batch listener that receives a <code>ConsumerRecords&lt;?, ?&gt;</code> argument.
Use the <code>KafkaUtils</code> mechanism in that case.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="container-thread-naming"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-thread-naming"></a>Container Thread Naming</h5>
<div class="paragraph">
<p>Listener containers currently use two task executors, one to invoke the consumer and another that is used to invoke the listener when the kafka consumer property <code>enable.auto.commit</code> is <code>false</code>.
You can provide custom executors by setting the <code>consumerExecutor</code> and <code>listenerExecutor</code> properties of the container’s <code>ContainerProperties</code>.
When using pooled executors, be sure that enough threads are available to handle the concurrency across all the containers in which they are used.
When using the <code>ConcurrentMessageListenerContainer</code>, a thread from each is used for each consumer (<code>concurrency</code>).</p>
</div>
<div class="paragraph">
<p>If you do not provide a consumer executor, a <code>SimpleAsyncTaskExecutor</code> is used.
This executor creates threads with names similar to <code>&lt;beanName&gt;-C-1</code> (consumer thread).
For the <code>ConcurrentMessageListenerContainer</code>, the <code>&lt;beanName&gt;</code> part of the thread name becomes <code>&lt;beanName&gt;-m</code>, where <code>m</code> represents the consumer instance.
<code>n</code> increments each time the container is started.
So, with a bean name of <code>container</code>, threads in this container will be named <code>container-0-C-1</code>, <code>container-1-C-1</code> etc., after the container is started the first time; <code>container-0-C-2</code>, <code>container-1-C-2</code> etc., after a stop and subsequent start.</p>
</div>
</div>
<div class="sect4">
<h5 id="kafka-listener-meta"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-meta"></a><code>@KafkaListener</code> as a Meta Annotation</h5>
<div class="paragraph">
<p>Starting with version 2.2, you can now use <code>@KafkaListener</code> as a meta annotation.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Target</span>(ElementType.METHOD)
<span class="hljs-meta">@Retention</span>(RetentionPolicy.RUNTIME)
<span class="hljs-meta">@KafkaListener</span>
<span class="hljs-keyword">public</span> <span class="hljs-meta">@interface</span> MyThreeConsumersListener {

    <span class="hljs-meta">@AliasFor</span>(annotation = KafkaListener.class, attribute = <span class="hljs-string">"id"</span>)
    <span class="hljs-function">String <span class="hljs-title">id</span><span class="hljs-params">()</span></span>;

    <span class="hljs-meta">@AliasFor</span>(annotation = KafkaListener.class, attribute = <span class="hljs-string">"topics"</span>)
    String[] topics();

    <span class="hljs-meta">@AliasFor</span>(annotation = KafkaListener.class, attribute = <span class="hljs-string">"concurrency"</span>)
    <span class="hljs-function">String <span class="hljs-title">concurrency</span><span class="hljs-params">()</span> <span class="hljs-keyword">default</span> "3"</span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You must alias at least one of <code>topics</code>, <code>topicPattern</code>, or <code>topicPartitions</code> (and, usually, <code>id</code> or <code>groupId</code> unless you have specified a <code>group.id</code> in the consumer factory configuration).
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@MyThreeConsumersListener</span>(id = <span class="hljs-string">"my.group"</span>, topics = <span class="hljs-string">"my.topic"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen1</span><span class="hljs-params">(String in)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="class-level-kafkalistener"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-level-kafkalistener"></a><code>@KafkaListener</code> on a Class</h5>
<div class="paragraph">
<p>When you use <code>@KafkaListener</code> at the class-level, you must specify <code>@KafkaHandler</code> at the method level.
When messages are delivered, the converted message payload type is used to determine which method to call.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"multi"</span>, topics = <span class="hljs-string">"myTopic"</span>)
<span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiListenerBean</span> </span>{

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String foo)</span> </span>{
        ...
    }

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(Integer bar)</span> </span>{
        ...
    }

    <span class="hljs-meta">@KafkaHandler</span>(isDefault = <span class="hljs-keyword">true</span>`)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listenDefault</span><span class="hljs-params">(Object object)</span> </span>{
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.1.3, you can designate a <code>@KafkaHandler</code> method as the default method that is invoked if there is no match on other methods.
At most, one method can be so designated.
When using <code>@KafkaHandler</code> methods, the payload must have already been converted to the domain object (so the match can be performed).
Use a custom deserializer, the <code>JsonDeserializer</code>, or the <code>JsonMessageConverter</code> with its <code>TypePrecedence</code> set to <code>TYPE_ID</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a> for more information.</p>
</div>
</div>
<div class="sect4">
<h5 id="kafkalistener-lifecycle"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-lifecycle"></a><code>@KafkaListener</code> Lifecycle Management</h5>
<div class="paragraph">
<p>The listener containers created for <code>@KafkaListener</code> annotations are not beans in the application context.
Instead, they are registered with an infrastructure bean of type <code>KafkaListenerEndpointRegistry</code>.
This bean is automatically declared by the framework and manages the containers' lifecycles; it will auto-start any containers that have <code>autoStartup</code> set to <code>true</code>.
All containers created by all container factories must be in the same <code>phase</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-auto-startup">Listener Container Auto Startup</a> for more information.
You can manage the lifecycle programmatically by using the registry.
Starting or stopping the registry will start or stop all the registered containers.
Alternatively, you can get a reference to an individual container by using its <code>id</code> attribute.
You can set <code>autoStartup</code> on the annotation, which overrides the default setting configured into the container factory.
You can get a reference to the bean from the application context, such as auto-wiring, to manage its registered containers.
The following examples show how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"myContainer"</span>, topics = <span class="hljs-string">"myTopic"</span>, autoStartup = <span class="hljs-string">"false"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(...)</span> </span>{ ... }</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Autowired</span>
<span class="hljs-keyword">private</span> KafkaListenerEndpointRegistry registry;

...

    <span class="hljs-keyword">this</span>.registry.getListenerContainer(<span class="hljs-string">"myContainer"</span>).start();

...</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The registry only maintains the life cycle of containers it manages; containers declared as beans are not managed by the registry and can be obtained from the application context.
A collection of managed containers can be obtained by calling the registry’s <code>getListenerContainers()</code> method.
Version 2.2.5 added a convenience method <code>getAllListenerContainers()</code>, which returns a collection of all containers, including those managed by the registry and those declared as beans.
The collection returned will include any prototype beans that have been initialized, but it will not initialize any lazy bean declarations.</p>
</div>
</div>
<div class="sect4">
<h5 id="kafka-validation"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-validation"></a><code>@KafkaListener</code> <code>@Payload</code> Validation</h5>
<div class="paragraph">
<p>Starting with version 2.2, it is now easier to add a <code>Validator</code> to validate <code>@KafkaListener</code> <code>@Payload</code> arguments.
Previously, you had to configure a custom <code>DefaultMessageHandlerMethodFactory</code> and add it to the registrar.
Now, you can add the validator to the registrar itself.
The following code shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Configuration</span>
<span class="hljs-meta">@EnableKafka</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Config</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">KafkaListenerConfigurer</span> </span>{

    ...

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">configureKafkaListeners</span><span class="hljs-params">(KafkaListenerEndpointRegistrar registrar)</span> </span>{
      registrar.setValidator(<span class="hljs-keyword">new</span> MyValidator());
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When you use Spring Boot with the validation starter, a <code>LocalValidatorFactoryBean</code> is auto-configured, as the following example shows:
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Configuration</span>
<span class="hljs-meta">@EnableKafka</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Config</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">KafkaListenerConfigurer</span> </span>{

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> LocalValidatorFactoryBean validator;
    ...

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">configureKafkaListeners</span><span class="hljs-params">(KafkaListenerEndpointRegistrar registrar)</span> </span>{
      registrar.setValidator(<span class="hljs-keyword">this</span>.validator);
    }
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following examples show how to validate:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ValidatedClass</span> </span>{

  <span class="hljs-meta">@Max</span>(<span class="hljs-number">10</span>)
  <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> bar;

  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getBar</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.bar;
  }

  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setBar</span><span class="hljs-params">(<span class="hljs-keyword">int</span> bar)</span> </span>{
    <span class="hljs-keyword">this</span>.bar = bar;
  }

}</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id=<span class="hljs-string">"validated"</span>, topics = <span class="hljs-string">"annotated35"</span>, errorHandler = <span class="hljs-string">"validationErrorHandler"</span>,
      containerFactory = <span class="hljs-string">"kafkaJsonListenerContainerFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">validatedListener</span><span class="hljs-params">(@Payload @Valid ValidatedClass val)</span> </span>{
    ...
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaListenerErrorHandler <span class="hljs-title">validationErrorHandler</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> (m, e) -&gt; {
        ...
    };
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="rebalance-listeners"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#rebalance-listeners"></a>Rebalancing Listeners</h5>
<div class="paragraph">
<p><code>ContainerProperties</code> has a property called <code>consumerRebalanceListener</code>, which takes an implementation of the Kafka client’s <code>ConsumerRebalanceListener</code> interface.
If this property is not provided, the container configures a logging listener that logs rebalance events at the <code>INFO</code> level.
The framework also adds a sub-interface <code>ConsumerAwareRebalanceListener</code>.
The following listing shows the <code>ConsumerAwareRebalanceListener</code> interface definition:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">ConsumerAwareRebalanceListener</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ConsumerRebalanceListener</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsRevokedBeforeCommit</span><span class="hljs-params">(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions)</span></span>;

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsRevokedAfterCommit</span><span class="hljs-params">(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions)</span></span>;

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsAssigned</span><span class="hljs-params">(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions)</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Notice that there are two callbacks when partitions are revoked.
The first is called immediately.
The second is called after any pending offsets are committed.
This is useful if you wish to maintain offsets in some external repository, as the following example shows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">containerProperties.setConsumerRebalanceListener(<span class="hljs-keyword">new</span> ConsumerAwareRebalanceListener() {

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsRevokedBeforeCommit</span><span class="hljs-params">(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions)</span> </span>{
        <span class="hljs-comment">// acknowledge any pending Acknowledgments (if using manual acks)</span>
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsRevokedAfterCommit</span><span class="hljs-params">(Consumer&lt;?, ?&gt; consumer, Collection&lt;TopicPartition&gt; partitions)</span> </span>{
        <span class="hljs-comment">// ...</span>
            store(consumer.position(partition));
        <span class="hljs-comment">// ...</span>
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsAssigned</span><span class="hljs-params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>{
        <span class="hljs-comment">// ...</span>
            consumer.seek(partition, offsetTracker.getOffset() + <span class="hljs-number">1</span>);
        <span class="hljs-comment">// ...</span>
    }
});</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="annotation-send-to"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-send-to"></a>Forwarding Listener Results using <code>@SendTo</code></h5>
<div class="paragraph">
<p>Starting with version 2.0, if you also annotate a <code>@KafkaListener</code> with a <code>@SendTo</code> annotation and the method invocation returns a result, the result is forwarded to the topic specified by the <code>@SendTo</code>.</p>
</div>
<div class="paragraph">
<p>The <code>@SendTo</code> value can have several forms:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>@SendTo("someTopic")</code> routes to the literal topic</p>
</li>
<li>
<p><code>@SendTo("#{someExpression}")</code> routes to the topic determined by evaluating the expression once during application context initialization.</p>
</li>
<li>
<p><code>@SendTo("!{someExpression}")</code> routes to the topic determined by evaluating the expression at runtime.
The <code>#root</code> object for the evaluation has three properties:</p>
<div class="ulist">
<ul>
<li>
<p><code>request</code>: The inbound <code>ConsumerRecord</code> (or <code>ConsumerRecords</code> object for a batch listener))</p>
</li>
<li>
<p><code>source</code>: The <code>org.springframework.messaging.Message&lt;?&gt;</code> converted from the <code>request</code>.</p>
</li>
<li>
<p><code>result</code>: The method return result.</p>
</li>
</ul>
</div>
</li>
<li>
<p><code>@SendTo</code> (no properties): This is treated as <code>!{source.headers['kafka_replyTopic']}</code> (since version 2.1.3).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Starting with versions 2.1.11 and 2.2.1, property placeholders are resolved within <code>@SendTo</code> values.</p>
</div>
<div class="paragraph">
<p>The result of the expression evaluation must be a <code>String</code> that represents the topic name.
The following examples show the various ways to use <code>@SendTo</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"annotated21"</span>)
<span class="hljs-meta">@SendTo</span>(<span class="hljs-string">"!{request.value()}"</span>) <span class="hljs-comment">// runtime SpEL</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">replyingListener</span><span class="hljs-params">(String in)</span> </span>{
    ...
}

<span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"${some.property:annotated22}"</span>)
<span class="hljs-meta">@SendTo</span>(<span class="hljs-string">"#{myBean.replyTopic}"</span>) <span class="hljs-comment">// config time SpEL</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> Collection&lt;String&gt; <span class="hljs-title">replyingBatchListener</span><span class="hljs-params">(List&lt;String&gt; in)</span> </span>{
    ...
}

<span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"annotated23"</span>, errorHandler = <span class="hljs-string">"replyErrorHandler"</span>)
<span class="hljs-meta">@SendTo</span>(<span class="hljs-string">"annotated23reply"</span>) <span class="hljs-comment">// static reply topic definition</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">replyingListenerWithErrorHandler</span><span class="hljs-params">(String in)</span> </span>{
    ...
}
...
<span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"annotated25"</span>)
<span class="hljs-meta">@SendTo</span>(<span class="hljs-string">"annotated25reply1"</span>)
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiListenerSendTo</span> </span>{

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">foo</span><span class="hljs-params">(String in)</span> </span>{
        ...
    }

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-meta">@SendTo</span>(<span class="hljs-string">"!{'annotated25reply2'}"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">bar</span><span class="hljs-params">(@Payload(required = <span class="hljs-keyword">false</span>)</span> KafkaNull nul,
            @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> <span class="hljs-keyword">int</span> key) </span>{
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.2, you can add a <code>ReplyHeadersConfigurer</code> to the listener container factory.
This is consulted to determine which headers you want to set in the reply message.
The following example shows how to add a <code>ReplyHeadersConfigurer</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; <span class="hljs-title">kafkaListenerContainerFactory</span><span class="hljs-params">()</span> </span>{
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
        <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    factory.setConsumerFactory(cf());
    factory.setReplyTemplate(template());
    factory.setReplyHeadersConfigurer((k, v) -&gt; k.equals(<span class="hljs-string">"cat"</span>));
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You can also add more headers if you wish.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; <span class="hljs-title">kafkaListenerContainerFactory</span><span class="hljs-params">()</span> </span>{
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
        <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    factory.setConsumerFactory(cf());
    factory.setReplyTemplate(template());
    factory.setReplyHeadersConfigurer(<span class="hljs-keyword">new</span> ReplyHeadersConfigurer() {

      <span class="hljs-meta">@Override</span>
      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">shouldCopy</span><span class="hljs-params">(String headerName, Object headerValue)</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;
      }

      <span class="hljs-meta">@Override</span>
      <span class="hljs-function"><span class="hljs-keyword">public</span> Map&lt;String, Object&gt; <span class="hljs-title">additionalHeaders</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> Collections.singletonMap(<span class="hljs-string">"qux"</span>, <span class="hljs-string">"fiz"</span>);
      }

    });
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When you use <code>@SendTo</code>, you must configure the <code>ConcurrentKafkaListenerContainerFactory</code> with a <code>KafkaTemplate</code> in its <code>replyTemplate</code> property to perform the send.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Unless you use <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template">request/reply semantics</a> only the simple <code>send(topic, value)</code> method is used, so you may wish to create a subclass to generate the partition or key.
The following example shows how to do so:
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaTemplate&lt;String, String&gt; <span class="hljs-title">myReplyingTemplate</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaTemplate&lt;Integer, String&gt;(producerFactory()) {

        <span class="hljs-meta">@Override</span>
        <span class="hljs-keyword">public</span> ListenableFuture&lt;SendResult&lt;String, String&gt;&gt; send(String topic, String data) {
            <span class="hljs-keyword">return</span> <span class="hljs-keyword">super</span>.send(topic, partitionForData(data), keyForData(data), data);
        }

        ...

    };
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If the listener method returns <code>Message&lt;?&gt;</code> or <code>Collection&lt;Message&lt;?&gt;&gt;</code>, the listener method is responsible for setting up the message headers for the reply.
For example, when handling a request from a <code>ReplyingKafkaTemplate</code>, you might do the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"messageReturned"</span>, topics = <span class="hljs-string">"someTopic"</span>)
<span class="hljs-keyword">public</span> Message&lt;?&gt; listen(String in, <span class="hljs-meta">@Header</span>(KafkaHeaders.REPLY_TOPIC) <span class="hljs-keyword">byte</span>[] replyTo,
        <span class="hljs-meta">@Header</span>(KafkaHeaders.CORRELATION_ID) <span class="hljs-keyword">byte</span>[] correlation) {
    <span class="hljs-keyword">return</span> MessageBuilder.withPayload(in.toUpperCase())
            .setHeader(KafkaHeaders.TOPIC, replyTo)
            .setHeader(KafkaHeaders.MESSAGE_KEY, <span class="hljs-number">42</span>)
            .setHeader(KafkaHeaders.CORRELATION_ID, correlation)
            .setHeader(<span class="hljs-string">"someOtherHeader"</span>, <span class="hljs-string">"someValue"</span>)
            .build();
}</code></pre>
</div>
</div>
</div>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>When using request/reply semantics, the target partition can be requested by the sender.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can annotate a <code>@KafkaListener</code> method with <code>@SendTo</code> even if no result is returned.
This is to allow the configuration of an <code>errorHandler</code> that can forward information about a failed message delivery to some topic.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"voidListenerWithReplyingErrorHandler"</span>, topics = <span class="hljs-string">"someTopic"</span>,
        errorHandler = <span class="hljs-string">"voidSendToErrorHandler"</span>)
<span class="hljs-meta">@SendTo</span>(<span class="hljs-string">"failures"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">voidListenerWithReplyingErrorHandler</span><span class="hljs-params">(String in)</span> </span>{
    <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> RuntimeException(<span class="hljs-string">"fail"</span>);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaListenerErrorHandler <span class="hljs-title">voidSendToErrorHandler</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> (m, e) -&gt; {
        <span class="hljs-keyword">return</span> ... <span class="hljs-comment">// some information about the failure and input data</span>
    };
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-error-handling">Handling Exceptions</a> for more information.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="filtering-messages"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#filtering-messages"></a>Filtering Messages</h5>
<div class="paragraph">
<p>In certain scenarios, such as rebalancing, a message that has already been processed may be redelivered.
The framework cannot know whether such a message has been processed or not.
That is an application-level function.
This is known as the <a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/IdempotentReceiver.html">Idempotent Receiver</a> pattern and Spring Integration provides an <a href="https://docs.spring.io/spring-integration/reference/html/#idempotent-receiver">implementation of it</a>.</p>
</div>
<div class="paragraph">
<p>The Spring for Apache Kafka project also provides some assistance by means of the <code>FilteringMessageListenerAdapter</code> class, which can wrap your <code>MessageListener</code>.
This class takes an implementation of <code>RecordFilterStrategy</code> in which you implement the <code>filter</code> method to signal that a message is a duplicate and should be discarded.
This has an additional property called <code>ackDiscarded</code>, which indicates whether the adapter should acknowledge the discarded record.
It is <code>false</code> by default.</p>
</div>
<div class="paragraph">
<p>When you use <code>@KafkaListener</code>, set the <code>RecordFilterStrategy</code> (and optionally <code>ackDiscarded</code>) on the container factory so that the listener is wrapped in the appropriate filtering adapter.</p>
</div>
<div class="paragraph">
<p>In addition, a <code>FilteringBatchMessageListenerAdapter</code> is provided, for when you use a batch <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners">message listener</a>.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The <code>FilteringBatchMessageListenerAdapter</code> is ignored if your <code>@KafkaListener</code> receives a <code>ConsumerRecords&lt;?, ?&gt;</code> instead of <code>List&lt;ConsumerRecord&lt;?, ?&gt;&gt;</code>, because <code>ConsumerRecords</code> is immutable.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="retrying-deliveries"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deliveries"></a>Retrying Deliveries</h5>
<div class="paragraph">
<p>If your listener throws an exception, the default behavior is to invoke the <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handlers">Container Error Handlers</a>, if configured, or logged otherwise.</p>
</div>
<div class="paragraph">
<p>NOTE:
To retry deliveries, a convenient listener adapter <code>RetryingMessageListenerAdapter</code> is provided.</p>
</div>
<div class="paragraph">
<p>You can configure it with a <code>RetryTemplate</code> and <code>RecoveryCallback&lt;Void&gt;</code> - see the <a href="https://github.com/spring-projects/spring-retry">spring-retry</a> project for information about these components.
If a recovery callback is not provided, the exception is thrown to the container after retries are exhausted.
In that case, the <code>ErrorHandler</code> is invoked, if configured, or logged otherwise.</p>
</div>
<div class="paragraph">
<p>When you use <code>@KafkaListener</code>, you can set the <code>RetryTemplate</code> (and optionally <code>recoveryCallback</code>) on the container factory.
When you do so, the listener is wrapped in the appropriate retrying adapter.</p>
</div>
<div class="paragraph">
<p>The contents of the <code>RetryContext</code> passed into the <code>RecoveryCallback</code> depend on the type of listener.
The context always has a <code>record</code> attribute, which is the record for which the failure occurred.
If your listener is acknowledging or consumer aware, additional <code>acknowledgment</code> or <code>consumer</code> attributes are available.
For convenience, the <code>RetryingMessageListenerAdapter</code> provides static constants for these keys.
See its <a href="https://docs.spring.io/spring-kafka/api/org/springframework/kafka/listener/adapter/AbstractRetryingMessageListenerAdapter.html">Javadoc</a> for more information.</p>
</div>
<div class="paragraph">
<p>A retry adapter is not provided for any of the batch <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners">message listeners</a>, because the framework has no knowledge of where in a batch the failure occurred.
If you need retry capabilities when you use a batch listener, we recommend that you use a <code>RetryTemplate</code> within the listener itself.</p>
</div>
</div>
<div class="sect4">
<h5 id="stateful-retry"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry"></a>Stateful Retry</h5>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Now that the <code>SeekToCurrentErrorHandler</code> can be configured with a <code>BackOff</code> and has the ability to retry only certain exceptions (since version 2.3), the use of stateful retry, via the listener adapter retry configuration, is no longer necessary.
You can provide the same functionality with appropriate configuration of the error handler and remove all retry configuration from the listener adatper.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a> for more information.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>You should understand that the retry discussed in the <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deliveries">preceding section</a> suspends the consumer thread (if a <code>BackOffPolicy</code> is used).
There are no calls to <code>Consumer.poll()</code> during the retries.
Kafka has two properties to determine consumer health.
The <code>session.timeout.ms</code> is used to determine if the consumer is active.
Since <code>kafka-clients</code> version <code>0.10.1.0</code>, heartbeats are sent on a background thread, so a slow consumer no longer affects that.
<code>max.poll.interval.ms</code> (default: five minutes) is used to determine if a consumer appears to be hung (taking too long to process records from the last poll).
If the time between <code>poll()</code> calls exceeds this, the broker revokes the assigned partitions and performs a rebalance.
For lengthy retry sequences, with back off, this can easily happen.</p>
</div>
<div class="paragraph">
<p>Since version 2.1.3, you can avoid this problem by using stateful retry in conjunction with a <code>SeekToCurrentErrorHandler</code>.
In this case, each delivery attempt throws the exception back to the container, the error handler re-seeks the unprocessed offsets, and the same message is redelivered by the next <code>poll()</code>.
This avoids the problem of exceeding the <code>max.poll.interval.ms</code> property (as long as an individual delay between attempts does not exceed it).
So, when you use an <code>ExponentialBackOffPolicy</code>, you must ensure that the <code>maxInterval</code> is less than the <code>max.poll.interval.ms</code> property.
To enable stateful retry, you can use the <code>RetryingMessageListenerAdapter</code> constructor that takes a <code>stateful</code> <code>boolean</code> argument (set it to <code>true</code>).
When you configure the listener container factory (for <code>@KafkaListener</code>), set the factory’s <code>statefulRetry</code> property to <code>true</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Version 2.2 added recovery to the <code>SeekToCurrentErrorHandler</code>, such as sending a failed record to a dead-letter topic.
When using stateful retry, you must perform the recovery in the retry <code>RecoveryCallback</code> and NOT in the error handler.
Otherwise, if the recovery is done in the error handler, the retry template’s state will never be cleared.
Also, you must ensure that the <code>maxFailures</code> in the <code>SeekToCurrentErrorHandler</code> must be at least as many as configured in the retry policy, again to ensure that the retries are exhausted and the state cleared.
Here is an example for retry configuration when used with a <code>SeekToCurrentErrorHandler</code> where <code>factory</code> is the <code>ConcurrentKafkaListenerContainerFactory</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Autowired</span>
DeadLetterPublishingRecoverer recoverer;

...
    factory.setRetryTemplate(<span class="hljs-keyword">new</span> RetryTemplate()); <span class="hljs-comment">// 3 retries by default</span>
    factory.setStatefulRetry(<span class="hljs-keyword">true</span>);
    factory.setRecoveryCallback(context -&gt; {
        recoverer.accept((ConsumerRecord&lt;?, ?&gt;) context.getAttribute(<span class="hljs-string">"record"</span>),
                (Exception) context.getLastThrowable());
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;
    });
...

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> SeekToCurrentErrorHandler <span class="hljs-title">eh</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> SeekToCurrentErrorHandler(<span class="hljs-keyword">new</span> FixedBackOff(<span class="hljs-number">0L</span>, <span class="hljs-number">3L</span>)); <span class="hljs-comment">// at least 3</span>
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>However, see the note at the beginning of this section; you can avoid using the <code>RetryTemplate</code> altogether.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If the recoverer fails (throws an exception), the record will be included in the seeks and recovery will be attempted again during the next delivery.
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="events"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#events"></a>4.1.4. Application Events</h4>
<div class="paragraph">
<p>The following Spring application events are published by listener containers and their consumers:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ConsumerStartingEvent</code> - published when a consumer thread is first started, before it starts polling.</p>
</li>
<li>
<p><code>ConsumerStartedEvent</code> - published when a consumer is about to start polling.</p>
</li>
<li>
<p><code>ConsumerFailedToStartEvent</code> - published if no <code>ConsumerStartingEvent</code> is published within the <code>consumerStartTimeout</code> container property.
This event might signal that the configured task executor has insufficient threads to support the containers it is used in and their concurrency.
An error message is also logged when this condition occurs.</p>
</li>
<li>
<p><code>ListenerContainerIdleEvent</code>: published when no messages have been received in <code>idleInterval</code> (if configured).</p>
</li>
<li>
<p><code>NonResponsiveConsumerEvent</code>: published when the consumer appears to be blocked in the <code>poll</code> method.</p>
</li>
<li>
<p><code>ConsumerPausedEvent</code>: published by each consumer when the container is paused.</p>
</li>
<li>
<p><code>ConsumerResumedEvent</code>: published by each consumer when the container is resumed.</p>
</li>
<li>
<p><code>ConsumerStoppingEvent</code>: published by each consumer just before stopping.</p>
</li>
<li>
<p><code>ConsumerStoppedEvent</code>: published after the consumer is closed.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#thread-safety">Thread Safety</a>.</p>
</li>
<li>
<p><code>ContainerStoppedEvent</code>: published when all consumers have terminated.</p>
</li>
</ul>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
By default, the application context’s event multicaster invokes event listeners on the calling thread.
If you change the multicaster to use an async executor, you must not invoke any <code>Consumer</code> methods when the event contains a reference to the consumer.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>The <code>ListenerContainerIdleEvent</code> has the following properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>source</code>: The listener container instance that published the event.</p>
</li>
<li>
<p><code>container</code>: The listener container or the parent listener container, if the source container is a child.</p>
</li>
<li>
<p><code>id</code>: The listener ID (or container bean name).</p>
</li>
<li>
<p><code>idleTime</code>: The time the container had been idle when the event was published.</p>
</li>
<li>
<p><code>topicPartitions</code>: The topics and partitions that the container was assigned at the time the event was generated.</p>
</li>
<li>
<p><code>consumer</code>: A reference to the Kafka <code>Consumer</code> object.
For example, if the consumer’s <code>pause()</code> method was previously called, it can <code>resume()</code> when the event is received.</p>
</li>
<li>
<p><code>paused</code>: Whether the container is currently paused.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pause-resume">Pausing and Resuming Listener Containers</a> for more information.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>NonResponsiveConsumerEvent</code> has the following properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>source</code>: The listener container instance that published the event.</p>
</li>
<li>
<p><code>container</code>: The listener container or the parent listener container, if the source container is a child.</p>
</li>
<li>
<p><code>id</code>: The listener ID (or container bean name).</p>
</li>
<li>
<p><code>timeSinceLastPoll</code>: The time just before the container last called <code>poll()</code>.</p>
</li>
<li>
<p><code>topicPartitions</code>: The topics and partitions that the container was assigned at the time the event was generated.</p>
</li>
<li>
<p><code>consumer</code>: A reference to the Kafka <code>Consumer</code> object.
For example, if the consumer’s <code>pause()</code> method was previously called, it can <code>resume()</code> when the event is received.</p>
</li>
<li>
<p><code>paused</code>: Whether the container is currently paused.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pause-resume">Pausing and Resuming Listener Containers</a> for more information.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>ConsumerPausedEvent</code>, <code>ConsumerResumedEvent</code>, and <code>ConsumerStopping</code> events have the following properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>source</code>: The listener container instance that published the event.</p>
</li>
<li>
<p><code>container</code>: The listener container or the parent listener container, if the source container is a child.</p>
</li>
<li>
<p><code>partitions</code>: The <code>TopicPartition</code> instances involved.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>ConsumerStartingEvent</code>, <code>ConsumerStartingEvent</code>, <code>ConsumerFailedToStartEvent</code>, <code>ConsumerStoppedEvent</code> and <code>ContainerStoppedEvent</code> events have the following properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>source</code>: The listener container instance that published the event.</p>
</li>
<li>
<p><code>container</code>: The listener container or the parent listener container, if the source container is a child.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>All containers (whether a child or a parent) publish <code>ContainerStoppedEvent</code>.
For a parent container, the source and container properties are identical.</p>
</div>
<div class="sect4">
<h5 id="idle-containers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#idle-containers"></a>Detecting Idle and Non-Responsive Consumers</h5>
<div class="paragraph">
<p>While efficient, one problem with asynchronous consumers is detecting when they are idle.
You might want to take some action if no messages arrive for some period of time.</p>
</div>
<div class="paragraph">
<p>You can configure the listener container to publish a <code>ListenerContainerIdleEvent</code> when some time passes with no message delivery.
While the container is idle, an event is published every <code>idleEventInterval</code> milliseconds.</p>
</div>
<div class="paragraph">
<p>To configure this feature, set the <code>idleEventInterval</code> on the container.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">KafkaMessageListenerContainer</span><span class="hljs-params">(ConsumerFactory&lt;String, String&gt; consumerFactory)</span> </span>{
    ContainerProperties containerProps = <span class="hljs-keyword">new</span> ContainerProperties(<span class="hljs-string">"topic1"</span>, <span class="hljs-string">"topic2"</span>);
    ...
    containerProps.setIdleEventInterval(<span class="hljs-number">60000L</span>);
    ...
    KafkaMessageListenerContainer&lt;String, String&gt; container = <span class="hljs-keyword">new</span> KafKaMessageListenerContainer&lt;&gt;(...);
    <span class="hljs-keyword">return</span> container;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to set the <code>idleEventInterval</code> for a <code>@KafkaListener</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConcurrentKafkaListenerContainerFactory <span class="hljs-title">kafkaListenerContainerFactory</span><span class="hljs-params">()</span> </span>{
    ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory =
                <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    ...
    factory.getContainerProperties().setIdleEventInterval(<span class="hljs-number">60000L</span>);
    ...
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>In each of these cases, an event is published once per minute while the container is idle.</p>
</div>
<div class="paragraph">
<p>In addition, if the broker is unreachable, the consumer <code>poll()</code> method does not exit, so no messages are received and idle events cannot be generated.
To solve this issue, the container publishes a <code>NonResponsiveConsumerEvent</code> if a poll does not return within <code>3x</code> the <code>pollTimeout</code> property.
By default, this check is performed once every 30 seconds in each container.
You can modify this behavior by setting the <code>monitorInterval</code> (default 30 seconds) and <code>noPollThreshold</code> (default 3.0) properties in the <code>ContainerProperties</code> when configuring the listener container.
The <code>noPollThreshold</code> should be greater than <code>1.0</code> to avoid getting spurious events due to a race condition.
Receiving such an event lets you stop the containers, thus waking the consumer so that it can terminate.</p>
</div>
<div class="sect5">
<h6 id="event-consumption"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#event-consumption"></a>Event Consumption</h6>
<div class="paragraph">
<p>You can capture these events by implementing <code>ApplicationListener</code> — either a general listener or one narrowed to only receive this specific event.
You can also use <code>@EventListener</code>, introduced in Spring Framework 4.2.</p>
</div>
<div class="paragraph">
<p>The next example combines <code>@KafkaListener</code> and <code>@EventListener</code> into a single class.
You should understand that the application listener gets events for all containers, so you may need to check the listener ID if you want to take specific action based on which container is idle.
You can also use the <code>@EventListener</code> <code>condition</code> for this purpose.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#events">Application Events</a> for information about event properties.</p>
</div>
<div class="paragraph">
<p>The event is normally published on the consumer thread, so it is safe to interact with the <code>Consumer</code> object.</p>
</div>
<div class="paragraph">
<p>The following example uses both <code>@KafkaListener</code> and <code>@EventListener</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml">public class Listener {

    @KafkaListener(id = "qux", topics = "annotated")
    public void listen4(@Payload String foo, Acknowledgment ack) {
        ...
    }

    @EventListener(condition = "event.listenerId.startsWith('qux-')")
    public void eventHandler(ListenerContainerIdleEvent event) {
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Event listeners see events for all containers.
Consequently, in the preceding example, we narrow the events received based on the listener ID.
Since containers created for the <code>@KafkaListener</code> support concurrency, the actual containers are named <code>id-n</code> where the <code>n</code> is a unique value for each instance to support the concurrency.
That is why we use <code>startsWith</code> in the condition.
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
If you wish to use the idle event to stop the lister container, you should not call <code>container.stop()</code> on the thread that calls the listener.
Doing so causes delays and unnecessary log messages.
Instead, you should hand off the event to a different thread that can then stop the container.
Also, you should not <code>stop()</code> the container instance if it is a child container.
You should stop the concurrent container instead.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect5">
<h6 id="current-positions-when-idle"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#current-positions-when-idle"></a>Current Positions when Idle</h6>
<div class="paragraph">
<p>Note that you can obtain the current positions when idle is detected by implementing <code>ConsumerSeekAware</code> in your listener.
See <code>onIdleContainer()</code> in `<a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek">Seeking to a Specific Offset</a>.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="topicpartition-initial-offset"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#topicpartition-initial-offset"></a>Topic/Partition Initial Offset</h5>
<div class="paragraph">
<p>There are several ways to set the initial offset for a partition.</p>
</div>
<div class="paragraph">
<p>When manually assigning partitions, you can set the initial offset (if desired) in the configured <code>TopicPartitionOffset</code> arguments (see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listener-container">Message Listener Containers</a>).
You can also seek to a specific offset at any time.</p>
</div>
<div class="paragraph">
<p>When you use group management where the broker assigns partitions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For a new <code>group.id</code>, the initial offset is determined by the <code>auto.offset.reset</code> consumer property (<code>earliest</code> or <code>latest</code>).</p>
</li>
<li>
<p>For an existing group ID, the initial offset is the current offset for that group ID.
You can, however, seek to a specific offset during initialization (or at any time thereafter).</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="seek"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek"></a>Seeking to a Specific Offset</h5>
<div class="paragraph">
<p>In order to seek, your listener must implement <code>ConsumerSeekAware</code>, which has the following methods:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">registerSeekCallback</span><span class="hljs-params">(ConsumerSeekCallback callback)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsAssigned</span><span class="hljs-params">(Map&lt;TopicPartition, Long&gt; assignments, ConsumerSeekCallback callback)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsRevoked</span><span class="hljs-params">(Collection&lt;TopicPartition&gt; partitions)</span>

<span class="hljs-keyword">void</span> <span class="hljs-title">onIdleContainer</span><span class="hljs-params">(Map&lt;TopicPartition, Long&gt; assignments, ConsumerSeekCallback callback)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>registerSeekCallback</code> is called when the container is started and whenever partitions are assigned.
You should use this callback when seeking at some arbitrary time after initialization.
You should save a reference to the callback.
If you use the same listener in multiple containers (or in a <code>ConcurrentMessageListenerContainer</code>), you should store the callback in a <code>ThreadLocal</code> or some other structure keyed by the listener <code>Thread</code>.</p>
</div>
<div class="paragraph">
<p>When using group management, <code>onPartitionsAssigned</code> is called when partitions are assigned.
You can use this method, for example, for setting initial offsets for the partitions, by calling the callback.
You can also use this method to associate this thread’s callback with the assigned partitions (see the example below).
You must use the callback argument, not the one passed into <code>registerSeekCallback</code>.
This method is never called if you explicitly assign partitions yourself.
Use the <code>TopicPartitionOffset</code> in that case.</p>
</div>
<div class="paragraph">
<p><code>onPartitionsRevoked</code> is called when the container is stopped or Kafka revokes assignments.
You should discard this thread’s callback and remove any associations to the revoked partitions.</p>
</div>
<div class="paragraph">
<p>The callback has the following methods:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seek</span><span class="hljs-params">(String topic, <span class="hljs-keyword">int</span> partition, <span class="hljs-keyword">long</span> offset)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekToBeginning</span><span class="hljs-params">(String topic, <span class="hljs-keyword">int</span> partition)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekToBeginning</span><span class="hljs-params">(Collection=&lt;TopicPartitions&gt; partitions)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekToEnd</span><span class="hljs-params">(String topic, <span class="hljs-keyword">int</span> partition)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekToEnd</span><span class="hljs-params">(Collection=&lt;TopicPartitions&gt; partitions)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekRelative</span><span class="hljs-params">(String topic, <span class="hljs-keyword">int</span> partition, <span class="hljs-keyword">long</span> offset, <span class="hljs-keyword">boolean</span> toCurrent)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekToTimestamp</span><span class="hljs-params">(String topic, <span class="hljs-keyword">int</span> partition, <span class="hljs-keyword">long</span> timestamp)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">seekToTimestamp</span><span class="hljs-params">(Collection&lt;TopicPartition&gt; topicPartitions, <span class="hljs-keyword">long</span> timestamp)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p><code>seekRelative</code> was added in version 2.3, to perform relative seeks.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>offset</code> negative and <code>toCurrent</code> <code>false</code> - seek relative to the end of the partition.</p>
</li>
<li>
<p><code>offset</code> positive and <code>toCurrent</code> <code>false</code> - seek relative to the beginning of the partition.</p>
</li>
<li>
<p><code>offset</code> negative and <code>toCurrent</code> <code>true</code> - seek relative to the current position (rewind).</p>
</li>
<li>
<p><code>offset</code> positive and <code>toCurrent</code> <code>true</code> - seek relative to the current position (fast forward).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The <code>seekToTimestamp</code> methods were also added in version 2.3.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
When seeking to the same timestamp for multiple partitions in the <code>onIdleContainer</code> or <code>onPartitionsAssigned</code> methods, the second method is preferred because it is more efficient to find the offsets for the timestamps in a single call to the consumer’s <code>offsetsForTimes</code> method.
When called from other locations, the container will gather all timestamp seek requests and make one call to <code>offsetsForTimes</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>You can also perform seek operations from <code>onIdleContainer()</code> when an idle container is detected.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#idle-containers">Detecting Idle and Non-Responsive Consumers</a> for how to enable idle container detection.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The <code>seekToBeginning</code> method that accepts a collection is useful, for example, when processing a compacted topic and you wish to seek to the beginning every time the application is started:
</td>
</tr>
</tbody></table>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyListener</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">AbstractConsumerSeekAware</span> </span>{

...

    <span class="hljs-meta">@Override</span>
	<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsAssigned</span><span class="hljs-params">(Map&lt;TopicPartition, Long&gt; assignments, ConsumerSeekCallback callback)</span> </span>{
		callback.seekToBeginning(assignments.keySet());
	}

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>To arbitrarily seek at runtime, use the callback reference from the <code>registerSeekCallback</code> for the appropriate thread.</p>
</div>
<div class="paragraph">
<p>Here is a trivial Spring Boot application that demonstrates how to use the callback; it sends 10 records to the topic; hitting <code>&lt;Enter&gt;</code> in the console causes all partitions to seek to the beginning.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SeekExampleApplication</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(SeekExampleApplication.class, args);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ApplicationRunner <span class="hljs-title">runner</span><span class="hljs-params">(Listener listener, KafkaTemplate&lt;String, String&gt; template)</span> </span>{
        <span class="hljs-keyword">return</span> args -&gt; {
            IntStream.range(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>).forEach(i -&gt; template.send(
                <span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(<span class="hljs-string">"seekExample"</span>, i % <span class="hljs-number">3</span>, <span class="hljs-string">"foo"</span>, <span class="hljs-string">"bar"</span>)));
            <span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) {
                System.in.read();
                listener.seekToStart();
            }
        };
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> NewTopic(<span class="hljs-string">"seekExample"</span>, <span class="hljs-number">3</span>, (<span class="hljs-keyword">short</span>) <span class="hljs-number">1</span>);
    }

}

<span class="hljs-meta">@Component</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Listener</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">ConsumerSeekAware</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> Logger logger = LoggerFactory.getLogger(Listener.class);

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ThreadLocal&lt;ConsumerSeekCallback&gt; callbackForThread = <span class="hljs-keyword">new</span> ThreadLocal&lt;&gt;();

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Map&lt;TopicPartition, ConsumerSeekCallback&gt; callbacks = <span class="hljs-keyword">new</span> ConcurrentHashMap&lt;&gt;();

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">registerSeekCallback</span><span class="hljs-params">(ConsumerSeekCallback callback)</span> </span>{
        <span class="hljs-keyword">this</span>.callbackForThread.set(callback);
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsAssigned</span><span class="hljs-params">(Map&lt;TopicPartition, Long&gt; assignments, ConsumerSeekCallback callback)</span> </span>{
        assignments.keySet().forEach(tp -&gt; <span class="hljs-keyword">this</span>.callbacks.put(tp, <span class="hljs-keyword">this</span>.callbackForThread.get()));
    }

    <span class="hljs-meta">@Override</span>
	<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onPartitionsRevoked</span><span class="hljs-params">(Collection&lt;TopicPartition&gt; partitions)</span> </span>{
		partitions.forEach(tp -&gt; <span class="hljs-keyword">this</span>.callbacks.remove(tp));
		<span class="hljs-keyword">this</span>.callbackForThread.remove();
	}

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onIdleContainer</span><span class="hljs-params">(Map&lt;TopicPartition, Long&gt; assignments, ConsumerSeekCallback callback)</span> </span>{
    }

    <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"seekExample"</span>, topics = <span class="hljs-string">"seekExample"</span>, concurrency = <span class="hljs-string">"3"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(ConsumerRecord&lt;String, String&gt; in)</span> </span>{
        logger.info(in.toString());
    }

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">seekToStart</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.callbacks.forEach((tp, callback) -&gt; callback.seekToBeginning(tp.topic(), tp.partition()));
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>To make things simpler, version 2.3 added the <code>AbstractConsumerSeekAware</code> class, which keeps track of which callback is to be used for a topic/partition.
The following example shows how to seek to the last record processed, in each partition, each time the container goes idle.
It also has methods that allow arbitrary external calls to rewind partitions by one record.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SeekToLastOnIdleListener</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">AbstractConsumerSeekAware</span> </span>{

    <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"seekOnIdle"</span>, topics = <span class="hljs-string">"seekOnIdle"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String in)</span> </span>{
        ...
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onIdleContainer</span><span class="hljs-params">(Map&lt;org.apache.kafka.common.TopicPartition, Long&gt; assignments,
            ConsumerSeekCallback callback)</span> </span>{

            assignments.keySet().forEach(tp -&gt; callback.seekRelative(tp.topic(), tp.partition(), -<span class="hljs-number">1</span>, <span class="hljs-keyword">true</span>));
    }

    <span class="hljs-comment">/**
    * Rewind all partitions one record.
    */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">rewindAllOneRecord</span><span class="hljs-params">()</span> </span>{
        getSeekCallbacks()
            .forEach((tp, callback) -&gt;
                callback.seekRelative(tp.topic(), tp.partition(), -<span class="hljs-number">1</span>, <span class="hljs-keyword">true</span>));
    }

    <span class="hljs-comment">/**
    * Rewind one partition one record.
    */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">rewindOnePartitionOneRecord</span><span class="hljs-params">(String topic, <span class="hljs-keyword">int</span> partition)</span> </span>{
        getSeekCallbackFor(<span class="hljs-keyword">new</span> org.apache.kafka.common.TopicPartition(topic, partition))
            .seekRelative(topic, partition, -<span class="hljs-number">1</span>, <span class="hljs-keyword">true</span>);
    }

}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="container-factory"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory"></a>Container factory</h5>
<div class="paragraph">
<p>As discussed in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-annotation"><code>@KafkaListener</code> Annotation</a>, a <code>ConcurrentKafkaListenerContainerFactory</code> is used to create containers for annotated methods.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2, you can use the same factory to create any <code>ConcurrentMessageListenerContainer</code>.
This might be useful if you want to create several containers with similar properties or you wish to use some externally configured factory, such as the one provided by Spring Boot auto-configuration.
Once the container is created, you can further modify its properties, many of which are set by using <code>container.getContainerProperties()</code>.
The following example configures a <code>ConcurrentMessageListenerContainer</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> ConcurrentMessageListenerContainer&lt;String, String&gt;(
        ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory) {

    ConcurrentMessageListenerContainer&lt;String, String&gt; container =
        factory.createContainer(<span class="hljs-string">"topic1"</span>, <span class="hljs-string">"topic2"</span>);
    container.setMessageListener(m -&gt; { ... } );
    <span class="hljs-keyword">return</span> container;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Containers created this way are not added to the endpoint registry.
They should be created as <code>@Bean</code> definitions so that they are registered with the application context.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 2.3.4, you can add a <code>ContainerCustomizer</code> to the factory to further configure each container after it has been created and configured.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KafkaListenerContainerFactory&lt;?, ?&gt; kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
            <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    ...
    factory.setContainerCustomizer(container -&gt; { <span class="hljs-comment">/* customize the container */</span> });
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="thread-safety"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#thread-safety"></a>Thread Safety</h5>
<div class="paragraph">
<p>When using a concurrent message listener container, a single listener instance is invoked on all consumer threads.
Listeners, therefore, need to be thread-safe, and it is preferable to use stateless listeners.
If it is not possible to make your listener thread-safe or adding synchronization would significantly reduce the benefit of adding concurrency, you can use one of a few techniques:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Use <code>n</code> containers with <code>concurrency=1</code> with a prototype scoped <code>MessageListener</code> bean so that each container gets its own instance (this is not possible when using <code>@KafkaListener</code>).</p>
</li>
<li>
<p>Keep the state in <code>ThreadLocal&lt;?&gt;</code> instances.</p>
</li>
<li>
<p>Have the singleton listener delegate to a bean that is declared in <code>SimpleThreadScope</code> (or a similar scope).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>To facilitate cleaning up thread state (for the second and third items in the preceding list), starting with version 2.2, the listener container publishes a <code>ConsumerStoppedEvent</code> when each thread exits.
You can consume these events with an <code>ApplicationListener</code> or <code>@EventListener</code> method to remove <code>ThreadLocal&lt;?&gt;</code> instances or <code>remove()</code> thread-scoped beans from the scope.
Note that <code>SimpleThreadScope</code> does not destroy beans that have a destruction interface (such as <code>DisposableBean</code>), so you should <code>destroy()</code> the instance yourself.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
By default, the application context’s event multicaster invokes event listeners on the calling thread.
If you change the multicaster to use an async executor, thread cleanup is not effective.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="micrometer"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#micrometer"></a>Monitoring Listener Performance</h5>
<div class="paragraph">
<p>Starting with version 2.3, the listener container will automatically create and update Micrometer <code>Timer</code> s for the listener, if <code>Micrometer</code> is detected on the class path, and a <code>MeterRegistry</code> is present in the application context.
The timers can be disabled by setting the <code>ContainerProperty</code> <code>micrometerEnabled</code> to <code>false</code>.</p>
</div>
<div class="paragraph">
<p>Two timers are maintained - one for successful calls to the listener and one for failures.</p>
</div>
<div class="paragraph">
<p>The timers are named <code>spring.kafka.listener</code> and have the following tags:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>name</code> : (container bean name)</p>
</li>
<li>
<p><code>result</code> : <code>success</code> or <code>failure</code></p>
</li>
<li>
<p><code>exception</code> : <code>none</code> or <code>ListenerExecutionFailedException</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can add additional tags using the <code>ContainerProperties</code> <code>micrometerTags</code> property.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
With the concurrent container, timers are created for each thread and the <code>name</code> tag is suffixed with <code>-n</code> where n is <code>0</code> to <code>concurrency-1</code>.
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="transactions"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions"></a>4.1.5. Transactions</h4>
<div class="paragraph">
<p>This section describes how Spring for Apache Kafka supports transactions.</p>
</div>
<div class="sect4">
<h5 id="overview-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-2"></a>Overview</h5>
<div class="paragraph">
<p>The 0.11.0.0 client library added support for transactions.
Spring for Apache Kafka adds support in the following ways:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>KafkaTransactionManager</code>: Used with normal Spring transaction support (<code>@Transactional</code>, <code>TransactionTemplate</code> etc).</p>
</li>
<li>
<p>Transactional <code>KafkaMessageListenerContainer</code></p>
</li>
<li>
<p>Local transactions with <code>KafkaTemplate</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Transactions are enabled by providing the <code>DefaultKafkaProducerFactory</code> with a <code>transactionIdPrefix</code>.
In that case, instead of managing a single shared <code>Producer</code>, the factory maintains a cache of transactional producers.
When the user calls <code>close()</code> on a producer, it is returned to the cache for reuse instead of actually being closed.
The <code>transactional.id</code> property of each producer is <code>transactionIdPrefix</code> + <code>n</code>, where <code>n</code> starts with <code>0</code> and is incremented for each new producer, unless the transaction is started by a listener container with a record-based listener.
In that case, the <code>transactional.id</code> is <code>&lt;transactionIdPrefix&gt;.&lt;group.id&gt;.&lt;topic&gt;.&lt;partition&gt;</code>.
This is to properly support fencing zombies, <a href="https://www.confluent.io/blog/transactions-apache-kafka/">as described here</a>.
This new behavior was added in versions 1.3.7, 2.0.6, 2.1.10, and 2.2.0.
If you wish to revert to the previous behavior, you can set the <code>producerPerConsumerPartition</code> property on the <code>DefaultKafkaProducerFactory</code> to <code>false</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
While transactions are supported with batch listeners, by default, zombie fencing is not supported because a batch may contain records from multiple topics or partitions.
However, starting with version 2.3.2, zombie fencing is supported if you set the container property <code>subBatchPerPartition</code> to true.
In that case, the batch listener is invoked once per partition received from the last poll, as if each poll only returned records for a single partition.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Also see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-id-prefix"><code>transactionIdPrefix</code></a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="using-kafkatransactionmanager"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-kafkatransactionmanager"></a>Using <code>KafkaTransactionManager</code></h5>
<div class="paragraph">
<p>The <code>KafkaTransactionManager</code> is an implementation of Spring Framework’s <code>PlatformTransactionManager</code>.
It is provided with a reference to the producer factory in its constructor.
If you provide a custom producer factory, it must support transactions.
See <code>ProducerFactory.transactionCapable()</code>.</p>
</div>
<div class="paragraph">
<p>You can use the <code>KafkaTransactionManager</code> with normal Spring transaction support (<code>@Transactional</code>, <code>TransactionTemplate</code>, and others).
If a transaction is active, any <code>KafkaTemplate</code> operations performed within the scope of the transaction use the transaction’s <code>Producer</code>.
The manager commits or rolls back the transaction, depending on success or failure.
You must configure the <code>KafkaTemplate</code> to use the same <code>ProducerFactory</code> as the transaction manager.</p>
</div>
</div>
<div class="sect4">
<h5 id="transactional-listener-container-and-exactly-once-processing"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactional-listener-container-and-exactly-once-processing"></a>Transactional Listener Container and Exactly Once Processing</h5>
<div class="paragraph">
<p>You can provide a listener container with a <code>KafkaAwareTransactionManager</code> instance.
When so configured, the container starts a transaction before invoking the listener.
Any <code>KafkaTemplate</code> operations performed by the listener participate in the transaction.
If the listener successfully processes the record (or multiple records, when using a <code>BatchMessageListener</code>), the container sends the offsets to the transaction by using <code>producer.sendOffsetsToTransaction()</code>), before the transaction manager commits the transaction.
If the listener throws an exception, the transaction is rolled back and the consumer is repositioned so that the rolled-back record(s) can be retrieved on the next poll.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback">After-rollback Processor</a> for more information and for handling records that repeatedly fail.</p>
</div>
</div>
<div class="sect4">
<h5 id="transaction-synchronization"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-synchronization"></a>Transaction Synchronization</h5>
<div class="paragraph">
<p>If you need to synchronize a Kafka transaction with some other transaction, configure the listener container with the appropriate transaction manager (one that supports synchronization, such as the <code>DataSourceTransactionManager</code>).
Any operations performed on a transactional <code>KafkaTemplate</code> from the listener participate in a single transaction.
The Kafka transaction is committed (or rolled back) immediately after the controlling transaction.
Before exiting the listener, you should invoke one of the template’s <code>sendOffsetsToTransaction</code> methods (unless you use a <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chained-transaction-manager"><code>ChainedKafkaTransactionManager</code></a>).
For convenience, the listener container binds its consumer group ID to the thread, so, generally, you can use the first method.
The following listing shows the two method signatures:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">sendOffsetsToTransaction</span><span class="hljs-params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span></span>;

<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">sendOffsetsToTransaction</span><span class="hljs-params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, String consumerGroupId)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to use the first signature of the <code>sendOffsetsToTransaction</code> method:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function">KafkaMessageListenerContainer <span class="hljs-title">container</span><span class="hljs-params">(ConsumerFactory&lt;String, String&gt; cf,
            <span class="hljs-keyword">final</span> KafkaTemplate template)</span> </span>{
    ContainerProperties props = <span class="hljs-keyword">new</span> ContainerProperties(<span class="hljs-string">"foo"</span>);
    props.setGroupId(<span class="hljs-string">"group"</span>);
    props.setTransactionManager(<span class="hljs-keyword">new</span> SomeOtherTransactionManager());
    ...
    props.setMessageListener((MessageListener&lt;String, String&gt;) m -&gt; {
        template.send(<span class="hljs-string">"foo"</span>, <span class="hljs-string">"bar"</span>);
        template.send(<span class="hljs-string">"baz"</span>, <span class="hljs-string">"qux"</span>);
        template.sendOffsetsToTransaction(
            Collections.singletonMap(<span class="hljs-keyword">new</span> TopicPartition(m.topic(), m.partition()),
                <span class="hljs-keyword">new</span> OffsetAndMetadata(m.offset() + <span class="hljs-number">1</span>)));
    });
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaMessageListenerContainer&lt;&gt;(cf, props);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The offset to be committed is one greater than the offset of the records processed by the listener.
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You should call this only when you use transaction synchronization.
When a listener container is configured to use a <code>KafkaTransactionManager</code> or <code>ChainedKafkaTransactionManager</code>, it takes care of sending the offsets to the transaction.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#ex-jdbc-sync">Example of Transaction Synchronization</a> for an example application that synchronizes JDBC and Kafka transactions.</p>
</div>
</div>
<div class="sect4">
<h5 id="chained-transaction-manager"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chained-transaction-manager"></a>Using <code>ChainedKafkaTransactionManager</code></h5>
<div class="paragraph">
<p>The <code>ChainedKafkaTransactionManager</code> was introduced in version 2.1.3.
This is a subclass of <code>ChainedTransactionManager</code> that can have exactly one <code>KafkaTransactionManager</code>.
Since it is a <code>KafkaAwareTransactionManager</code>, the container can send the offsets to the transaction in the same way as when the container is configured with a simple <code>KafkaTransactionManager</code>.
This provides another mechanism for synchronizing transactions without having to send the offsets to the transaction in the listener code.
You should chain your transaction managers in the desired order and provide the <code>ChainedTransactionManager</code> in the <code>ContainerProperties</code>.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#ex-jdbc-sync">Example of Transaction Synchronization</a> for an example application that synchronizes JDBC and Kafka transactions.</p>
</div>
</div>
<div class="sect4">
<h5 id="kafkatemplate-local-transactions"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkatemplate-local-transactions"></a><code>KafkaTemplate</code> Local Transactions</h5>
<div class="paragraph">
<p>You can use the <code>KafkaTemplate</code> to execute a series of operations within a local transaction.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">boolean</span> result = template.executeInTransaction(t -&gt; {
    t.sendDefault(<span class="hljs-string">"thing1"</span>, <span class="hljs-string">"thing2"</span>);
    t.sendDefault(<span class="hljs-string">"cat"</span>, <span class="hljs-string">"hat"</span>);
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;
});</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The argument in the callback is the template itself (<code>this</code>).
If the callback exits normally, the transaction is committed.
If an exception is thrown, the transaction is rolled back.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If there is a <code>KafkaTransactionManager</code> (or synchronized) transaction in process, it is not used.
Instead, a new "nested" transaction is used.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="transaction-id-prefix"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transaction-id-prefix"></a><code>transactionIdPrefix</code></h5>
<div class="paragraph">
<p>As mentioned in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions">the overview</a>, the producer factory is configured with this property to build the producer <code>transactional.id</code> property.
There is rather a dichotomy when specifying this property in that, when running multiple instances of the application, it must be the same on all instances to satisfy fencing zombies (also mentioned in the overview) when producing records on a listener container thread.
However, when producing records using transactions that are <strong>not</strong> started by a listener container, the prefix has to be different on each instance.
Version 2.3, makes this simpler to configure, especially in a Spring Boot application.
In previous versions, you had to create two producer factories and <code>KafkaTemplate</code> s - one for producing records on a listener container thread and one for stand-alone transactions started by <code>kafkaTemplate.executeInTransaction()</code> or by a transaction interceptor on a <code>@Transactional</code> method.</p>
</div>
<div class="paragraph">
<p>Now, you can override the factory’s <code>transactionalIdPrefix</code> on the <code>KafkaTemplate</code> and the <code>KafkaTransactionManager</code>.</p>
</div>
<div class="paragraph">
<p>When using a transaction manager and template for a listener container, you would normally leave this to default to the producer factory’s property.
This value should be the same for all application instances.
For transactions started by the template (or the transaction manager for <code>@Transaction</code>) you should set the property on the template and transaction manager respectively.
This property must have a different value on each application instance.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="interceptors"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#interceptors"></a>4.1.6. Wiring Spring Beans into Producer/Consumer Interceptors</h4>
<div class="paragraph">
<p>Apache Kafka provides a mechanism to add interceptors to producers and consumers.
These objects are managed by Kafka, not Spring, and so normal Spring dependency injection won’t work for wiring in dependent Spring Beans.
However, you can manually wire in those dependencies using the interceptor <code>config()</code> method.
The following Spring Boot application shows how to do this by overriding boot’s default factories to add some dependent bean into the configuration properties.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Application</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(Application.class, args);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-keyword">public</span> ConsumerFactory&lt;?, ?&gt; kafkaConsumerFactory(KafkaProperties properties, SomeBean someBean) {
        Map&lt;String, Object&gt; consumerProperties = properties.buildConsumerProperties();
        consumerProperties.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, MyConsumerInterceptor.class.getName());
        consumerProperties.put(<span class="hljs-string">"some.bean"</span>, someBean);
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerProperties);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-keyword">public</span> ProducerFactory&lt;?, ?&gt; kafkaProducerFactory(KafkaProperties properties, SomeBean someBean) {
        Map&lt;String, Object&gt; producerProperties = properties.buildProducerProperties();
        producerProperties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, MyProducerInterceptor.class.getName());
        producerProperties.put(<span class="hljs-string">"some.bean"</span>, someBean);
        DefaultKafkaProducerFactory&lt;?, ?&gt; factory = <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(producerProperties);
        String transactionIdPrefix = properties.getProducer()
                .getTransactionIdPrefix();
        <span class="hljs-keyword">if</span> (transactionIdPrefix != <span class="hljs-keyword">null</span>) {
            factory.setTransactionIdPrefix(transactionIdPrefix);
        }
        <span class="hljs-keyword">return</span> factory;
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> SomeBean <span class="hljs-title">someBean</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> SomeBean();
    }

    <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"kgk897"</span>, topics = <span class="hljs-string">"kgh897"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String in)</span> </span>{
        System.out.println(<span class="hljs-string">"Received "</span> + in);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ApplicationRunner <span class="hljs-title">runner</span><span class="hljs-params">(KafkaTemplate&lt;String, String&gt; template)</span> </span>{
        <span class="hljs-keyword">return</span> args -&gt; template.send(<span class="hljs-string">"kgh897"</span>, <span class="hljs-string">"test"</span>);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">kRequests</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"kgh897"</span>)
            .partitions(<span class="hljs-number">1</span>)
            .replicas(<span class="hljs-number">1</span>)
            .build();
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SomeBean</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">someMethod</span><span class="hljs-params">(String what)</span> </span>{
        System.out.println(what + <span class="hljs-string">" in my foo bean"</span>);
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyProducerInterceptor</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">ProducerInterceptor</span>&lt;<span class="hljs-title">String</span>, <span class="hljs-title">String</span>&gt; </span>{

    <span class="hljs-keyword">private</span> SomeBean bean;

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">configure</span><span class="hljs-params">(Map&lt;String, ?&gt; configs)</span> </span>{
        <span class="hljs-keyword">this</span>.bean = (SomeBean) configs.get(<span class="hljs-string">"some.bean"</span>);
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ProducerRecord&lt;String, String&gt; <span class="hljs-title">onSend</span><span class="hljs-params">(ProducerRecord&lt;String, String&gt; record)</span> </span>{
        <span class="hljs-keyword">this</span>.bean.someMethod(<span class="hljs-string">"producer interceptor"</span>);
        <span class="hljs-keyword">return</span> record;
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onAcknowledgement</span><span class="hljs-params">(RecordMetadata metadata, Exception exception)</span> </span>{
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> </span>{
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyConsumerInterceptor</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">ConsumerInterceptor</span>&lt;<span class="hljs-title">String</span>, <span class="hljs-title">String</span>&gt; </span>{

    <span class="hljs-keyword">private</span> SomeBean bean;

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">configure</span><span class="hljs-params">(Map&lt;String, ?&gt; configs)</span> </span>{
        <span class="hljs-keyword">this</span>.bean = (SomeBean) configs.get(<span class="hljs-string">"some.bean"</span>);
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerRecords&lt;String, String&gt; <span class="hljs-title">onConsume</span><span class="hljs-params">(ConsumerRecords&lt;String, String&gt; records)</span> </span>{
        <span class="hljs-keyword">this</span>.bean.someMethod(<span class="hljs-string">"consumer interceptor"</span>);
        <span class="hljs-keyword">return</span> records;
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onCommit</span><span class="hljs-params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span> </span>{
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">close</span><span class="hljs-params">()</span> </span>{
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Result:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="hljs bash">producer interceptor <span class="hljs-keyword">in</span> my foo bean
consumer interceptor <span class="hljs-keyword">in</span> my foo bean
Received <span class="hljs-built_in">test</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="pause-resume"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pause-resume"></a>4.1.7. Pausing and Resuming Listener Containers</h4>
<div class="paragraph">
<p>Version 2.1.3 added <code>pause()</code> and <code>resume()</code> methods to listener containers.
Previously, you could pause a consumer within a <code>ConsumerAwareMessageListener</code> and resume it by listening for a <code>ListenerContainerIdleEvent</code>, which provides access to the <code>Consumer</code> object.
While you could pause a consumer in an idle container byi using an event listener, in some cases, this was not thread-safe, since there is no guarantee that the event listener is invoked on the consumer thread.
To safely pause and resume consumers, you should use the <code>pause</code> and <code>resume</code> methods on the listener containers.
A <code>pause()</code> takes effect just before the next <code>poll()</code>; a <code>resume()</code> takes effect just after the current <code>poll()</code> returns.
When a container is paused, it continues to <code>poll()</code> the consumer, avoiding a rebalance if group management is being used, but it does not retrieve any records.
See the Kafka documentation for more information.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.1.5, you can call <code>isPauseRequested()</code> to see if <code>pause()</code> has been called.
However, the consumers might not have actually paused yet.
<code>isConsumerPaused()</code> returns true if all <code>Consumer</code> instances have actually paused.</p>
</div>
<div class="paragraph">
<p>In addition (also since 2.1.5), <code>ConsumerPausedEvent</code> and <code>ConsumerResumedEvent</code> instances are published with the container as the <code>source</code> property and the <code>TopicPartition</code> instances involved in the <code>partitions</code> property.</p>
</div>
<div class="paragraph">
<p>The following simple Spring Boot application demonstrates by using the container registry to get a reference to a <code>@KafkaListener</code> method’s container and pausing or resuming its consumers as well as receiving the corresponding events:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Application</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">ApplicationListener</span>&lt;<span class="hljs-title">KafkaEvent</span>&gt; </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(Application.class, args).close();
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onApplicationEvent</span><span class="hljs-params">(KafkaEvent event)</span> </span>{
        System.out.println(event);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ApplicationRunner <span class="hljs-title">runner</span><span class="hljs-params">(KafkaListenerEndpointRegistry registry,
            KafkaTemplate&lt;String, String&gt; template)</span> </span>{
        <span class="hljs-keyword">return</span> args -&gt; {
            template.send(<span class="hljs-string">"pause.resume.topic"</span>, <span class="hljs-string">"thing1"</span>);
            Thread.sleep(<span class="hljs-number">10_000</span>);
            System.out.println(<span class="hljs-string">"pausing"</span>);
            registry.getListenerContainer(<span class="hljs-string">"pause.resume"</span>).pause();
            Thread.sleep(<span class="hljs-number">10_000</span>);
            template.send(<span class="hljs-string">"pause.resume.topic"</span>, <span class="hljs-string">"thing2"</span>);
            Thread.sleep(<span class="hljs-number">10_000</span>);
            System.out.println(<span class="hljs-string">"resuming"</span>);
            registry.getListenerContainer(<span class="hljs-string">"pause.resume"</span>).resume();
            Thread.sleep(<span class="hljs-number">10_000</span>);
        };
    }

    <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"pause.resume"</span>, topics = <span class="hljs-string">"pause.resume.topic"</span>)
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String in)</span> </span>{
        System.out.println(in);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"pause.resume.topic"</span>)
            .partitions(<span class="hljs-number">2</span>)
            .replicas(<span class="hljs-number">1</span>)
            .build();
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following listing shows the results of the preceding example:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="hljs properties"><span class="hljs-attr">partitions</span> <span class="hljs-string">assigned: [pause.resume.topic-1, pause.resume.topic-0]</span>
<span class="hljs-attr">thing1</span>
<span class="hljs-attr">pausing</span>
<span class="hljs-attr">ConsumerPausedEvent</span> <span class="hljs-string">[partitions=[pause.resume.topic-1, pause.resume.topic-0]]</span>
<span class="hljs-attr">resuming</span>
<span class="hljs-attr">ConsumerResumedEvent</span> <span class="hljs-string">[partitions=[pause.resume.topic-1, pause.resume.topic-0]]</span>
<span class="hljs-attr">thing2</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="serdes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes"></a>4.1.8. Serialization, Deserialization, and Message Conversion</h4>
<div class="sect4">
<h5 id="overview-3"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-3"></a>Overview</h5>
<div class="paragraph">
<p>Apache Kafka provides a high-level API for serializing and deserializing record values as well as their keys.
It is present with the <code>org.apache.kafka.common.serialization.Serializer&lt;T&gt;</code> and
<code>org.apache.kafka.common.serialization.Deserializer&lt;T&gt;</code> abstractions with some built-in implementations.
Meanwhile, we can specify serializer and deserializer classes by using <code>Producer</code> or <code>Consumer</code> configuration properties.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class);
props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
...
props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class);
props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>For more complex or particular cases, the <code>KafkaConsumer</code> (and, therefore, <code>KafkaProducer</code>) provides overloaded
constructors to accept <code>Serializer</code> and <code>Deserializer</code> instances for <code>keys</code> and <code>values</code>, respectively.</p>
</div>
<div class="paragraph">
<p>When you use this API, the <code>DefaultKafkaProducerFactory</code> and <code>DefaultKafkaConsumerFactory</code> also provide properties (through constructors or setter methods) to inject custom <code>Serializer</code> and <code>Deserializer</code> instances into the target <code>Producer</code> or <code>Consumer</code>.
Also, you can pass in <code>Supplier&lt;Serializer&gt;</code> or <code>Supplier&lt;Deserializer&gt;</code> instances through constructors - these <code>Supplier</code> s are called on creation of each <code>Producer</code> or <code>Consumer</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="json"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json"></a>JSON</h5>
<div class="paragraph">
<p>Spring for Apache Kafka also provides <code>JsonSerializer</code> and <code>JsonDeserializer</code> implementations that are based on the
Jackson JSON object mapper.
The <code>JsonSerializer</code> allows writing any Java object as a JSON <code>byte[]</code>.
The <code>JsonDeserializer</code> requires an additional <code>Class&lt;?&gt; targetType</code> argument to allow the deserialization of a consumed <code>byte[]</code> to the proper target object.
The following example shows how to create a <code>JsonDeserializer</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">JsonDeserializer&lt;Thing&gt; thingDeserializer = <span class="hljs-keyword">new</span> JsonDeserializer&lt;&gt;(Thing.class);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You can customize both <code>JsonSerializer</code> and <code>JsonDeserializer</code> with an <code>ObjectMapper</code>.
You can also extend them to implement some particular configuration logic in the <code>configure(Map&lt;String, ?&gt; configs, boolean isKey)</code> method.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, all the JSON-aware components are configured by default with a <code>JacksonUtils.enhancedObjectMapper()</code> instance, which comes with the <code>MapperFeature.DEFAULT_VIEW_INCLUSION</code> and <code>DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES</code> features disabled.
Also such an instance is supplied with well-known modules for custom data types, such a Java time and Kotlin support.
See <code>JacksonUtils.enhancedObjectMapper()</code> JavaDocs for more information.
This method also registers a <code>org.springframework.kafka.support.JacksonMimeTypeModule</code> for <code>org.springframework.util.MimeType</code> objects serialization into the plain string for inter-platform compatibility over the network.
A <code>JacksonMimeTypeModule</code> can be registered as a bean in the application context and it will be auto-configured into <a href="https://docs.spring.io/spring-boot/docs/current/reference/html/howto-spring-mvc.html#howto-customize-the-jackson-objectmapper">Spring Boot <code>ObjectMapper</code> instance</a>.</p>
</div>
<div class="paragraph">
<p>Also starting with version 2.3, the <code>JsonDeserializer</code> provides <code>TypeReference</code>-based constructors for better handling of target generic container types.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.1, you can convey type information in record <code>Headers</code>, allowing the handling of multiple types.
In addition, you can configure the serializer and deserializer by using the following Kafka properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>JsonSerializer.ADD_TYPE_INFO_HEADERS</code> (default <code>true</code>): You can set it to <code>false</code> to disable this feature on the <code>JsonSerializer</code> (sets the <code>addTypeInfo</code> property).</p>
</li>
<li>
<p><code>JsonSerializer.TYPE_MAPPINGS</code> (default <code>empty</code>): See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes-mapping-types">Mapping Types</a>.</p>
</li>
<li>
<p><code>JsonDeserializer.USE_TYPE_INFO_HEADERS</code> (default <code>true</code>): You can set it to <code>false</code> to ignore headers set by the serializer.</p>
</li>
<li>
<p><code>JsonDeserializer.REMOVE_TYPE_INFO_HEADERS</code> (default <code>true</code>): You can set it to <code>false</code> to retain headers set by the serializer.</p>
</li>
<li>
<p><code>JsonDeserializer.KEY_DEFAULT_TYPE</code>: Fallback type for deserialization of keys if no header information is present.</p>
</li>
<li>
<p><code>JsonDeserializer.VALUE_DEFAULT_TYPE</code>: Fallback type for deserialization of values if no header information is present.</p>
</li>
<li>
<p><code>JsonDeserializer.TRUSTED_PACKAGES</code> (default <code>java.util</code>, <code>java.lang</code>): Comma-delimited list of package patterns allowed for deserialization.
<code>*</code> means deserialize all.</p>
</li>
<li>
<p><code>JsonDeserializer.TYPE_MAPPINGS</code> (default <code>empty</code>): See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes-mapping-types">Mapping Types</a>.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Starting with version 2.2, the type information headers (if added by the serializer) are removed by the deserializer.
You can revert to the previous behavior by setting the <code>removeTypeHeaders</code> property to <code>false</code>, either directly on the deserializer or with the configuration property described earlier.</p>
</div>
<div class="paragraph">
<p>When constructing the serializer/deserializer programmatically for use in the producer/consumer factory, since version 2.3, you can use the fluent API, which simplifies configuration.</p>
</div>
<div class="paragraph">
<p>The following example assumes you are using Spring Boot:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> DefaultKafkaProducerFactory <span class="hljs-title">pf</span><span class="hljs-params">(KafkaProperties properties)</span> </span>{
    Map&lt;String, Object&gt; props = properties.buildProducerProperties();
    DefaultKafkaProducerFactory pf = <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory(props,
        <span class="hljs-keyword">new</span> JsonSerializer&lt;&gt;(MyKeyType.class)
            .forKeys()
            .noTypeInfo(),
        <span class="hljs-keyword">new</span> JsonSerializer&lt;&gt;(MyValueType.class)
            .noTypeInfo());
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> DefaultKafkaConsumerFactory <span class="hljs-title">pf</span><span class="hljs-params">(KafkaProperties properties)</span> </span>{
    Map&lt;String, Object&gt; props = properties.buildConsumerProperties();
    DefaultKafkaConsumerFactory pf = <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory(props,
        <span class="hljs-keyword">new</span> JsonDeserializer&lt;&gt;(MyKeyType.class)
            .forKeys()
            .ignoreTypeHeaders(),
        <span class="hljs-keyword">new</span> JsonSerializer&lt;&gt;(MyValueType.class)
            .ignoreTypeHeaders());
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="serdes-mapping-types"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes-mapping-types"></a>Mapping Types</h5>
<div class="paragraph">
<p>Starting with version 2.2, when using JSON, you can now provide type mappings by using the properties in the preceding list.
Previously, you had to customize the type mapper within the serializer and deserializer.
Mappings consist of a comma-delimited list of <code>token:className</code> pairs.
On outbound, the payload’s class name is mapped to the corresponding token.
On inbound, the token in the type header is mapped to the corresponding class name.</p>
</div>
<div class="paragraph">
<p>The following example creates a set of mappings:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">senderProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
senderProps.put(JsonSerializer.TYPE_MAPPINGS, <span class="hljs-string">"cat:com.mycat.Cat, hat:com.myhat.hat"</span>);
...
consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class);
consumerProps.put(JsonDeSerializer.TYPE_MAPPINGS, <span class="hljs-string">"cat:com.yourcat.Cat, hat:com.yourhat.hat"</span>);</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The corresponding objects must be compatible.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>If you use <a href="https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-messaging.html#boot-features-kafka">Spring Boot</a>, you can provide these properties in the <code>application.properties</code> (or yaml) file.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="hljs groovy">spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.properties.spring.json.type.mapping=<span class="hljs-string">cat:</span>com.mycat.Cat,<span class="hljs-string">hat:</span>com.myhat.Hat</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You can perform only simple configuration with properties.
For more advanced configuration (such as using a custom <code>ObjectMapper</code> in the serializer and deserializer), you should use the producer and consumer factory constructors that accept a pre-built serializer and deserializer.
The following Spring Boot example overrides the default factories:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerFactory&lt;Foo, Bar&gt; <span class="hljs-title">kafkaConsumerFactory</span><span class="hljs-params">(KafkaProperties properties,
    JsonDeserializer customDeserializer)</span> </span>{

    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(properties.buildConsumerProperties(),
        customDeserializer, customDeserializer);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ProducerFactory&lt;Foo, Bar&gt; <span class="hljs-title">kafkaProducerFactory</span><span class="hljs-params">(KafkaProperties properties,
    JsonSerializer customSerializer)</span> </span>{

    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(properties.buildProducerProperties(),
        customSerializer, customSerializer);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Setters are also provided, as an alternative to using these constructors.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 2.2, you can explicitly configure the deserializer to use the supplied target type and ignore type information in headers by using one of the overloaded constructors that have a boolean <code>useHeadersIfPresent</code> (which is <code>true</code> by default).
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">DefaultKafkaConsumerFactory&lt;Integer, Cat1&gt; cf = <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(props,
        <span class="hljs-keyword">new</span> IntegerDeserializer(), <span class="hljs-keyword">new</span> JsonDeserializer&lt;&gt;(Cat1.class, <span class="hljs-keyword">false</span>));</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="delegating-serialization"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#delegating-serialization"></a>Delegating Serializer and Deserializer</h5>
<div class="paragraph">
<p>Version 2.3 introduced the <code>DelegatingSerializer</code> and <code>DelegatingDeserializer</code>, which allow producing and consuming records with different key and/or value types.
Producers must set a header <code>DelegatingSerializer.SERIALIZATION_SELECTOR</code> to a selector value that is used to select which serializer to use; if a match is not found, an <code>IllegalStateException</code> is thrown.</p>
</div>
<div class="paragraph">
<p>For incoming records, the deserializer uses the same header to select the deserializer to use; if a match is not found or the header is not present, the raw <code>byte[]</code> is returned.</p>
</div>
<div class="paragraph">
<p>You can configure the map of selector to <code>Serializer</code> / <code>Deserializer</code> via a constructor, or you can configure it via Kafka producer/consumer properties with the key <code>DelegatingSerializer.SERIALIZATION_SELECTOR_CONFIG</code>.
For the serializer, the producer property can be a <code>Map&lt;String, Object&gt;</code> where the key is the selector and the value is a <code>Serializer</code> instance, a serializer <code>Class</code> or the class name.
The property can also be a String of comma-delimited map entries, as shown below.</p>
</div>
<div class="paragraph">
<p>For the deserializer, the consumer property can be a <code>Map&lt;String, Object&gt;</code> where the key is the selector and the value is a <code>Deserializer</code> instance, a deserializer <code>Class</code> or the class name.
The property can also be a String of comma-delimited map entries, as shown below.</p>
</div>
<div class="paragraph">
<p>To configure using properties, use the following syntax:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">producerProps.put(DelegatingSerializer.SERIALIZATION_SELECTOR_CONFIG,
    <span class="hljs-string">"thing1:com.example.MyThing1Serializer, thing2:com.example.MyThing2Serializer"</span>)

consumerProps.put(DelegatingDeserializer.SERIALIZATION_SELECTOR_CONFIG,
    <span class="hljs-string">"thing1:com.example.MyThing1Deserializer, thing2:com.example.MyThing2Deserializer"</span>)</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Producers would then set the <code>DelegatingSerializer.SERIALIZATION_SELECTOR</code> header to <code>thing1</code> or <code>thing2</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="retrying-deserialization"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#retrying-deserialization"></a>Retrying Deserializer</h5>
<div class="paragraph">
<p>The <code>RetryingDeserializer</code> uses a delegate <code>Deserializer</code> and <code>RetryTemplate</code> to retry deserialization when the delegate might have transient errors, such a network issues, during deserialization.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">ConsumerFactory cf = <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory(myConsumerConfigs,
    <span class="hljs-keyword">new</span> RetryingDeserializer(myUnreliableKeyDeserializer, retryTemplate),
    <span class="hljs-keyword">new</span> RetryingDeserializer(myUnreliableValueDeserializer, retryTemplate));</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Refer to the <a href="https://github.com/spring-projects/spring-retry">spring-retry</a> project for configuration of the <code>RetryTemplate</code> with a retry policy, back off policy, etc.</p>
</div>
</div>
<div class="sect4">
<h5 id="messaging-message-conversion"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#messaging-message-conversion"></a>Spring Messaging Message Conversion</h5>
<div class="paragraph">
<p>Although the <code>Serializer</code> and <code>Deserializer</code> API is quite simple and flexible from the low-level Kafka <code>Consumer</code> and <code>Producer</code> perspective, you might need more flexibility at the Spring Messaging level, when using either <code>@KafkaListener</code> or <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-kafka">Spring Integration</a>.
To let you easily convert to and from <code>org.springframework.messaging.Message</code>, Spring for Apache Kafka provides a <code>MessageConverter</code> abstraction with the <code>MessagingMessageConverter</code> implementation and its <code>JsonMessageConverter</code> (and subclasses) customization.
You can inject the <code>MessageConverter</code> into a <code>KafkaTemplate</code> instance directly and by using <code>AbstractKafkaListenerContainerFactory</code> bean definition for the <code>@KafkaListener.containerFactory()</code> property.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KafkaListenerContainerFactory&lt;?, ?&gt; kafkaJsonListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
        <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    factory.setConsumerFactory(consumerFactory());
    factory.setMessageConverter(<span class="hljs-keyword">new</span> JsonMessageConverter());
    <span class="hljs-keyword">return</span> factory;
}
...
<span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"jsonData"</span>,
                containerFactory = <span class="hljs-string">"kafkaJsonListenerContainerFactory"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">jsonListener</span><span class="hljs-params">(Cat cat)</span> </span>{
...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When you use a <code>@KafkaListener</code>, the parameter type is provided to the message converter to assist with the conversion.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This type inference can be achieved only when the <code>@KafkaListener</code> annotation is declared at the method level.
With a class-level <code>@KafkaListener</code>, the payload type is used to select which <code>@KafkaHandler</code> method to invoke, so it must already have been converted before the method can be chosen.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>On the consumer side, you can configure a <code>JsonMessageConverter</code>; it can handle <code>ConsumerRecord</code> values of type <code>byte[]</code>, <code>Bytes</code> and <code>String</code> so should be used in conjunction with a <code>ByteArrayDeserializer</code>, <code>BytesDeserializer</code> or <code>StringDeserializer</code>.
(<code>byte[]</code> and <code>Bytes</code> are more efficient because they avoid an unnecessary <code>byte[]</code> to <code>String</code> conversion).
You can also configure the specific subclass of <code>JsonMessageConverter</code> corresponding to the deserializer, if you so wish.</p>
</div>
<div class="paragraph">
<p>On the producer side, when you use Spring Integration or the <code>KafkaTemplate.send(Message&lt;?&gt; message)</code> method (see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template">Using <code>KafkaTemplate</code></a>), you must configure a message converter that is compatible with the configured Kafka <code>Serializer</code>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>StringJsonMessageConverter</code> with <code>StringSerializer</code></p>
</li>
<li>
<p><code>BytesJsonMessageConverter</code> with <code>BytesSerializer</code></p>
</li>
<li>
<p><code>ByteArrayJsonMessageConverter</code> with <code>ByteArraySerializer</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Again, using <code>byte[]</code> or <code>Bytes</code> is more efficient because they avoid a <code>String</code> to <code>byte[]</code> conversion.</p>
</div>
<div class="paragraph">
<p>For convenience, starting with version 2.3, the framework also provides a <code>StringOrBytesSerializer</code> which can serialize all three value types so it can be used with any of the message converters.</p>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="sect5">
<h6 id="data-projection"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#data-projection"></a>Using Spring Data Projection Interfaces</h6>
<div class="paragraph">
<p>Starting with version 2.1.1, you can convert JSON to a Spring Data Projection interface instead of a concrete type.
This allows very selective, and low-coupled bindings to data, including the lookup of values from multiple places inside the JSON document.
For example the following interface can be defined as message payload type:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">SomeSample</span> </span>{

  <span class="hljs-meta">@JsonPath</span>({ <span class="hljs-string">"$.username"</span>, <span class="hljs-string">"$.user.name"</span> })
  <span class="hljs-function">String <span class="hljs-title">getUsername</span><span class="hljs-params">()</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id=<span class="hljs-string">"projection.listener"</span>, topics = <span class="hljs-string">"projection"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">projection</span><span class="hljs-params">(SomeSample in)</span> </span>{
    String username = in.getUsername();
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Accessor methods will be used to lookup the property name as field in the received JSON document by default.
The <code>@JsonPath</code> expression allows customization of the value lookup, and even to define multiple JSON Path expressions, to lookup values from multiple places until an expression returns an actual value.</p>
</div>
<div class="paragraph">
<p>To enable this feature, use a <code>ProjectingMessageConverter</code> configured with an appropriate delegate converter (used for outbound conversion and converting non-projection interfaces).
You must also add <code>spring-data:spring-data-commons</code> and <code>com.jayway.jsonpath:json-path</code> to the class path.</p>
</div>
<div class="paragraph">
<p>When used as the parameter to a <code>@KafkaListener</code> method, the interface type is automatically passed to the converter as normal.</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="error-handling-deserializer"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handling-deserializer"></a>Using <code>ErrorHandlingDeserializer</code></h5>
<div class="paragraph">
<p>When a deserializer fails to deserialize a message, Spring has no way to handle the problem, because it occurs before the <code>poll()</code> returns.
To solve this problem, version 2.2 introduced the <code>ErrorHandlingDeserializer2</code>.
This deserializer delegates to a real deserializer (key or value).
If the delegate fails to deserialize the record content, the <code>ErrorHandlingDeserializer2</code> returns a <code>null</code> value and a <code>DeserializationException</code> in a header that contains the cause and the raw bytes.
When you use a record-level <code>MessageListener</code>, if the <code>ConsumerRecord</code> contains a <code>DeserializationException</code> header for either the key or value, the container’s <code>ErrorHandler</code> is called with the failed <code>ConsumerRecord</code>.
The record is not passed to the listener.</p>
</div>
<div class="paragraph">
<p>Alternatively, you can configure the <code>ErrorHandlingDeserializer2</code> to create a custom value by providing a <code>failedDeserializationFunction</code>, which is a <code>Function&lt;FailedDeserializationInfo, T&gt;</code>.
This function is invoked to create an instance of <code>T</code>, which is passed to the listener in the usual fashion.
An object of type <code>FailedDeserializationInfo</code>, which contains all the contextual information is provided to the function.
You can find the <code>DeserializationException</code> (as a serialized Java object) in headers.
See the <a href="https://docs.spring.io/spring-kafka/api/org/springframework/kafka/support/serializer/ErrorHandlingDeserializer2.html">Javadoc</a> for the <code>ErrorHandlingDeserializer2</code> for more information.</p>
</div>
<div class="admonitionblock caution">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
When you use a <code>BatchMessageListener</code>, you must provide a <code>failedDeserializationFunction</code>.
Otherwise, the batch of records are not type safe.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>You can use the <code>DefaultKafkaConsumerFactory</code> constructor that takes key and value <code>Deserializer</code> objects and wire in appropriate <code>ErrorHandlingDeserializer2</code> instances that you have configured with the proper delegates.
Alternatively, you can use consumer configuration properties (which are used by the <code>ErrorHandlingDeserializer</code>) to instantiate the delegates.
The property names are <code>ErrorHandlingDeserializer2.KEY_DESERIALIZER_CLASS</code> and <code>ErrorHandlingDeserializer2.VALUE_DESERIALIZER_CLASS</code>.
The property value can be a class or class name.
The following example shows how to set these properties:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">... <span class="hljs-comment">// other props</span>
props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer2.class);
props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer2.class);
props.put(ErrorHandlingDeserializer.KEY_DESERIALIZER_CLASS, JsonDeserializer.class);
props.put(JsonDeserializer.KEY_DEFAULT_TYPE, <span class="hljs-string">"com.example.MyKey"</span>)
props.put(ErrorHandlingDeserializer.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class.getName());
props.put(JsonDeserializer.VALUE_DEFAULT_TYPE, <span class="hljs-string">"com.example.MyValue"</span>)
props.put(JsonDeserializer.TRUSTED_PACKAGES, <span class="hljs-string">"com.example"</span>)
<span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(props);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example uses a <code>failedDeserializationFunction</code>.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BadFoo</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Foo</span> </span>{

  <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> FailedDeserializationInfo failedDeserializationInfo;

  <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">BadFoo</span><span class="hljs-params">(FailedDeserializationInfo failedDeserializationInfo)</span> </span>{
    <span class="hljs-keyword">this</span>.failedDeserializationInfo = failedDeserializationInfo;
  }

  <span class="hljs-function"><span class="hljs-keyword">public</span> FailedDeserializationInfo <span class="hljs-title">getFailedDeserializationInfo</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.failedDeserializationInfo;
  }

}

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FailedFooProvider</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Function</span>&lt;<span class="hljs-title">FailedDeserializationInfo</span>, <span class="hljs-title">Foo</span>&gt; </span>{

  <span class="hljs-meta">@Override</span>
  <span class="hljs-function"><span class="hljs-keyword">public</span> Foo <span class="hljs-title">apply</span><span class="hljs-params">(FailedDeserializationInfo info)</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> BadFoo(info);
  }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The preceding example uses the following configuration:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">...
consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ErrorHandlingDeserializer2.class);
consumerProps.put(ErrorHandlingDeserializer2.VALUE_DESERIALIZER_CLASS, JsonDeserializer.class);
consumerProps.put(ErrorHandlingDeserializer2.VALUE_FUNCTION, FailedFooProvider.class);
...</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="payload-conversion-with-batch"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#payload-conversion-with-batch"></a>Payload Conversion with Batch Listeners</h5>
<div class="paragraph">
<p>You can also use a <code>JsonMessageConverter</code> within a <code>BatchMessagingMessageConverter</code> to convert batch messages when you use a batch listener container factory.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a> and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-conversion">Message Conversion</a> for more information.</p>
</div>
<div class="paragraph">
<p>By default, the type for the conversion is inferred from the listener argument.
If you configure the <code>JsonMessageConverter</code> with a <code>DefaultJackson2TypeMapper</code> that has its <code>TypePrecedence</code> set to <code>TYPE_ID</code> (instead of the default <code>INFERRED</code>), the converter uses the type information in headers (if present) instead.
This allows, for example, listener methods to be declared with interfaces instead of concrete classes.
Also, the type converter supports mapping, so the deserialization can be to a different type than the source (as long as the data is compatible).
This is also useful when you use <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-level-kafkalistener">class-level <code>@KafkaListener</code> instances</a> where the payload must have already been converted to determine which method to invoke.
The following example creates beans that use this method:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KafkaListenerContainerFactory&lt;?, ?&gt; kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
            <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    factory.setConsumerFactory(consumerFactory());
    factory.setBatchListener(<span class="hljs-keyword">true</span>);
    factory.setMessageConverter(<span class="hljs-keyword">new</span> BatchMessagingMessageConverter(converter()));
    <span class="hljs-keyword">return</span> factory;
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> JsonMessageConverter <span class="hljs-title">converter</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> JsonMessageConverter();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that, for this to work, the method signature for the conversion target must be a container object with a single generic parameter type, such as the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"blc1"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(List&lt;Foo&gt; foos, @Header(KafkaHeaders.OFFSET)</span> List&lt;Long&gt; offsets) </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that you can still access the batch headers.</p>
</div>
<div class="paragraph">
<p>If the batch converter has a record converter that supports it, you can also receive a list of messages where the payloads are converted according to the generic type.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(topics = <span class="hljs-string">"blc3"</span>, groupId = <span class="hljs-string">"blc3"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen1</span><span class="hljs-params">(List&lt;Message&lt;Foo&gt;&gt; fooMessages)</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="conversionservice-customization"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#conversionservice-customization"></a><code>ConversionService</code> Customization</h5>
<div class="paragraph">
<p>Starting with version 2.1.1, the <code>org.springframework.core.convert.ConversionService</code> used by the default <code>o.s.messaging.handler.annotation.support.MessageHandlerMethodFactory</code> to resolve parameters for the invocation of a listener method is supplied with all beans that implement any of the following interfaces:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>org.springframework.core.convert.converter.Converter</code></p>
</li>
<li>
<p><code>org.springframework.core.convert.converter.GenericConverter</code></p>
</li>
<li>
<p><code>org.springframework.format.Formatter</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This lets you further customize listener deserialization without changing the default configuration for <code>ConsumerFactory</code> and <code>KafkaListenerContainerFactory</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Setting a custom <code>MessageHandlerMethodFactory</code> on the <code>KafkaListenerEndpointRegistrar</code> through a <code>KafkaListenerConfigurer</code> bean disables this feature.
</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="headers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#headers"></a>4.1.9. Message Headers</h4>
<div class="paragraph">
<p>The 0.11.0.0 client introduced support for headers in messages.
As of version 2.0, Spring for Apache Kafka now supports mapping these headers to and from <code>spring-messaging</code> <code>MessageHeaders</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Previous versions mapped <code>ConsumerRecord</code> and <code>ProducerRecord</code> to spring-messaging <code>Message&lt;?&gt;</code>, where the value property is mapped to and from the <code>payload</code> and other properties (<code>topic</code>, <code>partition</code>, and so on) were mapped to headers.
This is still the case, but additional (arbitrary) headers can now be mapped.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Apache Kafka headers have a simple API, shown in the following interface definition:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">Header</span> </span>{

    <span class="hljs-function">String <span class="hljs-title">key</span><span class="hljs-params">()</span></span>;

    <span class="hljs-keyword">byte</span>[] value();

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>KafkaHeaderMapper</code> strategy is provided to map header entries between Kafka <code>Headers</code> and <code>MessageHeaders</code>.
Its interface definition is as follows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">KafkaHeaderMapper</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">fromHeaders</span><span class="hljs-params">(MessageHeaders headers, Headers target)</span></span>;

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">toHeaders</span><span class="hljs-params">(Headers source, Map&lt;String, Object&gt; target)</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>DefaultKafkaHeaderMapper</code> maps the key to the <code>MessageHeaders</code> header name and, in order to support rich header types for outbound messages, JSON conversion is performed.
A “special” header (with a key of <code>spring_json_header_types</code>) contains a JSON map of <code>&lt;key&gt;:&lt;type&gt;</code>.
This header is used on the inbound side to provide appropriate conversion of each header value to the original type.</p>
</div>
<div class="paragraph">
<p>On the inbound side, all Kafka <code>Header</code> instances are mapped to <code>MessageHeaders</code>.
On the outbound side, by default, all <code>MessageHeaders</code> are mapped, except <code>id</code>, <code>timestamp</code>, and the headers that map to <code>ConsumerRecord</code> properties.</p>
</div>
<div class="paragraph">
<p>You can specify which headers are to be mapped for outbound messages, by providing patterns to the mapper.
The following listing shows a number of example mappings:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">DefaultKafkaHeaderMapper</span><span class="hljs-params">()</span> </span>{ <i class="conum" data-value="1"></i><b>(<span class="hljs-number">1</span>)</b>
    ...
}

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">DefaultKafkaHeaderMapper</span><span class="hljs-params">(ObjectMapper objectMapper)</span> </span>{ <i class="conum" data-value="2"></i><b>(<span class="hljs-number">2</span>)</b>
    ...
}

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">DefaultKafkaHeaderMapper</span><span class="hljs-params">(String... patterns)</span> </span>{ <i class="conum" data-value="3"></i><b>(<span class="hljs-number">3</span>)</b>
    ...
}

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">DefaultKafkaHeaderMapper</span><span class="hljs-params">(ObjectMapper objectMapper, String... patterns)</span> </span>{ <i class="conum" data-value="4"></i><b>(<span class="hljs-number">4</span>)</b>
    ...
}</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tbody><tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>Uses a default Jackson <code>ObjectMapper</code> and maps most headers, as discussed before the example.</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>Uses the provided Jackson <code>ObjectMapper</code> and maps most headers, as discussed before the example.</td>
</tr>
<tr>
<td><i class="conum" data-value="3"></i><b>3</b></td>
<td>Uses a default Jackson <code>ObjectMapper</code> and maps headers according to the provided patterns.</td>
</tr>
<tr>
<td><i class="conum" data-value="4"></i><b>4</b></td>
<td>Uses the provided Jackson <code>ObjectMapper</code> and maps headers according to the provided patterns.</td>
</tr>
</tbody></table>
</div>
</div>
</div>
<div class="paragraph">
<p>Patterns are rather simple and can contain a leading wildcard (<code><strong></strong></code><strong>), a trailing wildcard, or both (for example, <code></code></strong><code>.cat.*</code>).
You can negate patterns with a leading <code>!</code>.
The first pattern that matches a header name (whether positive or negative) wins.</p>
</div>
<div class="paragraph">
<p>When you provide your own patterns, we recommend including <code>!id</code> and <code>!timestamp</code>, since these headers are read-only on the inbound side.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
By default, the mapper deserializes only classes in <code>java.lang</code> and <code>java.util</code>.
You can trust other (or all) packages by adding trusted packages with the <code>addTrustedPackages</code> method.
If you receive messages from untrusted sources, you may wish to add only those packages you trust.
To trust all packages, you can use <code>mapper.addTrustedPackages("*")</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Mapping <code>String</code> header values in a raw form is useful when communicating with systems that are not aware of the mapper’s JSON format.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 2.2.5, you can specify that certain string-valued headers should not be mapped using JSON, but to/from a raw <code>byte[]</code>.
The <code>AbstractKafkaHeaderMapper</code> has new properties; <code>mapAllStringsOut</code> when set to true, all string-valued headers will be converted to <code>byte[]</code> using the <code>charset</code> property (default <code>UTF-8</code>).
In addition, there is a property <code>rawMappedHeaders</code>, which is a map of <code>header name : boolean</code>; if the map contains a header name, and the header contains a <code>String</code> value, it will be mapped as a raw <code>byte[]</code> using the charset.
This map is also used to map raw incoming <code>byte[]</code> headers to <code>String</code> using the charset if, and only if, the boolean in the map value is <code>true</code>.
If the boolean is <code>false</code>, or the header name is not in the map with a <code>true</code> value, the incoming header is simply mapped as the raw unmapped header.</p>
</div>
<div class="paragraph">
<p>The following test case illustrates this mechanism.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Test</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testSpecificStringConvert</span><span class="hljs-params">()</span> </span>{
    DefaultKafkaHeaderMapper mapper = <span class="hljs-keyword">new</span> DefaultKafkaHeaderMapper();
    Map&lt;String, Boolean&gt; rawMappedHeaders = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    rawMappedHeaders.put(<span class="hljs-string">"thisOnesAString"</span>, <span class="hljs-keyword">true</span>);
    rawMappedHeaders.put(<span class="hljs-string">"thisOnesBytes"</span>, <span class="hljs-keyword">false</span>);
    mapper.setRawMappedHeaders(rawMappedHeaders);
    Map&lt;String, Object&gt; headersMap = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    headersMap.put(<span class="hljs-string">"thisOnesAString"</span>, <span class="hljs-string">"thing1"</span>);
    headersMap.put(<span class="hljs-string">"thisOnesBytes"</span>, <span class="hljs-string">"thing2"</span>);
    headersMap.put(<span class="hljs-string">"alwaysRaw"</span>, <span class="hljs-string">"thing3"</span>.getBytes());
    MessageHeaders headers = <span class="hljs-keyword">new</span> MessageHeaders(headersMap);
    Headers target = <span class="hljs-keyword">new</span> RecordHeaders();
    mapper.fromHeaders(headers, target);
    assertThat(target).containsExactlyInAnyOrder(
            <span class="hljs-keyword">new</span> RecordHeader(<span class="hljs-string">"thisOnesAString"</span>, <span class="hljs-string">"thing1"</span>.getBytes()),
            <span class="hljs-keyword">new</span> RecordHeader(<span class="hljs-string">"thisOnesBytes"</span>, <span class="hljs-string">"thing2"</span>.getBytes()),
            <span class="hljs-keyword">new</span> RecordHeader(<span class="hljs-string">"alwaysRaw"</span>, <span class="hljs-string">"thing3"</span>.getBytes()));
    headersMap.clear();
    mapper.toHeaders(target, headersMap);
    assertThat(headersMap).contains(
            entry(<span class="hljs-string">"thisOnesAString"</span>, <span class="hljs-string">"thing1"</span>),
            entry(<span class="hljs-string">"thisOnesBytes"</span>, <span class="hljs-string">"thing2"</span>.getBytes()),
            entry(<span class="hljs-string">"alwaysRaw"</span>, <span class="hljs-string">"thing3"</span>.getBytes()));
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>By default, the <code>DefaultKafkaHeaderMapper</code> is used in the <code>MessagingMessageConverter</code> and <code>BatchMessagingMessageConverter</code>, as long as Jackson is on the class path.</p>
</div>
<div class="paragraph">
<p>With the batch converter, the converted headers are available in the <code>KafkaHeaders.BATCH_CONVERTED_HEADERS</code> as a <code>List&lt;Map&lt;String, Object&gt;&gt;</code> where the map in a position of the list corresponds to the data position in the payload.</p>
</div>
<div class="paragraph">
<p>If there is no converter (either because Jackson is not present or it is explicitly set to <code>null</code>), the headers from the consumer record are provided unconverted in the <code>KafkaHeaders.NATIVE_HEADERS</code> header.
This header is a <code>Headers</code> object (or a <code>List&lt;Headers&gt;</code> in the case of the batch converter), where the position in the list corresponds to the data position in the payload).</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Certain types are not suitable for JSON serialization, and a simple <code>toString()</code> serialization might be preferred for these types.
The <code>DefaultKafkaHeaderMapper</code> has a method called <code>addToStringClasses()</code> that lets you supply the names of classes that should be treated this way for outbound mapping.
During inbound mapping, they are mapped as <code>String</code>.
By default, only <code>org.springframework.util.MimeType</code> and <code>org.springframework.http.MediaType</code> are mapped this way.
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Starting with version 2.3, handling of String-valued headers is simplified.
Such headers are no longer JSON encoded, by default (i.e. they do not have enclosing <code>"…​"</code> added).
The type is still added to the JSON_TYPES header so the receiving system can convert back to a String (from <code>byte[]</code>).
The mapper can handle (decode) headers produced by older versions (it checks for a leading <code>"</code>); in this way an application using 2.3 can consume records from older versions.
</td>
</tr>
</tbody></table>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
To be compatible with earlier versions, set <code>encodeStrings</code> to <code>true</code>, if records produced by a version using 2.3 might be consumed by applications using earlier versions.
When all applications are using 2.3 or higher, you can leave the property at its default value of <code>false</code>.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="tombstones"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tombstones"></a>4.1.10. Null Payloads and Log Compaction of 'Tombstone' Records</h4>
<div class="paragraph">
<p>When you use <a href="https://kafka.apache.org/documentation/#compaction">Log Compaction</a>, you can send and receive messages with <code>null</code> payloads to identify the deletion of a key.</p>
</div>
<div class="paragraph">
<p>You can also receive <code>null</code> values for other reasons, such as a <code>Deserializer</code> that might return <code>null</code> when it cannot deserialize a value.</p>
</div>
<div class="paragraph">
<p>To send a <code>null</code> payload by using the <code>KafkaTemplate</code>, you can pass null into the value argument of the <code>send()</code> methods.
One exception to this is the <code>send(Message&lt;?&gt; message)</code> variant.
Since <code>spring-messaging</code> <code>Message&lt;?&gt;</code> cannot have a <code>null</code> payload, you can use a special payload type called <code>KafkaNull</code>, and the framework sends <code>null</code>.
For convenience, the static <code>KafkaNull.INSTANCE</code> is provided.</p>
</div>
<div class="paragraph">
<p>When you use a message listener container, the received <code>ConsumerRecord</code> has a <code>null</code> <code>value()</code>.</p>
</div>
<div class="paragraph">
<p>To configure the <code>@KafkaListener</code> to handle <code>null</code> payloads, you must use the <code>@Payload</code> annotation with <code>required = false</code>.
If it is a tombstone message for a compacted log, you usually also need the key so that your application can determine which key was “deleted”.
The following example shows such a configuration:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"deletableListener"</span>, topics = <span class="hljs-string">"myTopic"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(@Payload(required = <span class="hljs-keyword">false</span>)</span> String value, @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> String key) </span>{
    <span class="hljs-comment">// value == null represents key deletion</span>
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When you use a class-level <code>@KafkaListener</code> with multiple <code>@KafkaHandler</code> methods, some additional configuration is needed.
Specifically, you need a <code>@KafkaHandler</code> method with a <code>KafkaNull</code> payload.
The following example shows how to configure one:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"multi"</span>, topics = <span class="hljs-string">"myTopic"</span>)
<span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiListenerBean</span> </span>{

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(String cat)</span> </span>{
        ...
    }

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(Integer hat)</span> </span>{
        ...
    }

    <span class="hljs-meta">@KafkaHandler</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">delete</span><span class="hljs-params">(@Payload(required = <span class="hljs-keyword">false</span>)</span> KafkaNull nul, @<span class="hljs-title">Header</span><span class="hljs-params">(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> <span class="hljs-keyword">int</span> key) </span>{
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Note that the argument is <code>null</code>, not <code>KafkaNull</code>.</p>
</div>
<div class="admonitionblock tip">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tip-assign-all-parts">Manually Assigning All Partitions</a>.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="annotation-error-handling"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-error-handling"></a>4.1.11. Handling Exceptions</h4>
<div class="paragraph">
<p>This section describes how to handle various exceptions that may arise when you use Spring for Apache Kafka.</p>
</div>
<div class="sect4">
<h5 id="listener-error-handlers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-error-handlers"></a>Listener Error Handlers</h5>
<div class="paragraph">
<p>Starting with version 2.0, the <code>@KafkaListener</code> annotation has a new attribute: <code>errorHandler</code>.</p>
</div>
<div class="paragraph">
<p>By default, this attribute is not configured.</p>
</div>
<div class="paragraph">
<p>You can use the <code>errorHandler</code> to provide the bean name of a <code>KafkaListenerErrorHandler</code> implementation.
This functional interface has one method, as the following listing shows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@FunctionalInterface</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">KafkaListenerErrorHandler</span> </span>{

    <span class="hljs-function">Object <span class="hljs-title">handleError</span><span class="hljs-params">(Message&lt;?&gt; message, ListenerExecutionFailedException exception)</span> <span class="hljs-keyword">throws</span> Exception</span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>You have access to the spring-messaging <code>Message&lt;?&gt;</code> object produced by the message converter and the exception that was thrown by the listener, which is wrapped in a <code>ListenerExecutionFailedException</code>.
The error handler can throw the original or a new exception, which is thrown to the container.
Anything returned by the error handler is ignored.</p>
</div>
<div class="paragraph">
<p>It has a sub-interface (<code>ConsumerAwareListenerErrorHandler</code>) that has access to the consumer object, through the following method:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function">Object <span class="hljs-title">handleError</span><span class="hljs-params">(Message&lt;?&gt; message, ListenerExecutionFailedException exception, Consumer&lt;?, ?&gt; consumer)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>If your error handler implements this interface, you can, for example, adjust the offsets accordingly.
For example, to reset the offset to replay the failed message, you could do something like the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerAwareListenerErrorHandler <span class="hljs-title">listen3ErrorHandler</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> (m, e, c) -&gt; {
        <span class="hljs-keyword">this</span>.listen3Exception = e;
        MessageHeaders headers = m.getHeaders();
        c.seek(<span class="hljs-keyword">new</span> org.apache.kafka.common.TopicPartition(
                headers.get(KafkaHeaders.RECEIVED_TOPIC, String.class),
                headers.get(KafkaHeaders.RECEIVED_PARTITION_ID, Integer.class)),
                headers.get(KafkaHeaders.OFFSET, Long.class));
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;
    };
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Similarly, you could do something like the following for a batch listener:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerAwareListenerErrorHandler <span class="hljs-title">listen10ErrorHandler</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> (m, e, c) -&gt; {
        <span class="hljs-keyword">this</span>.listen10Exception = e;
        MessageHeaders headers = m.getHeaders();
        List&lt;String&gt; topics = headers.get(KafkaHeaders.RECEIVED_TOPIC, List.class);
        List&lt;Integer&gt; partitions = headers.get(KafkaHeaders.RECEIVED_PARTITION_ID, List.class);
        List&lt;Long&gt; offsets = headers.get(KafkaHeaders.OFFSET, List.class);
        Map&lt;TopicPartition, Long&gt; offsetsToReset = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; topics.size(); i++) {
            <span class="hljs-keyword">int</span> index = i;
            offsetsToReset.compute(<span class="hljs-keyword">new</span> TopicPartition(topics.get(i), partitions.get(i)),
                    (k, v) -&gt; v == <span class="hljs-keyword">null</span> ? offsets.get(index) : Math.min(v, offsets.get(index)));
        }
        offsetsToReset.forEach((k, v) -&gt; c.seek(k, v));
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;
    };
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>This resets each topic/partition in the batch to the lowest offset in the batch.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The preceding two examples are simplistic implementations, and you would probably want more checking in the error handler.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="error-handlers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#error-handlers"></a>Container Error Handlers</h5>
<div class="paragraph">
<p>Two error handler interfaces (<code>ErrorHandler</code> and <code>BatchErrorHandler</code>) are provided.
You must configure the appropriate type to match the <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners">message listener</a>.</p>
</div>
<div class="paragraph">
<p>By default, errors are simply logged when transactions are not being used.
When transactions are being used, no error handlers are configured, by default, so that the exception will roll back the transaction.
If you provide a custom error handler when using transactions, it must throw an exception if you want the transaction rolled back.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3.2, these interfaces have a default method <code>isAckAfterHandle()</code> which is called by the container to determine whether the offset(s) should be committed if the error handler returns without throwing an exception.
This returns false by default, for backwards compatibility.
In most cases, however, we expect that the offset should be committed.
For example, the <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current"><code>SeekToCurrentErrorHandler</code></a> returns <code>true</code> if a record is recovered (after any retries, if so configured).
In a future release, we expect to change this default to <code>true</code>.</p>
</div>
<div class="paragraph">
<p>You can specify a global error handler to be used for all listeners in the container factory.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt;
        kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
            <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    ...
    factory.setErrorHandler(myErrorHandler);
    ...
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Similarly, you can set a global batch error handler:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;Integer, String&gt;&gt;
        kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory&lt;Integer, String&gt; factory =
            <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
    ...
    factory.setBatchErrorHandler(myBatchErrorHandler);
    ...
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>By default, if an annotated listener method throws an exception, it is thrown to the container, and the message is handled according to the container configuration.</p>
</div>
<div class="paragraph">
<p>If you are using Spring Boot, you simply need to add the error handler as a <code>@Bean</code> and boot will add it to the auto-configured factory.</p>
</div>
</div>
<div class="sect4">
<h5 id="consumer-aware-container-error-handlers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#consumer-aware-container-error-handlers"></a>Consumer-Aware Container Error Handlers</h5>
<div class="paragraph">
<p>The container-level error handlers (<code>ErrorHandler</code> and <code>BatchErrorHandler</code>) have sub-interfaces called <code>ConsumerAwareErrorHandler</code> and <code>ConsumerAwareBatchErrorHandler</code>.
The <code>handle</code> method of the <code>ConsumerAwareErrorHandler</code> has the following signature:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">handle</span><span class="hljs-params">(Exception thrownException, ConsumerRecord&lt;?, ?&gt; data, Consumer&lt;?, ?&gt; consumer)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>handle</code> method of the <code>ConsumerAwareBatchErrorHandler</code> has the following signature:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">handle</span><span class="hljs-params">(Exception thrownException, ConsumerRecords&lt;?, ?&gt; data, Consumer&lt;?, ?&gt; consumer)</span></span>;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Similar to the <code>@KafkaListener</code> error handlers, you can reset the offsets as needed, based on the data that failed.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Unlike the listener-level error handlers, however, you should set the <code>ackOnError</code> container property to <code>false</code> (default) when making adjustments.
Otherwise, any pending acks are applied after your repositioning.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect4">
<h5 id="seek-to-current"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current"></a>Seek To Current Container Error Handlers</h5>
<div class="paragraph">
<p>If an <code>ErrorHandler</code> implements <code>RemainingRecordsErrorHandler</code>, the error handler is provided with the failed record and any unprocessed records retrieved by the previous <code>poll()</code>.
Those records are not passed to the listener after the handler exits.
The following listing shows the <code>RemainingRecordsErrorHandler</code> interface definition:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@FunctionalInterface</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">RemainingRecordsErrorHandler</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ConsumerAwareErrorHandler</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">handle</span><span class="hljs-params">(Exception thrownException, List&lt;ConsumerRecord&lt;?, ?&gt;&gt; records, Consumer&lt;?, ?&gt; consumer)</span></span>;

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>This interface lets implementations seek all unprocessed topics and partitions so that the current record (and the others remaining) are retrieved by the next poll.
The <code>SeekToCurrentErrorHandler</code> does exactly this.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<code>ackOnError</code> must be <code>false</code> (which is the default).
Otherwise, if the container is stopped after the seek, but before the record is reprocessed, the record will be skipped when the container is restarted.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>The container commits any pending offset commits before calling the error handler.</p>
</div>
<div class="paragraph">
<p>To configure the listener container with this handler, add it to the container factory.</p>
</div>
<div class="paragraph">
<p>For example, with the <code>@KafkaListener</code> container factory, you can add <code>SeekToCurrentErrorHandler</code> as follows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; <span class="hljs-title">kafkaListenerContainerFactory</span><span class="hljs-params">()</span> </span>{
    ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory = <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory();
    factory.setConsumerFactory(consumerFactory());
    factory.getContainerProperties().setAckOnError(<span class="hljs-keyword">false</span>);
    factory.getContainerProperties().setAckMode(AckMode.RECORD);
    factory.setErrorHandler(<span class="hljs-keyword">new</span> SeekToCurrentErrorHandler());
    <span class="hljs-keyword">return</span> factory;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>As an example; if the <code>poll</code> returns six records (two from each partition 0, 1, 2) and the listener throws an exception on the fourth record, the container acknowledges the first three messages by committing their offsets.
The <code>SeekToCurrentErrorHandler</code> seeks to offset 1 for partition 1 and offset 0 for partition 2.
The next <code>poll()</code> returns the three unprocessed records.</p>
</div>
<div class="paragraph">
<p>If the <code>AckMode</code> was <code>BATCH</code>, the container commits the offsets for the first two partitions before calling the error handler.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2, the <code>SeekToCurrentErrorHandler</code> can now recover (skip) a record that keeps failing.
By default, after ten failures, the failed record is logged (at the <code>ERROR</code> level).
You can configure the handler with a custom recoverer (<code>BiConsumer</code>) and maximum failures.
Setting the <code>maxFailures</code> property to a negative number causes infinite retries.
The following example configures recovery after three tries:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">SeekToCurrentErrorHandler errorHandler =
    <span class="hljs-keyword">new</span> SeekToCurrentErrorHandler((record, exception) -&gt; {
        <span class="hljs-comment">// recover after 3 failures, woth no back off - e.g. send to a dead-letter topic</span>
    }, <span class="hljs-keyword">new</span> FixedBackOff(<span class="hljs-number">0L</span>, <span class="hljs-number">2L</span>));</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.2.4, when the container is configured with <code>AckMode.MANUAL_IMMEDIATE</code>, the error handler can be configured to commit the offset of recovered records; set the <code>commitRecovered</code> property to <code>true</code>.</p>
</div>
<div class="paragraph">
<p>See also <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters">Publishing Dead-letter Records</a>.</p>
</div>
<div class="paragraph">
<p>When using transactions, similar functionality is provided by the <code>DefaultAfterRollbackProcessor</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback">After-rollback Processor</a>.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, the <code>SeekToCurrentErrorHandler</code> considers certain exceptions to be fatal, and retries are skipped for such exceptions; the recoverer is invoked on the first failure.
The exceptions that are considered fatal, by default, are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>DeserializationException</code></p>
</li>
<li>
<p><code>MessageConversionException</code></p>
</li>
<li>
<p><code>MethodArgumentResolutionException</code></p>
</li>
<li>
<p><code>NoSuchMethodException</code></p>
</li>
<li>
<p><code>ClassCastException</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>since these exceptions are unlikely to be resolved on a retried delivery.</p>
</div>
<div class="paragraph">
<p>You can add more exception types to the not-retryable category, or completely replace the <code>BinaryExceptionClassifier</code> with your own configured classifier.
See the Javadocs for <code>SeekToCurrentErrorHandler</code> for more information, as well as those for the <code>spring-retry</code> <code>BinaryExceptionClassifier</code>.</p>
</div>
<div class="paragraph">
<p>Here is an example that adds <code>IllegalArgumentException</code> to the not-retryable exceptions:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> SeekToCurrentErrorHandler <span class="hljs-title">errorHandler</span><span class="hljs-params">(BiConsumer&lt;ConsumerRecord&lt;?, ?&gt;, Exception&gt; recoverer)</span> </span>{
    SeekToCurrentErrorHandler handler = <span class="hljs-keyword">new</span> SeekToCurrentErrorHandler(recoverer);
    handler.addNotRetryableException(IllegalArgumentException.class);
    <span class="hljs-keyword">return</span> handler;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>SeekToCurrentBatchErrorHandler</code> seeks each partition to the first record in each partition in the batch, so the whole batch is replayed.
Also see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#committing-offsets">Committing Offsets</a> for an alternative.
This error handler does not support recovery, because the framework cannot know which message in the batch is failing.</p>
</div>
<div class="paragraph">
<p>After seeking, an exception that wraps the <code>ListenerExecutionFailedException</code> is thrown.
This is to cause the transaction to roll back (if transactions are enabled).</p>
</div>
<div class="paragraph">
<p>Starting with version 2.3, a <code>BackOff</code> can be provided to the <code>SeekToCurrentErrorHandler</code> and <code>DefaultAfterRollbackProcessor</code> so that the consumer thread can sleep for some configurable time between delivery attempts.
Spring Framework provides two out of the box <code>BackOff</code> s, <code>FixedBackOff</code> and <code>ExponentialBackOff</code>.
The maximum back off time must not exceed the <code>max.poll.interval.ms</code> consumer property, to avoid a rebalance.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Previously, the configuration was "maxFailures" (which included the first delivery attempt).
When using a <code>FixedBackOff</code>, its <code>maxAttempts</code> properties represents the number of delivery retries (one less than the old <code>maxFailures</code> property).
Also, <code>maxFailures=-1</code> meant retry indefinitely with the old configuration, with a <code>BackOff</code> you would set the <code>maxAttempts</code> to <code>Long.MAX_VALUE</code> for a <code>FixedBackOff</code> and leave the <code>maxElapsedTime</code> to its default in an <code>ExponentialBackOff</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>The <code>SeekToCurrentBatchErrorHandler</code> can also be configured with a <code>BackOff</code> to add a delay between delivery attempts.
Generally, you should configure the <code>BackOff</code> to never return <code>STOP</code>.
However, since this error handler has no mechanism to "recover" after retries are exhausted, if the <code>BackOffExecution</code> returns <code>STOP</code>, the previous interval will be used for all subsequent delays.
Again, the maximum delay must be less than the <code>max.poll.interval.ms</code> consumer property.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If the recoverer fails (throws an exception), the record will be included in the seeks and recovery will be attempted again during the next delivery.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 2.3.2, after a record has been recovered, its offset will be committed (if one of the container <code>AckMode</code> s is configured).
To revert to the previous behavior, set the error handler’s <code>ackAfterHandle</code> property to false.</p>
</div>
</div>
<div class="sect4">
<h5 id="container-stopping-error-handlers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-stopping-error-handlers"></a>Container Stopping Error Handlers</h5>
<div class="paragraph">
<p>The <code>ContainerStoppingErrorHandler</code> (used with record listeners) stops the container if the listener throws an exception.
When the <code>AckMode</code> is <code>RECORD</code>, offsets for already processed records are committed.
When the <code>AckMode</code> is any manual value, offsets for already acknowledged records are committed.
When the <code>AckMode</code> is <code>BATCH</code>, the entire batch is replayed when the container is restarted (unless transactions are enabled — in which case, only the unprocessed records are re-fetched).</p>
</div>
<div class="paragraph">
<p>The <code>ContainerStoppingBatchErrorHandler</code> (used with batch listeners) stops the container, and the entire batch is replayed when the container is restarted.</p>
</div>
<div class="paragraph">
<p>After the container stops, an exception that wraps the <code>ListenerExecutionFailedException</code> is thrown.
This is to cause the transaction to roll back (if transactions are enabled).</p>
</div>
</div>
<div class="sect4">
<h5 id="after-rollback"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback"></a>After-rollback Processor</h5>
<div class="paragraph">
<p>When using transactions, if the listener throws an exception (and an error handler, if present, throws an exception), the transaction is rolled back.
By default, any unprocessed records (including the failed record) are re-fetched on the next poll.
This is achieved by performing <code>seek</code> operations in the <code>DefaultAfterRollbackProcessor</code>.
With a batch listener, the entire batch of records is reprocessed (the container has no knowledge of which record in the batch failed).
To modify this behavior, you can configure the listener container with a custom <code>AfterRollbackProcessor</code>.
For example, with a record-based listener, you might want to keep track of the failed record and give up after some number of attempts, perhaps by publishing it to a dead-letter topic.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2, the <code>DefaultAfterRollbackProcessor</code> can now recover (skip) a record that keeps failing.
By default, after ten failures, the failed record is logged (at the <code>ERROR</code> level).
You can configure the processor with a custom recoverer (<code>BiConsumer</code>) and maximum failures.
Setting the <code>maxFailures</code> property to a negative number causes infinite retries.
The following example configures recovery after three tries:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">AfterRollbackProcessor&lt;String, String&gt; processor =
    <span class="hljs-keyword">new</span> DefaultAfterRollbackProcessor((record, exception) -&gt; {
        <span class="hljs-comment">// recover after 3 failures, with no back off - e.g. send to a dead-letter topic</span>
    }, <span class="hljs-keyword">new</span> FixedBackOff(<span class="hljs-number">0L</span>, <span class="hljs-number">2L</span>));</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When you do not use transactions, you can achieve similar functionality by configuring a <code>SeekToCurrentErrorHandler</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a>.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Recovery is not possible with a batch listener, since the framework has no knowledge about which record in the batch keeps failing.
In such cases, the application listener must handle a record that keeps failing.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>See also <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters">Publishing Dead-letter Records</a>.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2.5, the <code>DefaultAfterRollbackProcessor</code> can be invoked in a new transaction (started after the failed transaction rolls back).
Then, if you are using the <code>DeadLetterPublishingRecoverer</code> to publish a failed record, the processor will send the recovered record’s offset in the original topic/partition to the transaction.
To enable this feature, set the <code>commitRecovered</code> and <code>kafkaTemplate</code> properties on the <code>DefaultAfterRollbackProcessor</code>.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If the recoverer fails (throws an exception), the record will be included in the seeks and recovery will be attempted again during the next delivery.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 2.3.1, similar to the <code>SeekToCurrentErrorHandler</code>, the <code>DefaultAfterRollbackProcessor</code> considers certain exceptions to be fatal, and retries are skipped for such exceptions; the recoverer is invoked on the first failure.
The exceptions that are considered fatal, by default, are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>DeserializationException</code></p>
</li>
<li>
<p><code>MessageConversionException</code></p>
</li>
<li>
<p><code>MethodArgumentResolutionException</code></p>
</li>
<li>
<p><code>NoSuchMethodException</code></p>
</li>
<li>
<p><code>ClassCastException</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>since these exceptions are unlikely to be resolved on a retried delivery.</p>
</div>
<div class="paragraph">
<p>You can add more exception types to the not-retryable category, or completely replace the <code>BinaryExceptionClassifier</code> with your own configured classifier.
See the Javadocs for <code>DefaultAfterRollbackProcessor</code> for more information, as well as those for the <code>spring-retry</code> <code>BinaryExceptionClassifier</code>.</p>
</div>
<div class="paragraph">
<p>Here is an example that adds <code>IllegalArgumentException</code> to the not-retryable exceptions:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> DefaultAfterRollbackProcessor <span class="hljs-title">errorHandler</span><span class="hljs-params">(BiConsumer&lt;ConsumerRecord&lt;?, ?&gt;, Exception&gt; recoverer)</span> </span>{
    DefaultAfterRollbackProcessor processor = <span class="hljs-keyword">new</span> DefaultAfterRollbackProcessor(recoverer);
    processor.addNotRetryableException(IllegalArgumentException.class);
    <span class="hljs-keyword">return</span> processor;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="dead-letters"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters"></a>Publishing Dead-letter Records</h5>
<div class="paragraph">
<p>As <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry">discussed earlier</a>, you can configure the <code>SeekToCurrentErrorHandler</code> and <code>DefaultAfterRollbackProcessor</code> with a record recoverer when the maximum number of failures is reached for a record.
The framework provides the <code>DeadLetterPublishingRecoverer</code>, which publishes the failed message to another topic.
The recoverer requires a <code>KafkaTemplate&lt;Object, Object&gt;</code>, which is used to send the record.
You can also, optionally, configure it with a <code>BiFunction&lt;ConsumerRecord&lt;?, ?&gt;, Exception, TopicPartition&gt;</code>, which is called to resolve the destination topic and partition.
By default, the dead-letter record is sent to a topic named <code>&lt;originalTopic&gt;.DLT</code> (the original topic name suffixed with <code>.DLT</code>) and to the same partition as the original record.
Therefore, when you use the default resolver, the dead-letter topic must have at least as many partitions as the original topic.
If the returned <code>TopicPartition</code> has a negative partition, the partition is not set in the <code>ProducerRecord</code>, so the partition is selected by Kafka.
Starting with version 2.2.4, any <code>ListenerExecutionFailedException</code> (thrown, for example, when an exception is detected in a <code>@KafkaListener</code> method) is enhanced with the <code>groupId</code> property.
This allows the destination resolver to use this, in addition to the information in the <code>ConsumerRecord</code> to select the dead letter topic.</p>
</div>
<div class="paragraph">
<p>The following example shows how to wire a custom destination resolver:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">DeadLetterPublishingRecoverer recoverer = <span class="hljs-keyword">new</span> DeadLetterPublishingRecoverer(template,
        (r, e) -&gt; {
            <span class="hljs-keyword">if</span> (e <span class="hljs-keyword">instanceof</span> FooException) {
                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> TopicPartition(r.topic() + <span class="hljs-string">".Foo.failures"</span>, r.partition());
            }
            <span class="hljs-keyword">else</span> {
                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> TopicPartition(r.topic() + <span class="hljs-string">".other.failures"</span>, r.partition());
            }
        });
ErrorHandler errorHandler = <span class="hljs-keyword">new</span> SeekToCurrentErrorHandler(recoverer, <span class="hljs-keyword">new</span> FixedBackOff(<span class="hljs-number">0L</span>, <span class="hljs-number">2L</span>));</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The record sent to the dead-letter topic is enhanced with the following headers:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>KafkaHeaders.DLT_EXCEPTION_FQCN</code>: The Exception class name.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_EXCEPTION_STACKTRACE</code>: The Exception stack trace.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_EXCEPTION_MESSAGE</code>: The Exception message.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_ORIGINAL_TOPIC</code>: The original topic.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_ORIGINAL_PARTITION</code>: The original partition.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_ORIGINAL_OFFSET</code>: The original offset.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_ORIGINAL_TIMESTAMP</code>: The original timestamp.</p>
</li>
<li>
<p><code>KafkaHeaders.DLT_ORIGINAL_TIMESTAMP_TYPE</code>: The original timestamp type.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Starting with version 2.3, when used in conjunction with an <code>ErrorHandlingDeserializer2</code>, the publisher will restore the record <code>value()</code>, in the dead-letter producer record, to the original value that failed to be deserialized.
Previously, the <code>value()</code> was null and user code had to decode the <code>DeserializationException</code> from the message headers.
In addition, you can provide multiple <code>KafkaTemplate</code> s to the publisher; this might be needed, for example, if you want to publish the <code>byte[]</code> from a <code>DeserializationException</code>, as well as values using a different serializer from records that were deserialized successfully.
Here is an example of configuring the publisher with <code>KafkaTemplate</code> s that use a <code>String</code> and <code>byte[]</code> serializer:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> DeadLetterPublishingRecoverer <span class="hljs-title">publisher</span><span class="hljs-params">(KafkaTemplate&lt;?, ?&gt; stringTemplate,
        KafkaTemplate&lt;?, ?&gt; bytesTemplate)</span> </span>{

    Map&lt;Class&lt;?&gt;, KafkaTemplate&lt;?, ?&gt;&gt; templates = <span class="hljs-keyword">new</span> LinkedHashMap&lt;&gt;();
    templates.put(String.class, stringTemplate);
    templates.put(<span class="hljs-keyword">byte</span>[].class, bytesTemplate);
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DeadLetterPublishingRecoverer(templates);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The publisher uses the map keys to locate a template that is suitable for the <code>value()</code> about to be published.
A <code>LinkedHashMap</code> is recommended so that the keys are examined in order.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If the recoverer fails (throws an exception), the record will be included in the seeks and recovery will be attempted again during the next delivery.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Starting with version 2.3, the recoverer can also be used with Kafka Streams - see <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-deser-recovery">Recovery from Deserialization Exceptions</a> for more information.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="kerberos"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos"></a>4.1.12. Kerberos</h4>
<div class="paragraph">
<p>Starting with version 2.0, a <code>KafkaJaasLoginModuleInitializer</code> class has been added to assist with Kerberos configuration.
You can add this bean, with the desired configuration, to your application context.
The following example configures such a bean:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaJaasLoginModuleInitializer <span class="hljs-title">jaasConfig</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> IOException </span>{
    KafkaJaasLoginModuleInitializer jaasConfig = <span class="hljs-keyword">new</span> KafkaJaasLoginModuleInitializer();
    jaasConfig.setControlFlag(<span class="hljs-string">"REQUIRED"</span>);
    Map&lt;String, String&gt; options = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    options.put(<span class="hljs-string">"useKeyTab"</span>, <span class="hljs-string">"true"</span>);
    options.put(<span class="hljs-string">"storeKey"</span>, <span class="hljs-string">"true"</span>);
    options.put(<span class="hljs-string">"keyTab"</span>, <span class="hljs-string">"/etc/security/keytabs/kafka_client.keytab"</span>);
    options.put(<span class="hljs-string">"principal"</span>, <span class="hljs-string">"kafka-client-1@EXAMPLE.COM"</span>);
    jaasConfig.setOptions(options);
    <span class="hljs-keyword">return</span> jaasConfig;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="streams-kafka-streams"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-kafka-streams"></a>4.2. Kafka Streams Support</h3>
<div class="paragraph">
<p>Starting with version 1.1.4, Spring for Apache Kafka provides first-class support for <a href="https://kafka.apache.org/documentation/streams">Kafka Streams</a>.
To use it from a Spring application, the <code>kafka-streams</code> jar must be present on classpath.
It is an optional dependency of the <code>spring-kafka</code> project and is not downloaded transitively.</p>
</div>
<div class="sect3">
<h4 id="basics"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#basics"></a>4.2.1. Basics</h4>
<div class="paragraph">
<p>The reference Apache Kafka Streams documentation suggests the following way of using the API:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">// Use the builders to define the actual processing topology, e.g. to specify</span>
<span class="hljs-comment">// from which input topics to read, which stream operations (filter, map, etc.)</span>
<span class="hljs-comment">// should be called, and so on.</span>

StreamsBuilder builder = ...;  <span class="hljs-comment">// when using the Kafka Streams DSL</span>

<span class="hljs-comment">// Use the configuration to tell your application where the Kafka cluster is,</span>
<span class="hljs-comment">// which serializers/deserializers to use by default, to specify security settings,</span>
<span class="hljs-comment">// and so on.</span>
StreamsConfig config = ...;

KafkaStreams streams = <span class="hljs-keyword">new</span> KafkaStreams(builder, config);

<span class="hljs-comment">// Start the Kafka Streams instance</span>
streams.start();

<span class="hljs-comment">// Stop the Kafka Streams instance</span>
streams.close();</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>So, we have two main components:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>StreamsBuilder</code>: With an API to build <code>KStream</code> (or <code>KTable</code>) instances.</p>
</li>
<li>
<p><code>KafkaStreams</code>: To manage the lifecycle of those instances.</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
All <code>KStream</code> instances exposed to a <code>KafkaStreams</code> instance by a single <code>StreamsBuilder</code> are started and stopped at the same time, even if they have different logic.
In other words, all streams defined by a <code>StreamsBuilder</code> are tied with a single lifecycle control.
Once a <code>KafkaStreams</code> instance has been closed by <code>streams.close()</code>, it cannot be restarted.
Instead, a new <code>KafkaStreams</code> instance to restart stream processing must be created.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="spring-management"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-management"></a>4.2.2. Spring Management</h4>
<div class="paragraph">
<p>To simplify using Kafka Streams from the Spring application context perspective and use the lifecycle management through a container, the Spring for Apache Kafka introduces <code>StreamsBuilderFactoryBean</code>.
This is an <code>AbstractFactoryBean</code> implementation to expose a <code>StreamsBuilder</code> singleton instance as a bean.
The following example creates such a bean:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> FactoryBean&lt;StreamsBuilderFactoryBean&gt; <span class="hljs-title">myKStreamBuilder</span><span class="hljs-params">(KafkaStreamsConfiguration streamsConfig)</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> StreamsBuilderFactoryBean(streamsConfig);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Starting with version 2.2, the stream configuration is now provided as a <code>KafkaStreamsConfiguration</code> object rather than a <code>StreamsConfig</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>The <code>StreamsBuilderFactoryBean</code> also implements <code>SmartLifecycle</code> to manage the lifecycle of an internal <code>KafkaStreams</code> instance.
Similar to the Kafka Streams API, you must define the <code>KStream</code> instances before you start the <code>KafkaStreams</code>.
That also applies for the Spring API for Kafka Streams.
Therefore, when you use default <code>autoStartup = true</code> on the <code>StreamsBuilderFactoryBean</code>, you must declare <code>KStream</code> instances on the <code>StreamsBuilder</code> before the application context is refreshed.
For example, <code>KStream</code> can be a regular bean definition, while the Kafka Streams API is used without any impacts.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KStream&lt;?, ?&gt; kStream(StreamsBuilder kStreamBuilder) {
    KStream&lt;Integer, String&gt; stream = kStreamBuilder.stream(STREAMING_TOPIC1);
    <span class="hljs-comment">// Fluent KStream API</span>
    <span class="hljs-keyword">return</span> stream;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>If you would like to control the lifecycle manually (for example, stopping and starting by some condition), you can reference the <code>StreamsBuilderFactoryBean</code> bean directly by using the factory bean (<code>&amp;</code>) <a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/html/beans.html#beans-factory-extension-factorybean">prefix</a>.
Since <code>StreamsBuilderFactoryBean</code> use its internal <code>KafkaStreams</code> instance, it is safe to stop and restart it again.
A new <code>KafkaStreams</code> is created on each <code>start()</code>.
You might also consider using different <code>StreamsBuilderFactoryBean</code> instances, if you would like to control the lifecycles for <code>KStream</code> instances separately.</p>
</div>
<div class="paragraph">
<p>You also can specify <code>KafkaStreams.StateListener</code>, <code>Thread.UncaughtExceptionHandler</code>, and <code>StateRestoreListener</code> options on the <code>StreamsBuilderFactoryBean</code>, which are delegated to the internal <code>KafkaStreams</code> instance.
Also, apart from setting those options indirectly on <code>StreamsBuilderFactoryBean</code>, starting with <em>version 2.1.5</em>, you can use a <code>KafkaStreamsCustomizer</code> callback interface to configure an inner <code>KafkaStreams</code> instance.
Note that <code>KafkaStreamsCustomizer</code> overrides the options provided by <code>StreamsBuilderFactoryBean</code>.
If you need to perform some <code>KafkaStreams</code> operations directly, you can access that internal <code>KafkaStreams</code> instance by using <code>StreamsBuilderFactoryBean.getKafkaStreams()</code>.
You can autowire <code>StreamsBuilderFactoryBean</code> bean by type, but you should be sure to use the full type in the bean definition, as the following example shows:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> StreamsBuilderFactoryBean <span class="hljs-title">myKStreamBuilder</span><span class="hljs-params">(KafkaStreamsConfiguration streamsConfig)</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> StreamsBuilderFactoryBean(streamsConfig);
}
...
<span class="hljs-meta">@Autowired</span>
<span class="hljs-keyword">private</span> StreamsBuilderFactoryBean myKStreamBuilderFactoryBean;</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you can add <code>@Qualifier</code> for injection by name if you use interface bean definition.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> FactoryBean&lt;StreamsBuilder&gt; <span class="hljs-title">myKStreamBuilder</span><span class="hljs-params">(KafkaStreamsConfiguration streamsConfig)</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> StreamsBuilderFactoryBean(streamsConfig);
}
...
<span class="hljs-meta">@Autowired</span>
<span class="hljs-meta">@Qualifier</span>(<span class="hljs-string">"&amp;myKStreamBuilder"</span>)
<span class="hljs-keyword">private</span> StreamsBuilderFactoryBean myKStreamBuilderFactoryBean;</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="serde"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serde"></a>4.2.3. Streams JSON Serialization and Deserialization</h4>
<div class="paragraph">
<p>For serializing and deserializing data when reading or writing to topics or state stores in JSON format, Spring Kafka provides a <code>JsonSerde</code> implementation that uses JSON, delegating to the <code>JsonSerializer</code> and <code>JsonDeserializer</code> described in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a>.
The <code>JsonSerde</code> implementation provides the same configuration options through its constructor (target type or <code>ObjectMapper</code>).
In the following example, we use the <code>JsonSerde</code> to serialize and deserialize the <code>Cat</code> payload of a Kafka stream (the <code>JsonSerde</code> can be used in a similar fashion wherever an instance is required):</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">stream.through(Serdes.Integer(), <span class="hljs-keyword">new</span> JsonSerde&lt;&gt;(Cat.class), <span class="hljs-string">"cats"</span>);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When constructing the serializer/deserializer programmatically for use in the producer/consumer factory, since version 2.3, you can use the fluent API, which simplifies configuration.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">stream.through(<span class="hljs-keyword">new</span> JsonSerde&lt;&gt;(MyKeyType.class)
        .forKeys()
        .noTypeInfo(),
    <span class="hljs-keyword">new</span> JsonSerde&lt;&gt;(MyValueType.class)
        .noTypeInfo(),
    <span class="hljs-string">"myTypes"</span>);</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="using-kafkastreamsbrancher"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-kafkastreamsbrancher"></a>4.2.4. Using <code>KafkaStreamsBrancher</code></h4>
<div class="paragraph">
<p>The <code>KafkaStreamBrancher</code> class introduces a more convenient way to build conditional branches on top of <code>KStream</code>.</p>
</div>
<div class="paragraph">
<p>Consider the following example that does not use <code>KafkaStreamBrancher</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">KStream&lt;String, String&gt;[] branches = builder.stream(<span class="hljs-string">"source"</span>).branch(
      (key, value) -&gt; value.contains(<span class="hljs-string">"A"</span>),
      (key, value) -&gt; value.contains(<span class="hljs-string">"B"</span>),
      (key, value) -&gt; <span class="hljs-keyword">true</span>
     );
branches[<span class="hljs-number">0</span>].to(<span class="hljs-string">"A"</span>);
branches[<span class="hljs-number">1</span>].to(<span class="hljs-string">"B"</span>);
branches[<span class="hljs-number">2</span>].to(<span class="hljs-string">"C"</span>);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example uses <code>KafkaStreamBrancher</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">new</span> KafkaStreamsBrancher&lt;String, String&gt;()
   .branch((key, value) -&gt; value.contains(<span class="hljs-string">"A"</span>), ks -&gt; ks.to(<span class="hljs-string">"A"</span>))
   .branch((key, value) -&gt; value.contains(<span class="hljs-string">"B"</span>), ks -&gt; ks.to(<span class="hljs-string">"B"</span>))
   <span class="hljs-comment">//default branch should not necessarily be defined in the end of the chain!</span>
   .defaultBranch(ks -&gt; ks.to(<span class="hljs-string">"C"</span>))
   .onTopOf(builder.stream(<span class="hljs-string">"source"</span>));
   <span class="hljs-comment">//onTopOf method returns the provided stream so we can continue with method chaining</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="streams-config"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-config"></a>4.2.5. Configuration</h4>
<div class="paragraph">
<p>To configure the Kafka Streams environment, the <code>StreamsBuilderFactoryBean</code> requires a <code>KafkaStreamsConfiguration</code> instance.
See the Apache Kafka <a href="https://kafka.apache.org/0102/documentation/#streamsconfigs">documentation</a> for all possible options.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Starting with version 2.2, the stream configuration is now provided as a <code>KafkaStreamsConfiguration</code> object, rather than as a <code>StreamsConfig</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>To avoid boilerplate code for most cases, especially when you develop microservices, Spring for Apache Kafka provides the <code>@EnableKafkaStreams</code> annotation, which you should place on a <code>@Configuration</code> class.
All you need is to declare a <code>KafkaStreamsConfiguration</code> bean named <code>defaultKafkaStreamsConfig</code>.
A <code>StreamsBuilderFactoryBean</code> bean, named <code>defaultKafkaStreamsBuilder</code>, is automatically declared in the application context.
You can declare and use any additional <code>StreamsBuilderFactoryBean</code> beans as well.
Starting with version 2.3, you can perform additional customization of that bean, by providing a bean that implements <code>StreamsBuilderFactoryBeanCustomizer</code>.
There must only be one such bean, or one must be marked <code>@Primary</code>.</p>
</div>
<div class="paragraph">
<p>By default, when the factory bean is stopped, the <code>KafkaStreams.cleanUp()</code> method is called.
Starting with version 2.1.2, the factory bean has additional constructors, taking a <code>CleanupConfig</code> object that has properties to let you control whether the <code>cleanUp()</code> method is called during <code>start()</code> or <code>stop()</code> or neither.</p>
</div>
</div>
<div class="sect3">
<h4 id="streams-header-enricher"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-header-enricher"></a>4.2.6. Header Enricher</h4>
<div class="paragraph">
<p>Version 2.3 added the <code>HeaderEnricher</code> implementation of <code>Transformer</code>.
This can be used to add headers within the stream processing; the header values are SpEL expressions; the root object of the expression evaluation has 3 properties:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>context</code> - the <code>ProcessorContext</code>, allowing access to the current record metadata</p>
</li>
<li>
<p><code>key</code> - the key of the current record</p>
</li>
<li>
<p><code>value</code> - the value of the current record</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The expressions must return a <code>byte[]</code> or a <code>String</code> (which will be converted to <code>byte[]</code> using <code>UTF-8</code>).</p>
</div>
<div class="paragraph">
<p>To use the enricher within a stream:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">.transform(() -&gt; enricher)</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The transformer does not change the <code>key</code> or <code>value</code>; it simply adds headers.</p>
</div>
</div>
<div class="sect3">
<h4 id="streams-messaging"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-messaging"></a>4.2.7. <code>MessagingTransformer</code></h4>
<div class="paragraph">
<p>Version 2.3 added the <code>MessagingTransformer</code> this allows a Kafka Streams topology to interact with a Spring Messaging component, such as a Spring Integration flow.
The transformer requires an implementation of <code>MessagingFunction</code>.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@FunctionalInterface</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">MessagingFunction</span> </span>{

	Message&lt;?&gt; exchange(Message&lt;?&gt; message);

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Spring Integration automatically provides an implementation using its <code>GatewayProxyFactoryBean</code>.
It also requires a <code>MessagingMessageConverter</code> to convert the key, value and metadata (including headers) to/from a Spring Messaging <code>Message&lt;?&gt;</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-integration">Calling a Spring Integration flow from a <code>KStream</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="streams-deser-recovery"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-deser-recovery"></a>4.2.8. Recovery from Deserialization Exceptions</h4>
<div class="paragraph">
<p>Version 2.3 introduced the <code>RecoveringDeserializationExceptionHandler</code> which can take some action when a deserialization exception occurs.
Refer to the Kafka documentation about <code>DeserializationExceptionHandler</code>, of which the <code>RecoveringDeserializationExceptionHandler</code> is an implementation.
The <code>RecoveringDeserializationExceptionHandler</code> is configured with a <code>ConsumerRecordRecoverer</code> implementation.
The framework provides the <code>DeadLetterPublishingRecoverer</code> which sends the failed record to a dead-letter topic.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters">Publishing Dead-letter Records</a> for more information about this recoverer.</p>
</div>
<div class="paragraph">
<p>To configure the recoverer, add the following properties to your streams configuration:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>(name = KafkaStreamsDefaultConfiguration.DEFAULT_STREAMS_CONFIG_BEAN_NAME)
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaStreamsConfiguration <span class="hljs-title">kStreamsConfigs</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    ...
    props.put(StreamsConfig.DEFAULT_DESERIALIZATION_EXCEPTION_HANDLER_CLASS_CONFIG,
            RecoveringDeserializationExceptionHandler.class);
    props.put(RecoveringDeserializationExceptionHandler.KSTREAM_DESERIALIZATION_RECOVERER, recoverer());
    ...
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaStreamsConfiguration(props);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> DeadLetterPublishingRecoverer <span class="hljs-title">recoverer</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DeadLetterPublishingRecoverer(kafkaTemplate(),
            (record, ex) -&gt; <span class="hljs-keyword">new</span> TopicPartition(<span class="hljs-string">"recovererDLQ"</span>, -<span class="hljs-number">1</span>));
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Of course, the <code>recoverer()</code> bean can be your own implementation of <code>ConsumerRecordRecoverer</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafka-streams-example"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-example"></a>4.2.9. Kafka Streams Example</h4>
<div class="paragraph">
<p>The following example combines all the topics we have covered in this chapter:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Configuration</span>
<span class="hljs-meta">@EnableKafka</span>
<span class="hljs-meta">@EnableKafkaStreams</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaStreamsConfig</span> </span>{

    <span class="hljs-meta">@Bean</span>(name = KafkaStreamsDefaultConfiguration.DEFAULT_STREAMS_CONFIG_BEAN_NAME)
    <span class="hljs-function"><span class="hljs-keyword">public</span> KafkaStreamsConfiguration <span class="hljs-title">kStreamsConfigs</span><span class="hljs-params">()</span> </span>{
        Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="hljs-string">"testStreams"</span>);
        props.put(StreamsConfig.KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass().getName());
        props.put(StreamsConfig.VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        props.put(StreamsConfig.TIMESTAMP_EXTRACTOR_CLASS_CONFIG, WallclockTimestampExtractor.class.getName());
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaStreamsConfiguration(props);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> StreamsBuilderFactoryBeanCustomizer <span class="hljs-title">customizer</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> fb -&gt; fb.setStateListener((newState, oldState) -&gt; {
            System.out.println(<span class="hljs-string">"State transition from "</span> + oldState + <span class="hljs-string">" to "</span> + newState);
        });
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> KStream&lt;Integer, String&gt; <span class="hljs-title">kStream</span><span class="hljs-params">(StreamsBuilder kStreamBuilder)</span> </span>{
        KStream&lt;Integer, String&gt; stream = kStreamBuilder.stream(<span class="hljs-string">"streamingTopic1"</span>);
        stream
                .mapValues(String::toUpperCase)
                .groupByKey()
                .reduce((String value1, String value2) -&gt; value1 + value2,
                		TimeWindows.of(<span class="hljs-number">1000</span>),
                		<span class="hljs-string">"windowStore"</span>)
                .toStream()
                .map((windowedId, value) -&gt; <span class="hljs-keyword">new</span> KeyValue&lt;&gt;(windowedId.key(), value))
                .filter((i, s) -&gt; s.length() &gt; <span class="hljs-number">40</span>)
                .to(<span class="hljs-string">"streamingTopic2"</span>);

        stream.print();

        <span class="hljs-keyword">return</span> stream;
    }

}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="testing"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#testing"></a>4.3. Testing Applications</h3>
<div class="paragraph">
<p>The <code>spring-kafka-test</code> jar contains some useful utilities to assist with testing your applications.</p>
</div>
<div class="sect3">
<h4 id="junit"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#junit"></a>4.3.1. JUnit</h4>
<div class="paragraph">
<p><code>o.s.kafka.test.utils.KafkaTestUtils</code> provides some static methods to set up producer and consumer properties.
The following listing shows those method signatures:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">/**
 * Set up test properties for an {<span class="hljs-doctag">@code</span> &lt;Integer, String&gt;} consumer.
 * <span class="hljs-doctag">@param</span> group the group id.
 * <span class="hljs-doctag">@param</span> autoCommit the auto commit.
 * <span class="hljs-doctag">@param</span> embeddedKafka a {<span class="hljs-doctag">@link</span> EmbeddedKafkaBroker} instance.
 * <span class="hljs-doctag">@return</span> the properties.
 */</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Map&lt;String, Object&gt; <span class="hljs-title">consumerProps</span><span class="hljs-params">(String group, String autoCommit,
                                       EmbeddedKafkaBroker embeddedKafka)</span> </span>{ ... }

<span class="hljs-comment">/**
 * Set up test properties for an {<span class="hljs-doctag">@code</span> &lt;Integer, String&gt;} producer.
 * <span class="hljs-doctag">@param</span> embeddedKafka a {<span class="hljs-doctag">@link</span> EmbeddedKafkaBroker} instance.
 * <span class="hljs-doctag">@return</span> the properties.
 */</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Map&lt;String, Object&gt; <span class="hljs-title">senderProps</span><span class="hljs-params">(EmbeddedKafkaBroker embeddedKafka)</span> </span>{ ... }</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>A JUnit 4 <code>@Rule</code> wrapper for the <code>EmbeddedKafkaBroker</code> is provided to create an embedded Kafka and an embedded Zookeeper server.
(See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-annotation">@EmbeddedKafka Annotation</a> for information about using <code>@EmbeddedKafka</code> with JUnit 5).
The following listing shows the signatures of those methods:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">/**
 * Create embedded Kafka brokers.
 * <span class="hljs-doctag">@param</span> count the number of brokers.
 * <span class="hljs-doctag">@param</span> controlledShutdown passed into TestUtils.createBrokerConfig.
 * <span class="hljs-doctag">@param</span> topics the topics to create (2 partitions per).
 */</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">EmbeddedKafkaRule</span><span class="hljs-params">(<span class="hljs-keyword">int</span> count, <span class="hljs-keyword">boolean</span> controlledShutdown, String... topics)</span> </span>{ ... }

<span class="hljs-comment">/**
 *
 * Create embedded Kafka brokers.
 * <span class="hljs-doctag">@param</span> count the number of brokers.
 * <span class="hljs-doctag">@param</span> controlledShutdown passed into TestUtils.createBrokerConfig.
 * <span class="hljs-doctag">@param</span> partitions partitions per topic.
 * <span class="hljs-doctag">@param</span> topics the topics to create.
 */</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">EmbeddedKafkaRule</span><span class="hljs-params">(<span class="hljs-keyword">int</span> count, <span class="hljs-keyword">boolean</span> controlledShutdown, <span class="hljs-keyword">int</span> partitions, String... topics)</span> </span>{ ... }</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>EmbeddedKafkaBroker</code> class has a utility method that lets you consume for all the topics it created.
The following example shows how to use it:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">Map&lt;String, Object&gt; consumerProps = KafkaTestUtils.consumerProps(<span class="hljs-string">"testT"</span>, <span class="hljs-string">"false"</span>, embeddedKafka);
DefaultKafkaConsumerFactory&lt;Integer, String&gt; cf = <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;Integer, String&gt;(
        consumerProps);
Consumer&lt;Integer, String&gt; consumer = cf.createConsumer();
embeddedKafka.consumeFromAllEmbeddedTopics(consumer);</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The <code>KafkaTestUtils</code> has some utility methods to fetch results from the consumer.
The following listing shows those method signatures:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">/**
 * Poll the consumer, expecting a single record for the specified topic.
 * <span class="hljs-doctag">@param</span> consumer the consumer.
 * <span class="hljs-doctag">@param</span> topic the topic.
 * <span class="hljs-doctag">@return</span> the record.
 * <span class="hljs-doctag">@throws</span> org.junit.ComparisonFailure if exactly one record is not received.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;K, V&gt; <span class="hljs-function">ConsumerRecord&lt;K, V&gt; <span class="hljs-title">getSingleRecord</span><span class="hljs-params">(Consumer&lt;K, V&gt; consumer, String topic)</span> </span>{ ... }

<span class="hljs-comment">/**
 * Poll the consumer for records.
 * <span class="hljs-doctag">@param</span> consumer the consumer.
 * <span class="hljs-doctag">@return</span> the records.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;K, V&gt; <span class="hljs-function">ConsumerRecords&lt;K, V&gt; <span class="hljs-title">getRecords</span><span class="hljs-params">(Consumer&lt;K, V&gt; consumer)</span> </span>{ ... }</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to use <code>KafkaTestUtils</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">...
template.sendDefault(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-string">"bar"</span>);
ConsumerRecord&lt;Integer, String&gt; received = KafkaTestUtils.getSingleRecord(consumer, <span class="hljs-string">"topic"</span>);
...</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When the embedded Kafka and embedded Zookeeper server are started by the <code>EmbeddedKafkaBroker</code>, a system property named <code>spring.embedded.kafka.brokers</code> is set to the address of the Kafka brokers and a system property named <code>spring.embedded.zookeeper.connect</code> is set to the address of Zookeeper.
Convenient constants (<code>EmbeddedKafkaBroker.SPRING_EMBEDDED_KAFKA_BROKERS</code> and <code>EmbeddedKafkaBroker.SPRING_EMBEDDED_ZOOKEEPER_CONNECT</code>) are provided for this property.</p>
</div>
<div class="paragraph">
<p>With the <code>EmbeddedKafkaBroker.brokerProperties(Map&lt;String, String&gt;)</code>, you can provide additional properties for the Kafka servers.
See <a href="https://kafka.apache.org/documentation/#brokerconfigs">Kafka Config</a> for more information about possible broker properties.</p>
</div>
</div>
<div class="sect3">
<h4 id="configuring-topics-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#configuring-topics-2"></a>4.3.2. Configuring Topics</h4>
<div class="paragraph">
<p>The following example configuration creates topics called <code>cat</code> and <code>hat</code> with five partitions, a topic called <code>thing1</code> with 10 partitions, and a topic called <code>thing2</code> with 15 partitions:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyTests</span> </span>{

    <span class="hljs-meta">@ClassRule</span>
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> EmbeddedKafkaRule embeddedKafka = <span class="hljs-keyword">new</span> EmbeddedKafkaRule(<span class="hljs-number">1</span>, <span class="hljs-keyword">false</span>, <span class="hljs-number">5</span>, <span class="hljs-string">"cat"</span>, <span class="hljs-string">"hat"</span>);

    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test</span><span class="hljs-params">()</span> </span>{
        embeddedKafkaRule.getEmbeddedKafka()
              .addTopics(<span class="hljs-keyword">new</span> NewTopic(<span class="hljs-string">"thing1"</span>, <span class="hljs-number">10</span>, (<span class="hljs-keyword">short</span>) <span class="hljs-number">1</span>), <span class="hljs-keyword">new</span> NewTopic(<span class="hljs-string">"thing2"</span>, <span class="hljs-number">15</span>, (<span class="hljs-keyword">short</span>) <span class="hljs-number">1</span>));
        ...
      }

}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="using-the-same-brokers-for-multiple-test-classes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-the-same-brokers-for-multiple-test-classes"></a>4.3.3. Using the Same Brokers for Multiple Test Classes</h4>
<div class="paragraph">
<p>There is no built-in support for doing so, but you can use the same broker for multiple test classes with something similar to the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">EmbeddedKafkaHolder</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> EmbeddedKafkaRule embeddedKafka = <span class="hljs-keyword">new</span> EmbeddedKafkaRule(<span class="hljs-number">1</span>, <span class="hljs-keyword">false</span>);

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> started;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> EmbeddedKafkaRule <span class="hljs-title">getEmbeddedKafka</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">if</span> (!started) {
            <span class="hljs-keyword">try</span> {
                embeddedKafka.before();
            }
            <span class="hljs-keyword">catch</span> (Exception e) {
                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> KafkaException(e);
            }
            started = <span class="hljs-keyword">true</span>;
        }
        <span class="hljs-keyword">return</span> embeddedKafka;
    }

    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-title">EmbeddedKafkaHolder</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">super</span>();
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Then, in each test class, you can use something similar to the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">static</span> {
    EmbeddedKafkaHolder.getEmbeddedKafka().addTopics(topic1, topic2);
}

<span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> EmbeddedKafkaRule embeddedKafka = EmbeddedKafkaHolder.getEmbeddedKafka();</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The preceding example provides no mechanism for shutting down the brokers when all tests are complete.
This could be a problem if, say, you run your tests in a Gradle daemon.
You should not use this technique in such a situation, or you should use something to call <code>destroy()</code> on the <code>EmbeddedKafkaBroker</code> when your tests are complete.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="embedded-kafka-annotation"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-annotation"></a>4.3.4. @EmbeddedKafka Annotation</h4>
<div class="paragraph">
<p>We generally recommend that you use the rule as a <code>@ClassRule</code> to avoid starting and stopping the broker between tests (and use a different topic for each test).
Starting with version 2.0, if you use Spring’s test application context caching, you can also declare a <code>EmbeddedKafkaBroker</code> bean, so a single broker can be used across multiple test classes.
For convenience, we provide a test class-level annotation called <code>@EmbeddedKafka</code> to register the <code>EmbeddedKafkaBroker</code> bean.
The following example shows how to use it:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@RunWith</span>(SpringRunner.class)
<span class="hljs-meta">@DirtiesContext</span>
<span class="hljs-meta">@EmbeddedKafka</span>(partitions = <span class="hljs-number">1</span>,
         topics = {
                 KafkaStreamsTests.STREAMING_TOPIC1,
                 KafkaStreamsTests.STREAMING_TOPIC2 })
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaStreamsTests</span> </span>{

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> EmbeddedKafkaBroker embeddedKafka;

    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">someTest</span><span class="hljs-params">()</span> </span>{
        Map&lt;String, Object&gt; consumerProps = KafkaTestUtils.consumerProps(<span class="hljs-string">"testGroup"</span>, <span class="hljs-string">"true"</span>, <span class="hljs-keyword">this</span>.embeddedKafka);
        consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="hljs-string">"earliest"</span>);
        ConsumerFactory&lt;Integer, String&gt; cf = <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(consumerProps);
        Consumer&lt;Integer, String&gt; consumer = cf.createConsumer();
        <span class="hljs-keyword">this</span>.embeddedKafka.consumeFromAnEmbeddedTopic(consumer, KafkaStreamsTests.STREAMING_TOPIC2);
        ConsumerRecords&lt;Integer, String&gt; replies = KafkaTestUtils.getRecords(consumer);
        assertThat(replies.count()).isGreaterThanOrEqualTo(<span class="hljs-number">1</span>);
    }

    <span class="hljs-meta">@Configuration</span>
    <span class="hljs-meta">@EnableKafkaStreams</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaStreamsConfiguration</span> </span>{

        <span class="hljs-meta">@Value</span>(<span class="hljs-string">"${"</span> + EmbeddedKafkaBroker.SPRING_EMBEDDED_KAFKA_BROKERS + <span class="hljs-string">"}"</span>)
        <span class="hljs-keyword">private</span> String brokerAddresses;

        <span class="hljs-meta">@Bean</span>(name = KafkaStreamsDefaultConfiguration.DEFAULT_STREAMS_CONFIG_BEAN_NAME)
        <span class="hljs-function"><span class="hljs-keyword">public</span> KafkaStreamsConfiguration <span class="hljs-title">kStreamsConfigs</span><span class="hljs-params">()</span> </span>{
            Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
            props.put(StreamsConfig.APPLICATION_ID_CONFIG, <span class="hljs-string">"testStreams"</span>);
            props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-keyword">this</span>.brokerAddresses);
            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaStreamsConfiguration(props);
        }

    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with version 2.2.4, you can also use the <code>@EmbeddedKafka</code> annotation to specify the Kafka ports property.</p>
</div>
<div class="paragraph">
<p>The following example sets the <code>topics</code>, <code>brokerProperties</code>, and <code>brokerPropertiesLocation</code> attributes of <code>@EmbeddedKafka</code> support property placeholder resolutions:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@TestPropertySource</span>(locations = <span class="hljs-string">"classpath:/test.properties"</span>)
<span class="hljs-meta">@EmbeddedKafka</span>(topics = { <span class="hljs-string">"any-topic"</span>, <span class="hljs-string">"${kafka.topics.another-topic}"</span> },
        brokerProperties = { <span class="hljs-string">"log.dir=${kafka.broker.logs-dir}"</span>,
                            <span class="hljs-string">"listeners=PLAINTEXT://localhost:${kafka.broker.port}"</span>,
                            <span class="hljs-string">"auto.create.topics.enable=${kafka.broker.topics-enable:true}"</span> }
        brokerPropertiesLocation = <span class="hljs-string">"classpath:/broker.properties"</span>)</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>In the preceding example, the property placeholders <code>${kafka.topics.another-topic}</code>, <code>${kafka.broker.logs-dir}</code>, and <code>${kafka.broker.port}</code> are resolved from the Spring <code>Environment</code>.
In addition, the broker properties are loaded from the <code>broker.properties</code> classpath resource specified by the <code>brokerPropertiesLocation</code>.
Property placeholders are resolved for the <code>brokerPropertiesLocation</code> URL and for any property placeholders found in the resource.
Properties defined by <code>brokerProperties</code> override properties found in <code>brokerPropertiesLocation</code>.</p>
</div>
<div class="paragraph">
<p>You can use the <code>@EmbeddedKafka</code> annotation with JUnit 4 or JUnit 5.</p>
</div>
</div>
<div class="sect3">
<h4 id="embedded-kafka-junit5"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-junit5"></a>4.3.5. @EmbeddedKafka Annotation with JUnit5</h4>
<div class="paragraph">
<p>Starting with version 2.3, there are two ways to use the <code>@EmbeddedKafka</code> annotation with JUnit5.
When used with the <code>@SpringJunitConfig</code> annotation, the embedded broker is added to the test application context.
You can auto wire the broker into your test, at the class or method level, to get the broker address list.</p>
</div>
<div class="paragraph">
<p>When <strong>not</strong> using the spring test context, the <code>EmbdeddedKafkaCondition</code> creates a broker; the condition includes a parameter resolver so you can access the broker in your test method…​</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@EmbeddedKafka</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">EmbeddedKafkaConditionTests</span> </span>{

	<span class="hljs-meta">@Test</span>
	<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test</span><span class="hljs-params">(EmbeddedKafkaBroker broker)</span> </span>{
		String brokerList = broker.getBrokersAsString();
        ...
	}

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>A stand-alone (not Spring test context) broker will be created if the class annotated with <code>@EmbeddedBroker</code> is not also annotated (or meta annotated) with <code>ExtendedWith(SpringExtension.class)</code>.
<code>@SpringJunitConfig</code> and <code>@SpringBootTest</code> are so meta annotated and the context-based broker will be used when either of those annotations are also present.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
When there is a Spring test application context available, the topics and broker properties can contain property placeholders, which will be resolved as long as the property is defined somewhere.
If there is no Spring context available, these placeholders won’t be resolved.
</td>
</tr>
</tbody></table>
</div>
</div>
<div class="sect3">
<h4 id="embedded-broker-in-springboottest-annotations"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-broker-in-springboottest-annotations"></a>4.3.6. Embedded Broker in <code>@SpringBootTest</code> Annotations</h4>
<div class="paragraph">
<p><a href="https://start.spring.io/">Spring Initializr</a> now automatically adds the <code>spring-kafka-test</code> dependency in test scope to the project configuration.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If your application uses the Kafka binder in <code>spring-cloud-stream</code> and if you want to use an embedded broker for tests, you must remove the <code>spring-cloud-stream-test-support</code> dependency, because it replaces the real binder with a test binder for test cases.
If you wish some tests to use the test binder and some to use the embedded broker, tests that use the real binder need to disable the test binder by excluding the binder auto configuration in the test class.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@RunWith</span>(SpringRunner.class)
<span class="hljs-meta">@SpringBootTest</span>(properties = <span class="hljs-string">"spring.autoconfigure.exclude="</span>
    + <span class="hljs-string">"org.springframework.cloud.stream.test.binder.TestSupportBinderAutoConfiguration"</span>)
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyApplicationTests</span> </span>{
    ...
}</code></pre>
</div>
</div>
</div>
</div>
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>There are several ways to use an embedded broker in a Spring Boot application test.</p>
</div>
<div class="paragraph">
<p>They include:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-junit4-class-rule">JUnit4 Class Rule</a></p>
</li>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-embeddedkafka-annotation"><code>@EmbeddedKafka</code> Annotation or <code>EmbeddedKafkaBroker</code> Bean</a></p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="kafka-testing-junit4-class-rule"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-junit4-class-rule"></a>JUnit4 Class Rule</h5>
<div class="paragraph">
<p>The following example shows how to use a JUnit4 class rule to create an embedded broker:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@RunWith</span>(SpringRunner.class)
<span class="hljs-meta">@SpringBootTest</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyApplicationTests</span> </span>{

    <span class="hljs-meta">@ClassRule</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> EmbeddedKafkaRule broker = <span class="hljs-keyword">new</span> EmbeddedKafkaRule(<span class="hljs-number">1</span>,
        <span class="hljs-keyword">false</span>, <span class="hljs-string">"someTopic"</span>)
            .brokerListProperty(<span class="hljs-string">"spring.kafka.bootstrap-servers"</span>);
    }

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> KafkaTemplate&lt;String, String&gt; template;

    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test</span><span class="hljs-params">()</span> </span>{
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Notice that, since this is a Spring Boot application, we override the broker list property to set Boot’s property.</p>
</div>
</div>
<div class="sect4">
<h5 id="kafka-testing-embeddedkafka-annotation"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-testing-embeddedkafka-annotation"></a><code>@EmbeddedKafka</code> Annotation or <code>EmbeddedKafkaBroker</code> Bean</h5>
<div class="paragraph">
<p>The following example shows how to use an <code>@EmbeddedKafka</code> Annotation to create an embedded broker:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@RunWith</span>(SpringRunner.class)
<span class="hljs-meta">@EmbeddedKafka</span>(topics = <span class="hljs-string">"someTopic"</span>,
        bootstrapServersProperty = <span class="hljs-string">"spring.kafka.bootstrap-servers"</span>)
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyApplicationTests</span> </span>{

    <span class="hljs-meta">@Autowired</span>
    <span class="hljs-keyword">private</span> KafkaTemplate&lt;String, String&gt; template;

    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">test</span><span class="hljs-params">()</span> </span>{
        ...
    }

}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="hamcrest-matchers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#hamcrest-matchers"></a>4.3.7. Hamcrest Matchers</h4>
<div class="paragraph">
<p>The <code>o.s.kafka.test.hamcrest.KafkaMatchers</code> provides the following matchers:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> key the key
 * <span class="hljs-doctag">@param</span> &lt;K&gt; the type.
 * <span class="hljs-doctag">@return</span> a Matcher that matches the key in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;K&gt; Matcher&lt;ConsumerRecord&lt;K, ?&gt;&gt; hasKey(K key) { ... }

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> value the value.
 * <span class="hljs-doctag">@param</span> &lt;V&gt; the type.
 * <span class="hljs-doctag">@return</span> a Matcher that matches the value in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;V&gt; Matcher&lt;ConsumerRecord&lt;?, V&gt;&gt; hasValue(V value) { ... }

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> partition the partition.
 * <span class="hljs-doctag">@return</span> a Matcher that matches the partition in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Matcher&lt;ConsumerRecord&lt;?, ?&gt;&gt; hasPartition(<span class="hljs-keyword">int</span> partition) { ... }

<span class="hljs-comment">/**
 * Matcher testing the timestamp of a {<span class="hljs-doctag">@link</span> ConsumerRecord} assuming the topic has been set with
 * {<span class="hljs-doctag">@link</span> org.apache.kafka.common.record.TimestampType#CREATE_TIME CreateTime}.
 *
 * <span class="hljs-doctag">@param</span> ts timestamp of the consumer record.
 * <span class="hljs-doctag">@return</span> a Matcher that matches the timestamp in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Matcher&lt;ConsumerRecord&lt;?, ?&gt;&gt; hasTimestamp(<span class="hljs-keyword">long</span> ts) {
  <span class="hljs-keyword">return</span> hasTimestamp(TimestampType.CREATE_TIME, ts);
}

<span class="hljs-comment">/**
 * Matcher testing the timestamp of a {<span class="hljs-doctag">@link</span> ConsumerRecord}
 * <span class="hljs-doctag">@param</span> type timestamp type of the record
 * <span class="hljs-doctag">@param</span> ts timestamp of the consumer record.
 * <span class="hljs-doctag">@return</span> a Matcher that matches the timestamp in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Matcher&lt;ConsumerRecord&lt;?, ?&gt;&gt; hasTimestamp(TimestampType type, <span class="hljs-keyword">long</span> ts) {
  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ConsumerRecordTimestampMatcher(type, ts);
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="assertj-conditions"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#assertj-conditions"></a>4.3.8. AssertJ Conditions</h4>
<div class="paragraph">
<p>You can use the following AssertJ conditions:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> key the key
 * <span class="hljs-doctag">@param</span> &lt;K&gt; the type.
 * <span class="hljs-doctag">@return</span> a Condition that matches the key in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;K&gt; Condition&lt;ConsumerRecord&lt;K, ?&gt;&gt; key(K key) { ... }

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> value the value.
 * <span class="hljs-doctag">@param</span> &lt;V&gt; the type.
 * <span class="hljs-doctag">@return</span> a Condition that matches the value in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;V&gt; Condition&lt;ConsumerRecord&lt;?, V&gt;&gt; value(V value) { ... }

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> key the key.
 * <span class="hljs-doctag">@param</span> value the value.
 * <span class="hljs-doctag">@param</span> &lt;K&gt; the key type.
 * <span class="hljs-doctag">@param</span> &lt;V&gt; the value type.
 * <span class="hljs-doctag">@return</span> a Condition that matches the key in a consumer record.
 * <span class="hljs-doctag">@since</span> 2.2.12
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> &lt;K, V&gt; Condition&lt;ConsumerRecord&lt;K, V&gt;&gt; keyValue(K key, V value) { ... }

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> partition the partition.
 * <span class="hljs-doctag">@return</span> a Condition that matches the partition in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Condition&lt;ConsumerRecord&lt;?, ?&gt;&gt; partition(<span class="hljs-keyword">int</span> partition) { ... }

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> value the timestamp.
 * <span class="hljs-doctag">@return</span> a Condition that matches the timestamp value in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Condition&lt;ConsumerRecord&lt;?, ?&gt;&gt; timestamp(<span class="hljs-keyword">long</span> value) {
  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ConsumerRecordTimestampCondition(TimestampType.CREATE_TIME, value);
}

<span class="hljs-comment">/**
 * <span class="hljs-doctag">@param</span> type the type of timestamp
 * <span class="hljs-doctag">@param</span> value the timestamp.
 * <span class="hljs-doctag">@return</span> a Condition that matches the timestamp value in a consumer record.
 */</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Condition&lt;ConsumerRecord&lt;?, ?&gt;&gt; timestamp(TimestampType type, <span class="hljs-keyword">long</span> value) {
  <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ConsumerRecordTimestampCondition(type, value);
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="example"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#example"></a>4.3.9. Example</h4>
<div class="paragraph">
<p>The following example brings together most of the topics covered in this chapter:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">KafkaTemplateTests</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> String TEMPLATE_TOPIC = <span class="hljs-string">"templateTopic"</span>;

    <span class="hljs-meta">@ClassRule</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> EmbeddedKafkaRule embeddedKafka = <span class="hljs-keyword">new</span> EmbeddedKafkaRule(<span class="hljs-number">1</span>, <span class="hljs-keyword">true</span>, TEMPLATE_TOPIC);

    <span class="hljs-meta">@Test</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testTemplate</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>{
        Map&lt;String, Object&gt; consumerProps = KafkaTestUtils.consumerProps(<span class="hljs-string">"testT"</span>, <span class="hljs-string">"false"</span>,
            embeddedKafka.getEmbeddedKafka());
        DefaultKafkaConsumerFactory&lt;Integer, String&gt; cf =
                            <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;Integer, String&gt;(consumerProps);
        ContainerProperties containerProperties = <span class="hljs-keyword">new</span> ContainerProperties(TEMPLATE_TOPIC);
        KafkaMessageListenerContainer&lt;Integer, String&gt; container =
                            <span class="hljs-keyword">new</span> KafkaMessageListenerContainer&lt;&gt;(cf, containerProperties);
        <span class="hljs-keyword">final</span> BlockingQueue&lt;ConsumerRecord&lt;Integer, String&gt;&gt; records = <span class="hljs-keyword">new</span> LinkedBlockingQueue&lt;&gt;();
        container.setupMessageListener(<span class="hljs-keyword">new</span> MessageListener&lt;Integer, String&gt;() {

            <span class="hljs-meta">@Override</span>
            <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onMessage</span><span class="hljs-params">(ConsumerRecord&lt;Integer, String&gt; record)</span> </span>{
                System.out.println(record);
                records.add(record);
            }

        });
        container.setBeanName(<span class="hljs-string">"templateTests"</span>);
        container.start();
        ContainerTestUtils.waitForAssignment(container, embeddedKafka.getEmbeddedKafka().getPartitionsPerTopic());
        Map&lt;String, Object&gt; senderProps =
                            KafkaTestUtils.senderProps(embeddedKafka.getEmbeddedKafka().getBrokersAsString());
        ProducerFactory&lt;Integer, String&gt; pf =
                            <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;Integer, String&gt;(senderProps);
        KafkaTemplate&lt;Integer, String&gt; template = <span class="hljs-keyword">new</span> KafkaTemplate&lt;&gt;(pf);
        template.setDefaultTopic(TEMPLATE_TOPIC);
        template.sendDefault(<span class="hljs-string">"foo"</span>);
        assertThat(records.poll(<span class="hljs-number">10</span>, TimeUnit.SECONDS), hasValue(<span class="hljs-string">"foo"</span>));
        template.sendDefault(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-string">"bar"</span>);
        ConsumerRecord&lt;Integer, String&gt; received = records.poll(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
        assertThat(received, hasKey(<span class="hljs-number">2</span>));
        assertThat(received, hasPartition(<span class="hljs-number">0</span>));
        assertThat(received, hasValue(<span class="hljs-string">"bar"</span>));
        template.send(TEMPLATE_TOPIC, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-string">"baz"</span>);
        received = records.poll(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
        assertThat(received, hasKey(<span class="hljs-number">2</span>));
        assertThat(received, hasPartition(<span class="hljs-number">0</span>));
        assertThat(received, hasValue(<span class="hljs-string">"baz"</span>));
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The preceding example uses the Hamcrest matchers.
With <code>AssertJ</code>, the final part looks like the following code:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">assertThat(records.poll(<span class="hljs-number">10</span>, TimeUnit.SECONDS)).has(value(<span class="hljs-string">"foo"</span>));
template.sendDefault(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-string">"bar"</span>);
ConsumerRecord&lt;Integer, String&gt; received = records.poll(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
<span class="hljs-comment">// using individual assertions</span>
assertThat(received).has(key(<span class="hljs-number">2</span>));
assertThat(received).has(value(<span class="hljs-string">"bar"</span>));
assertThat(received).has(partition(<span class="hljs-number">0</span>));
template.send(TEMPLATE_TOPIC, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-string">"baz"</span>);
received = records.poll(<span class="hljs-number">10</span>, TimeUnit.SECONDS);
<span class="hljs-comment">// using allOf()</span>
assertThat(received).has(allOf(keyValue(<span class="hljs-number">2</span>, <span class="hljs-string">"baz"</span>), partition(<span class="hljs-number">0</span>)));</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="tips-n-tricks"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tips-n-tricks"></a>5. Tips, Tricks and Examples</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="tip-assign-all-parts"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tip-assign-all-parts"></a>5.1. Manually Assigning All Partitions</h3>
<div class="paragraph">
<p>Let’s say you want to always read all records from all partitions (such as when using a compacted topic to load a distributed cache), it can be useful to manually assign the partitions and not use Kafka’s group management.
Doing so can be unwieldy when there are many partitions, because you have to list the partitions.
It’s also an issue if the number of partitions changes over time, because you would have to recompile your application each time the partition count changes.</p>
</div>
<div class="paragraph">
<p>The following is an example of how to use the power of a SpEL expression to create the partition list dynamically when the application starts:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@KafkaListener</span>(topicPartitions = <span class="hljs-meta">@TopicPartition</span>(topic = <span class="hljs-string">"compacted"</span>,
                                                 partitions = <span class="hljs-string">"#{@finder.partitions('compacted')}"</span>))
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen</span><span class="hljs-params">(@Header(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> String key, String payload) </span>{
    ...
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> PartitionFinder <span class="hljs-title">finder</span><span class="hljs-params">(ConsumerFactory&lt;String, String&gt; consumerFactory)</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> PartitionFinder(consumerFactory);
}

<span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PartitionFinder</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> ConsumerFactory&lt;String, String&gt; consumerFactory;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">PartitionFinder</span><span class="hljs-params">(ConsumerFactory&lt;String, String&gt; consumerFactory)</span> </span>{
        <span class="hljs-keyword">this</span>.consumerFactory = consumerFactory;
    }

    <span class="hljs-keyword">public</span> String[] partitions(String topic) {
        <span class="hljs-keyword">try</span> (Consumer&lt;String, String&gt; consumer = consumerFactory.createConsumer()) {
            <span class="hljs-keyword">return</span> consumer.partitionsFor(topic).stream()
                .map(pi -&gt; <span class="hljs-string">""</span> + pi.partition())
                .toArray(String[]::<span class="hljs-keyword">new</span>);
        }
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Using this in conjunction with <code>ConsumerConfig.AUTO_OFFSET_RESET_CONFIG=earliest</code> will load all records each time the application is started.
You should also set the container’s <code>AckMode</code> to <code>MANUAL</code> to prevent the container from committing offsets for a <code>null</code> consumer group.</p>
</div>
</div>
<div class="sect2">
<h3 id="ex-jdbc-sync"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#ex-jdbc-sync"></a>5.2. Example of Transaction Synchronization</h3>
<div class="paragraph">
<p>The following Spring Boot application is an example of synchronizing database and Kafka transactions.</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@SpringBootApplication</span>
<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Application</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SpringApplication.run(Application.class, args);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ApplicationRunner <span class="hljs-title">runner</span><span class="hljs-params">(KafkaTemplate&lt;String, String&gt; template)</span> </span>{
        <span class="hljs-keyword">return</span> args -&gt; template.executeInTransaction(t -&gt; t.send(<span class="hljs-string">"topic1"</span>, <span class="hljs-string">"test"</span>));
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> ChainedKafkaTransactionManager&lt;Object, Object&gt; <span class="hljs-title">chainedTm</span><span class="hljs-params">(
            KafkaTransactionManager&lt;String, String&gt; ktm,
            DataSourceTransactionManager dstm)</span> </span>{

        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ChainedKafkaTransactionManager&lt;&gt;(ktm, dstm);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> DataSourceTransactionManager <span class="hljs-title">dstm</span><span class="hljs-params">(DataSource dataSource)</span> </span>{
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DataSourceTransactionManager(dataSource);
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-keyword">public</span> ConcurrentKafkaListenerContainerFactory&lt;?, ?&gt; kafkaListenerContainerFactory(
            ConcurrentKafkaListenerContainerFactoryConfigurer configurer,
            ConsumerFactory&lt;Object, Object&gt; kafkaConsumerFactory,
            ChainedKafkaTransactionManager&lt;Object, Object&gt; chainedTM) {

        ConcurrentKafkaListenerContainerFactory&lt;Object, Object&gt; factory =
                <span class="hljs-keyword">new</span> ConcurrentKafkaListenerContainerFactory&lt;&gt;();
        configurer.configure(factory, kafkaConsumerFactory);
        factory.getContainerProperties().setTransactionManager(chainedTM);
        <span class="hljs-keyword">return</span> factory;
    }

    <span class="hljs-meta">@Component</span>
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Listener</span> </span>{

        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> JdbcTemplate jdbcTemplate;

        <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> KafkaTemplate&lt;String, String&gt; kafkaTemplate;

        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Listener</span><span class="hljs-params">(JdbcTemplate jdbcTemplate, KafkaTemplate&lt;String, String&gt; kafkaTemplate)</span> </span>{
            <span class="hljs-keyword">this</span>.jdbcTemplate = jdbcTemplate;
            <span class="hljs-keyword">this</span>.kafkaTemplate = kafkaTemplate;
        }

        <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"group1"</span>, topics = <span class="hljs-string">"topic1"</span>)
        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen1</span><span class="hljs-params">(String in)</span> </span>{
            <span class="hljs-keyword">this</span>.kafkaTemplate.send(<span class="hljs-string">"topic2"</span>, in.toUpperCase());
            <span class="hljs-keyword">this</span>.jdbcTemplate.execute(<span class="hljs-string">"insert into mytable (data) values ('"</span> + in + <span class="hljs-string">"')"</span>);
        }

        <span class="hljs-meta">@KafkaListener</span>(id = <span class="hljs-string">"group2"</span>, topics = <span class="hljs-string">"topic2"</span>)
        <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listen2</span><span class="hljs-params">(String in)</span> </span>{
            System.out.println(in);
        }

    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic1</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"topic1"</span>).build();
    }

    <span class="hljs-meta">@Bean</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> NewTopic <span class="hljs-title">topic2</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> TopicBuilder.name(<span class="hljs-string">"topic2"</span>).build();
    }

}</code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-properties hljs" data-lang="properties"><span class="hljs-meta">spring.datasource.url</span>=<span class="hljs-string">jdbc:mysql://localhost/integration?serverTimezone=UTC</span>
<span class="hljs-meta">spring.datasource.username</span>=<span class="hljs-string">root</span>
<span class="hljs-meta">spring.datasource.driver-class-name</span>=<span class="hljs-string">com.mysql.cj.jdbc.Driver</span>

<span class="hljs-meta">spring.kafka.consumer.auto-offset-reset</span>=<span class="hljs-string">earliest</span>
<span class="hljs-meta">spring.kafka.consumer.enable-auto-commit</span>=<span class="hljs-string">false</span>
<span class="hljs-meta">spring.kafka.consumer.properties.isolation.level</span>=<span class="hljs-string">read_committed</span>

<span class="hljs-meta">spring.kafka.producer.transaction-id-prefix</span>=<span class="hljs-string">tx-</span>
<span class="hljs-comment">
#logging.level.org.springframework.transaction=trace</span>
<span class="hljs-comment">#logging.level.org.springframework.kafka.transaction=debug</span>
<span class="hljs-comment">#logging.level.org.springframework.jdbc=debug</span></code></pre>
</div>
</div>
</div>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-sql hljs" data-lang="sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> mytable (<span class="hljs-keyword">data</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">20</span>));</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="spring-integration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-integration"></a>6. Spring Integration</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This part of the reference guide shows how to use the <code>spring-integration-kafka</code> module of Spring Integration.</p>
</div>
<div class="sect2">
<h3 id="si-kafka"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-kafka"></a>6.1. Spring Integration for Apache Kafka</h3>
<div class="sect3">
<h4 id="overview-4"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#overview-4"></a>6.1.1. Overview</h4>
<div class="paragraph">
<p>This documentation pertains to versions 2.0.0 and above.
For documentation for earlier releases, see the <a href="https://github.com/spring-projects/spring-integration-kafka/blob/1.3.x/README.md">1.3.x README</a>.</p>
</div>
<div class="paragraph">
<p>Spring Integration Kafka is an extension module to the <a href="https://spring.io/projects/spring-integration">Spring Integration Project</a>.</p>
</div>
<div class="paragraph">
<p>Spring Integration Kafka is now based on the <a href="https://projects.spring.io/spring-kafka/">Spring for Apache Kafka project</a>.
It provides the following components:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound">Outbound Channel Adapter</a></p>
</li>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound">Message-driven Channel Adapter</a></p>
</li>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-pollable">Inbound Channel Adapter</a></p>
</li>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound-gateway">Outbound Gateway</a></p>
</li>
<li>
<p><a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-gateway">Inbound Gateway</a></p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="new-in-sik"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#new-in-sik"></a>6.1.2. What’s new in Spring Integration for Apache Kafka (version 3.2)</h4>
<div class="ulist">
<ul>
<li>
<p>The pollable <code>KafkaMessageSource</code> now implements <code>Pausable</code> so the consumer can be <code>paused</code> and <code>resumed</code>.
You must continue to poll the adapter while paused, to avoid a topic/partition rebalance.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#max-poll-records">the discussion about <code>max.poll.records</code></a> for more information.</p>
</li>
<li>
<p>XML configuration is now supported for the gateways and polled inbound channel adapter (in addition to the existing XML support for the other adapters).</p>
</li>
<li>
<p>The pollable message source can now be configured to fetch multiple records at-a-time.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="si-outbound"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound"></a>6.1.3. Outbound Channel Adapter</h4>
<div class="paragraph">
<p>The Outbound channel adapter is used to publish messages from a Spring Integration channel to Kafka topics.
The channel is defined in the application context and then wired into the application that sends messages to Kafka.
Sender applications can publish to Kafka by using Spring Integration messages, which are internally converted to Kafka messages by the outbound channel adapter, as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The payload of the Spring Integration message is used to populate the payload of the Kafka message.</p>
</li>
<li>
<p>By default, the <code>kafka_messageKey</code> header of the Spring Integration message is used to populate the key of the Kafka message.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can customize the target topic and partition for publishing the message through the <code>kafka_topic</code>
and <code>kafka_partitionId</code> headers, respectively.</p>
</div>
<div class="paragraph">
<p>In addition, the <code>&lt;int-kafka:outbound-channel-adapter&gt;</code> provides the ability to extract the key, target topic, and target partition by applying SpEL expressions on the outbound message.
To that end, it supports three mutually exclusive pairs of attributes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>topic</code> and <code>topic-expression</code></p>
</li>
<li>
<p><code>message-key</code> and <code>message-key-expression</code></p>
</li>
<li>
<p><code>partition-id</code> and <code>partition-id-expression</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These let you specify <code>topic</code>, <code>message-key</code>, and <code>partition-id</code>, respectively, as static values on the adapter or to dynamically evaluate their values at runtime against the request message.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The <code>KafkaHeaders</code> interface (provided by <code>spring-kafka</code>) contains constants used for interacting with
headers.
The <code>messageKey</code> and <code>topic</code> default headers now require a <code>kafka_</code> prefix.
When migrating from an earlier version that used the old headers, you need to specify
<code>message-key-expression="headers['messageKey']"</code> and <code>topic-expression="headers['topic']"</code> on the
<code>&lt;int-kafka:outbound-channel-adapter&gt;</code>.
Alternatively, you can change the headers upstream to
the new headers from <code>KafkaHeaders</code> by using a <code>&lt;header-enricher&gt;</code> or a <code>MessageBuilder</code>.
If you use constant values, you can also configure them on the adapter by using <code>topic</code> and <code>message-key</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>NOTE : If the adapter is configured with a topic or message key (either with a constant or expression), those are used
and the corresponding header is ignored.
If you wish the header to override the configuration, you need to configure it in an expression, such as the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java">topic-expression=<span class="hljs-string">"headers['topic'] != null ? headers['topic'] : 'myTopic'"</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The adapter requires a <code>KafkaTemplate</code>, which, in turn, requires a suitably configured <code>KafkaProducerFactory</code>.</p>
</div>
<div class="paragraph">
<p>If a <code>send-failure-channel</code> (<code>sendFailureChannel</code>) is provided and a send failure (sync or async) is received, an <code>ErrorMessage</code> is sent to the channel.
The payload is a <code>KafkaSendFailureException</code> with <code>failedMessage</code>, <code>record</code> (the <code>ProducerRecord</code>) and <code>cause</code> properties.
You can override the <code>DefaultErrorMessageStrategy</code> by setting the <code>error-message-strategy</code> property.</p>
</div>
<div class="paragraph">
<p>If a <code>send-success-channel</code> (<code>sendSuccessChannel</code>) is provided, a message with a payload of type <code>org.apache.kafka.clients.producer.RecordMetadata</code> is sent after a successful send.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
If your application uses transactions and the same channel adapter is used to publish messages where the transaction is started by a listener container, as well as publishing where there is no existing transaction, you must configure a <code>transactionIdPrefix</code> on the <code>KafkaTemplate</code> to override the prefix used by the container or transaction manager.
The prefix used by container-initiated transactions (the producer factory or transaction manager property) must be the same on all application instances.
The prefix used for producer-only transactions must be unique on all application instances.
</td>
</tr>
</tbody></table>
</div>
<div class="sect4">
<h5 id="java-configuration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration"></a>Java Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure the Kafka outbound channel adapter with Java:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-meta">@ServiceActivator</span>(inputChannel = <span class="hljs-string">"toKafka"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> MessageHandler <span class="hljs-title">handler</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>{
    KafkaProducerMessageHandler&lt;String, String&gt; handler =
            <span class="hljs-keyword">new</span> KafkaProducerMessageHandler&lt;&gt;(kafkaTemplate());
    handler.setTopicExpression(<span class="hljs-keyword">new</span> LiteralExpression(<span class="hljs-string">"someTopic"</span>));
    handler.setMessageKeyExpression(<span class="hljs-keyword">new</span> LiteralExpression(<span class="hljs-string">"someKey"</span>));
    handler.setSuccessChannel(successes());
    handler.setFailureChannel(failures());
    <span class="hljs-keyword">return</span> handler;
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaTemplate&lt;String, String&gt; <span class="hljs-title">kafkaTemplate</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaTemplate&lt;&gt;(producerFactory());
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ProducerFactory&lt;String, String&gt; <span class="hljs-title">producerFactory</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-keyword">this</span>.brokerAddress);
    <span class="hljs-comment">// set more properties</span>
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(props);
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="java-dsl-configuration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration"></a>Java DSL Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure the Kafka outbound channel adapter Spring Integration Java DSL:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ProducerFactory&lt;Integer, String&gt; <span class="hljs-title">producerFactory</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaProducerFactory&lt;&gt;(KafkaTestUtils.producerProps(embeddedKafka));
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">sendToKafkaFlow</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> f -&gt; f
            .&lt;String&gt;split(p -&gt; Stream.generate(() -&gt; p).limit(<span class="hljs-number">101</span>).iterator(), <span class="hljs-keyword">null</span>)
            .publishSubscribeChannel(c -&gt; c
                    .subscribe(sf -&gt; sf.handle(
                            kafkaMessageHandler(producerFactory(), TEST_TOPIC1)
                                    .timestampExpression(<span class="hljs-string">"T(Long).valueOf('1487694048633')"</span>),
                            e -&gt; e.id(<span class="hljs-string">"kafkaProducer1"</span>)))
                    .subscribe(sf -&gt; sf.handle(
                            kafkaMessageHandler(producerFactory(), TEST_TOPIC2)
                                   .timestamp(m -&gt; <span class="hljs-number">1487694048644L</span>),
                            e -&gt; e.id(<span class="hljs-string">"kafkaProducer2"</span>)))
            );
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> DefaultKafkaHeaderMapper <span class="hljs-title">mapper</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaHeaderMapper();
}

<span class="hljs-keyword">private</span> KafkaProducerMessageHandlerSpec&lt;Integer, String, ?&gt; kafkaMessageHandler(
        ProducerFactory&lt;Integer, String&gt; producerFactory, String topic) {
    <span class="hljs-keyword">return</span> Kafka
            .outboundChannelAdapter(producerFactory)
            .messageKey(m -&gt; m
                    .getHeaders()
                    .get(IntegrationMessageHeaderAccessor.SEQUENCE_NUMBER))
            .headerMapper(mapper())
            .partitionId(m -&gt; <span class="hljs-number">10</span>)
            .topicExpression(<span class="hljs-string">"headers[kafka_topic] ?: '"</span> + topic + <span class="hljs-string">"'"</span>)
            .configureKafkaTemplate(t -&gt; t.id(<span class="hljs-string">"kafkaTemplate:"</span> + topic));
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="xml-configuration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration"></a>XML Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure the Kafka outbound channel adapter with XML:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">int-kafka:outbound-channel-adapter</span> <span class="hljs-attr">id</span>=<span class="hljs-string">"kafkaOutboundChannelAdapter"</span>
                                    <span class="hljs-attr">kafka-template</span>=<span class="hljs-string">"template"</span>
                                    <span class="hljs-attr">auto-startup</span>=<span class="hljs-string">"false"</span>
                                    <span class="hljs-attr">channel</span>=<span class="hljs-string">"inputToKafka"</span>
                                    <span class="hljs-attr">topic</span>=<span class="hljs-string">"foo"</span>
                                    <span class="hljs-attr">sync</span>=<span class="hljs-string">"false"</span>
                                    <span class="hljs-attr">message-key-expression</span>=<span class="hljs-string">"'bar'"</span>
                                    <span class="hljs-attr">send-failure-channel</span>=<span class="hljs-string">"failures"</span>
                                    <span class="hljs-attr">send-success-channel</span>=<span class="hljs-string">"successes"</span>
                                    <span class="hljs-attr">error-message-strategy</span>=<span class="hljs-string">"ems"</span>
                                    <span class="hljs-attr">partition-id-expression</span>=<span class="hljs-string">"2"</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">int-kafka:outbound-channel-adapter</span>&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-name">bean</span> <span class="hljs-attr">id</span>=<span class="hljs-string">"template"</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"org.springframework.kafka.core.KafkaTemplate"</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">constructor-arg</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">bean</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"org.springframework.kafka.core.DefaultKafkaProducerFactory"</span>&gt;</span>
            <span class="hljs-tag">&lt;<span class="hljs-name">constructor-arg</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-name">map</span>&gt;</span>
                    <span class="hljs-tag">&lt;<span class="hljs-name">entry</span> <span class="hljs-attr">key</span>=<span class="hljs-string">"bootstrap.servers"</span> <span class="hljs-attr">value</span>=<span class="hljs-string">"localhost:9092"</span> /&gt;</span>
                    ... <span class="hljs-comment">&lt;!-- more producer properties --&gt;</span>
                <span class="hljs-tag">&lt;/<span class="hljs-name">map</span>&gt;</span>
            <span class="hljs-tag">&lt;/<span class="hljs-name">constructor-arg</span>&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-name">bean</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">constructor-arg</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">bean</span>&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="si-inbound"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound"></a>6.1.4. Message-driven Channel Adapter</h4>
<div class="paragraph">
<p>The <code>KafkaMessageDrivenChannelAdapter</code> (<code>&lt;int-kafka:message-driven-channel-adapter&gt;</code>) uses a <code>spring-kafka</code> <code>KafkaMessageListenerContainer</code> or <code>ConcurrentListenerContainer</code>.</p>
</div>
<div class="paragraph">
<p>Starting with spring-integration-kafka version 2.1, the <code>mode</code> attribute is available.
It can accept values of <code>record</code> or <code>batch</code> (default: <code>record</code>).
For <code>record</code> mode, each message payload is converted from a single <code>ConsumerRecord</code>.
For <code>batch</code> mode, the payload is a list of objects that are converted from all the <code>ConsumerRecord</code> instances returned by the consumer poll.
As with the batched <code>@KafkaListener</code>, the <code>KafkaHeaders.RECEIVED_MESSAGE_KEY</code>, <code>KafkaHeaders.RECEIVED_PARTITION_ID</code>, <code>KafkaHeaders.RECEIVED_TOPIC</code>, and <code>KafkaHeaders.OFFSET</code> headers are also lists, with positions corresponding to the position in the payload.</p>
</div>
<div class="paragraph">
<p>Received messages have certain headers populated.
See the <a href="https://docs.spring.io/spring-kafka/api/org/springframework/kafka/support/KafkaHeaders.html"><code>KafkaHeaders</code> class</a> for more information.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The <code>Consumer</code> object (in the <code>kafka_consumer</code> header) is not thread-safe.
You must invoke its methods only on the thread that calls the listener within the adapter.
If you hand off the message to another thread, you must not call its methods.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>When a <code>retry-template</code> is provided, delivery failures are retried according to its retry policy.
An <code>error-channel</code> is not allowed in this case.
You can use the <code>recovery-callback</code> to handle the error when retries are exhausted.
In most cases, this is an <code>ErrorMessageSendingRecoverer</code> that sends the <code>ErrorMessage</code> to a channel.</p>
</div>
<div class="paragraph">
<p>When building an <code>ErrorMessage</code> (for use in the <code>error-channel</code> or <code>recovery-callback</code>), you can customize the error message by setting the <code>error-message-strategy</code> property.
By default, a <code>RawRecordHeaderErrorMessageStrategy</code> is used, to provide access to the converted message as well as the raw <code>ConsumerRecord</code>.</p>
</div>
<div class="sect4">
<h5 id="java-configuration-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-2"></a>Java Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure a message-driven channel adapter with Java:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaMessageDrivenChannelAdapter&lt;String, String&gt;
            <span class="hljs-title">adapter</span><span class="hljs-params">(KafkaMessageListenerContainer&lt;String, String&gt; container)</span> </span>{
    KafkaMessageDrivenChannelAdapter&lt;String, String&gt; kafkaMessageDrivenChannelAdapter =
            <span class="hljs-keyword">new</span> KafkaMessageDrivenChannelAdapter&lt;&gt;(container, ListenerMode.record);
    kafkaMessageDrivenChannelAdapter.setOutputChannel(received());
    <span class="hljs-keyword">return</span> kafkaMessageDrivenChannelAdapter;
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaMessageListenerContainer&lt;String, String&gt; <span class="hljs-title">container</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception </span>{
    ContainerProperties properties = <span class="hljs-keyword">new</span> ContainerProperties(<span class="hljs-keyword">this</span>.topic);
    <span class="hljs-comment">// set more properties</span>
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaMessageListenerContainer&lt;&gt;(consumerFactory(), properties);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> ConsumerFactory&lt;String, String&gt; <span class="hljs-title">consumerFactory</span><span class="hljs-params">()</span> </span>{
    Map&lt;String, Object&gt; props = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();
    props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="hljs-keyword">this</span>.brokerAddress);
    <span class="hljs-comment">// set more properties</span>
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> DefaultKafkaConsumerFactory&lt;&gt;(props);
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="java-dsl-configuration-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-2"></a>Java DSL Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure a message-driven channel adapter with the Spring Integration Java DSL:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">topic1ListenerFromKafkaFlow</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows
            .from(Kafka.messageDrivenChannelAdapter(consumerFactory(),
                    KafkaMessageDrivenChannelAdapter.ListenerMode.record, TEST_TOPIC1)
                    .configureListenerContainer(c -&gt;
                            c.ackMode(AbstractMessageListenerContainer.AckMode.MANUAL)
                                    .id(<span class="hljs-string">"topic1ListenerContainer"</span>))
                    .recoveryCallback(<span class="hljs-keyword">new</span> ErrorMessageSendingRecoverer(errorChannel(),
                            <span class="hljs-keyword">new</span> RawRecordHeaderErrorMessageStrategy()))
                    .retryTemplate(<span class="hljs-keyword">new</span> RetryTemplate())
                    .filterInRetry(<span class="hljs-keyword">true</span>))
            .filter(Message.class, m -&gt;
                            m.getHeaders().get(KafkaHeaders.RECEIVED_MESSAGE_KEY, Integer.class) &lt; <span class="hljs-number">101</span>,
                    f -&gt; f.throwExceptionOnRejection(<span class="hljs-keyword">true</span>))
            .&lt;String, String&gt;transform(String::toUpperCase)
            .channel(c -&gt; c.queue(<span class="hljs-string">"listeningFromKafkaResults1"</span>))
            .get();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with Spring for Apache Kafka version 2.2 (Spring Integration Kafka 3.1), you can also use the container factory that is used for <code>@KafkaListener</code> annotations to create <code>ConcurrentMessageListenerContainer</code> instances for other purposes.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory">Container factory</a> for an example.</p>
</div>
<div class="paragraph">
<p>With the Java DSL, the container does not have to be configured as a <code>@Bean</code>, because the DSL registers the container as a bean.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">topic2ListenerFromKafkaFlow</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows
            .from(Kafka.messageDrivenChannelAdapter(kafkaListenerContainerFactory().createContainer(TEST_TOPIC2),
            KafkaMessageDrivenChannelAdapter.ListenerMode.record)
                .id(<span class="hljs-string">"topic2Adapter"</span>))
            ...
            get();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Notice that, in this case, the adapter is given an <code>id</code> (<code>topic2Adapter</code>).
The container is registered in the application context with a name of <code>topic2Adapter.container</code>.
If the adapter does not have an <code>id</code> property, the container’s bean name is the container’s fully qualified class name plus <code>#n</code>, where <code>n</code> is incremented for each container.</p>
</div>
</div>
<div class="sect4">
<h5 id="xml-configuration-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-2"></a>XML Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure a message-driven channel adapter with XML:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">int-kafka:message-driven-channel-adapter</span>
        <span class="hljs-attr">id</span>=<span class="hljs-string">"kafkaListener"</span>
        <span class="hljs-attr">listener-container</span>=<span class="hljs-string">"container1"</span>
        <span class="hljs-attr">auto-startup</span>=<span class="hljs-string">"false"</span>
        <span class="hljs-attr">phase</span>=<span class="hljs-string">"100"</span>
        <span class="hljs-attr">send-timeout</span>=<span class="hljs-string">"5000"</span>
        <span class="hljs-attr">mode</span>=<span class="hljs-string">"record"</span>
        <span class="hljs-attr">retry-template</span>=<span class="hljs-string">"template"</span>
        <span class="hljs-attr">recovery-callback</span>=<span class="hljs-string">"callback"</span>
        <span class="hljs-attr">error-message-strategy</span>=<span class="hljs-string">"ems"</span>
        <span class="hljs-attr">channel</span>=<span class="hljs-string">"someChannel"</span>
        <span class="hljs-attr">error-channel</span>=<span class="hljs-string">"errorChannel"</span> /&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-name">bean</span> <span class="hljs-attr">id</span>=<span class="hljs-string">"container1"</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"org.springframework.kafka.listener.KafkaMessageListenerContainer"</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">constructor-arg</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">bean</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"org.springframework.kafka.core.DefaultKafkaConsumerFactory"</span>&gt;</span>
            <span class="hljs-tag">&lt;<span class="hljs-name">constructor-arg</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-name">map</span>&gt;</span>
                <span class="hljs-tag">&lt;<span class="hljs-name">entry</span> <span class="hljs-attr">key</span>=<span class="hljs-string">"bootstrap.servers"</span> <span class="hljs-attr">value</span>=<span class="hljs-string">"localhost:9092"</span> /&gt;</span>
                ...
                <span class="hljs-tag">&lt;/<span class="hljs-name">map</span>&gt;</span>
            <span class="hljs-tag">&lt;/<span class="hljs-name">constructor-arg</span>&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-name">bean</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">constructor-arg</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">constructor-arg</span>&gt;</span>
        <span class="hljs-tag">&lt;<span class="hljs-name">bean</span> <span class="hljs-attr">class</span>=<span class="hljs-string">"org.springframework.kafka.listener.config.ContainerProperties"</span>&gt;</span>
            <span class="hljs-tag">&lt;<span class="hljs-name">constructor-arg</span> <span class="hljs-attr">name</span>=<span class="hljs-string">"topics"</span> <span class="hljs-attr">value</span>=<span class="hljs-string">"foo"</span> /&gt;</span>
        <span class="hljs-tag">&lt;/<span class="hljs-name">bean</span>&gt;</span>
    <span class="hljs-tag">&lt;/<span class="hljs-name">constructor-arg</span>&gt;</span>

<span class="hljs-tag">&lt;/<span class="hljs-name">bean</span>&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="si-inbound-pollable"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-pollable"></a>6.1.5. Inbound Channel Adapter</h4>
<div class="paragraph">
<p>Introduced in version 3.0.1, the <code>KafkaMessageSource</code> provides a pollable channel adapter implementation.</p>
</div>
<div class="sect4">
<h5 id="java-configuration-3"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-3"></a>Java Configuration</h5>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@InboundChannelAdapter</span>(channel = <span class="hljs-string">"fromKafka"</span>, poller = <span class="hljs-meta">@Poller</span>(fixedDelay = <span class="hljs-string">"5000"</span>))
<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaMessageSource&lt;String, String&gt; <span class="hljs-title">source</span><span class="hljs-params">(ConsumerFactory&lt;String, String&gt; cf)</span>  </span>{
    KafkaMessageSource&lt;String, String&gt; source = <span class="hljs-keyword">new</span> KafkaMessageSource&lt;&gt;(cf, <span class="hljs-string">"myTopic"</span>);
    source.setGroupId(<span class="hljs-string">"myGroupId"</span>);
    source.setClientId(<span class="hljs-string">"myClientId"</span>);
    <span class="hljs-keyword">return</span> source;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Refer to the javadocs for available properties.</p>
</div>
<div id="max-poll-records" class="paragraph">
<p>By default, <code>max.poll.records</code> must be either explicitly set in the consumer factory, or it will be forced to 1 if the consumer factory is a <code>DefaultKafkaConsumerFactory</code>.
Starting with version 3.2, you can set the property <code>allowMultiFetch</code> to <code>true</code> to override this behavior.</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
You must poll the consumer within <code>max.poll.interval.ms</code> to avoid a rebalance.
If you set <code>allowMultiFetch</code> to <code>true</code> you must process all the retrieved records, and poll again, within <code>max.poll.interval.ms</code>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>Messages emitted by this adapter contain a header <code>kafka_remainingRecords</code> with a count of records remaining from the previous poll.</p>
</div>
</div>
<div class="sect4">
<h5 id="java-dsl-configuration-3"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-3"></a>Java DSL Configuration</h5>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">flow</span><span class="hljs-params">(ConsumerFactory&lt;String, String&gt; cf)</span>  </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows.from(Kafka.inboundChannelAdapter(cf, <span class="hljs-string">"myTopic"</span>)
                .groupId(<span class="hljs-string">"myDslGroupId"</span>), e -&gt; e.poller(Pollers.fixedDelay(<span class="hljs-number">5000</span>)))
            .handle(System.out::println)
            .get();
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="xml-configuration-3"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-3"></a>XML Configuration</h5>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">int-kafka:inbound-channel-adapter</span>
        <span class="hljs-attr">id</span>=<span class="hljs-string">"adapter1"</span>
        <span class="hljs-attr">consumer-factory</span>=<span class="hljs-string">"consumerFactory"</span>
        <span class="hljs-attr">ack-factory</span>=<span class="hljs-string">"ackFactory"</span>
        <span class="hljs-attr">topics</span>=<span class="hljs-string">"topic1"</span>
        <span class="hljs-attr">channel</span>=<span class="hljs-string">"inbound"</span>
        <span class="hljs-attr">client-id</span>=<span class="hljs-string">"client"</span>
        <span class="hljs-attr">group-id</span>=<span class="hljs-string">"group"</span>
        <span class="hljs-attr">message-converter</span>=<span class="hljs-string">"converter"</span>
        <span class="hljs-attr">payload-type</span>=<span class="hljs-string">"java.lang.String"</span>
        <span class="hljs-attr">raw-header</span>=<span class="hljs-string">"true"</span>
        <span class="hljs-attr">auto-startup</span>=<span class="hljs-string">"false"</span>
        <span class="hljs-attr">rebalance-listener</span>=<span class="hljs-string">"rebal"</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">int:poller</span> <span class="hljs-attr">fixed-delay</span>=<span class="hljs-string">"5000"</span>/&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">int-kafka:inbound-channel-adapter</span>&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="si-outbound-gateway"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound-gateway"></a>6.1.6. Outbound Gateway</h4>
<div class="paragraph">
<p>The outbound gateway is for request/reply operations.
It differs from most Spring Integration gateways in that the sending thread does not block in the gateway and the reply is processed on the reply listener container thread.
If your code invokes the gateway behind a synchronous <a href="https://docs.spring.io/spring-integration/reference/html/messaging-endpoints-chapter.html#gateway">Messaging Gateway</a>, the user thread blocks there until the reply is received (or a timeout occurs).</p>
</div>
<div class="admonitionblock important">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
The gateway does not accept requests until the reply container has been assigned its topics and partitions.
It is suggested that you add a <code>ConsumerRebalanceListener</code> to the template’s reply container properties and wait for the <code>onPartitionsAssigned</code> call before sending messages to the gateway.
</td>
</tr>
</tbody></table>
</div>
<div class="sect4">
<h5 id="java-configuration-4"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-configuration-4"></a>Java Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure a gateway with Java:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-meta">@ServiceActivator</span>(inputChannel = <span class="hljs-string">"kafkaRequests"</span>, outputChannel = <span class="hljs-string">"kafkaReplies"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaProducerMessageHandler&lt;String, String&gt; <span class="hljs-title">outGateway</span><span class="hljs-params">(
        ReplyingKafkaTemplate&lt;String, String, String&gt; kafkaTemplate)</span> </span>{
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> KafkaProducerMessageHandler&lt;&gt;(kafkaTemplate);
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Refer to the javadocs for available properties.</p>
</div>
<div class="paragraph">
<p>Notice that the same class as the <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-outbound">outbound channel adapter</a> is used, the only difference being that the Kafka template passed into the constructor is a <code>ReplyingKafkaTemplate</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template">Using <code>ReplyingKafkaTemplate</code></a> for more information.</p>
</div>
<div class="paragraph">
<p>The outbound topic, partition, key, and so on are determined in the same way as the outbound adapter.
The reply topic is determined as follows:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A message header named <code>KafkaHeaders.REPLY_TOPIC</code> (if present, it must have a <code>String</code> or <code>byte[]</code> value) is validated against the template’s reply container’s subscribed topics.</p>
</li>
<li>
<p>If the template’s <code>replyContainer</code> is subscribed to only one topic, it is used.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>You can also specify a <code>KafkaHeaders.REPLY_PARTITION</code> header to determine a specific partition to be used for replies.
Again, this is validated against the template’s reply container’s subscriptions.</p>
</div>
</div>
<div class="sect4">
<h5 id="java-dsl-configuration-4"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#java-dsl-configuration-4"></a>Java DSL Configuration</h5>
<div class="paragraph">
<p>The following example shows how to configure an outbound gateway with the Java DSL:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">outboundGateFlow</span><span class="hljs-params">(
        ReplyingKafkaTemplate&lt;String, String, String&gt; kafkaTemplate)</span> </span>{

    <span class="hljs-keyword">return</span> IntegrationFlows.from(<span class="hljs-string">"kafkaRequests"</span>)
            .handle(Kafka.outboundGateway(kafkaTemplate))
            .channel(<span class="hljs-string">"kafkaReplies"</span>)
            .get();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you can also use a configuration similar to the following bean:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">outboundGateFlow</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows.from(<span class="hljs-string">"kafkaRequests"</span>)
            .handle(Kafka.outboundGateway(producerFactory(), replyContainer())
                .configureKafkaTemplate(t -&gt; t.replyTimeout(<span class="hljs-number">30_000</span>)))
            .channel(<span class="hljs-string">"kafkaReplies"</span>)
            .get();
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="xml-configuration-4"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-4"></a>XML Configuration</h5>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">int-kafka:outbound-gateway</span>
    <span class="hljs-attr">id</span>=<span class="hljs-string">"allProps"</span>
    <span class="hljs-attr">error-message-strategy</span>=<span class="hljs-string">"ems"</span>
    <span class="hljs-attr">kafka-template</span>=<span class="hljs-string">"template"</span>
    <span class="hljs-attr">message-key-expression</span>=<span class="hljs-string">"'key'"</span>
    <span class="hljs-attr">order</span>=<span class="hljs-string">"23"</span>
    <span class="hljs-attr">partition-id-expression</span>=<span class="hljs-string">"2"</span>
    <span class="hljs-attr">reply-channel</span>=<span class="hljs-string">"replies"</span>
    <span class="hljs-attr">reply-timeout</span>=<span class="hljs-string">"43"</span>
    <span class="hljs-attr">request-channel</span>=<span class="hljs-string">"requests"</span>
    <span class="hljs-attr">requires-reply</span>=<span class="hljs-string">"false"</span>
    <span class="hljs-attr">send-success-channel</span>=<span class="hljs-string">"successes"</span>
    <span class="hljs-attr">send-failure-channel</span>=<span class="hljs-string">"failures"</span>
    <span class="hljs-attr">send-timeout-expression</span>=<span class="hljs-string">"44"</span>
    <span class="hljs-attr">sync</span>=<span class="hljs-string">"true"</span>
    <span class="hljs-attr">timestamp-expression</span>=<span class="hljs-string">"T(System).currentTimeMillis()"</span>
    <span class="hljs-attr">topic-expression</span>=<span class="hljs-string">"'topic'"</span>/&gt;</span></code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="si-inbound-gateway"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound-gateway"></a>6.1.7. Inbound Gateway</h4>
<div class="paragraph">
<p>The inbound gateway is for request/reply operations.</p>
</div>
<div class="paragraph">
<p>The following example shows how to configure an inbound gateway with Java:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaInboundGateway&lt;Integer, String, String&gt; <span class="hljs-title">inboundGateway</span><span class="hljs-params">(
        AbstractMessageListenerContainer&lt;Integer, String&gt;container,
        KafkaTemplate&lt;Integer, String&gt; replyTemplate)</span> </span>{

    KafkaInboundGateway&lt;Integer, String, String&gt; gateway =
        <span class="hljs-keyword">new</span> KafkaInboundGateway&lt;&gt;(container, replyTemplate);
    gateway.setRequestChannel(requests);
    gateway.setReplyChannel(replies);
    gateway.setReplyTimeout(<span class="hljs-number">30_000</span>);
    <span class="hljs-keyword">return</span> gateway;
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Refer to the javadocs for available properties.</p>
</div>
<div class="paragraph">
<p>The following example shows how to configure a simple upper case converter with the Java DSL:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">serverGateway</span><span class="hljs-params">(
        ConcurrentMessageListenerContainer&lt;Integer, String&gt; container,
        KafkaTemplate&lt;Integer, String&gt; replyTemplate)</span> </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows
            .from(Kafka.inboundGateway(container, template)
                .replyTimeout(<span class="hljs-number">30_000</span>))
            .&lt;String, String&gt;transform(String::toUpperCase)
            .get();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Alternatively, you could configure an upper-case converter by using code similar to the following:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">serverGateway</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows
            .from(Kafka.inboundGateway(consumerFactory(), containerProperties(),
                    producerFactory())
                .replyTimeout(<span class="hljs-number">30_000</span>))
            .&lt;String, String&gt;transform(String::toUpperCase)
            .get();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Starting with Spring for Apache Kafka version 2.2 (Spring Integration Kafka 3.1), you can also use the container factory that is used for <code>@KafkaListener</code> annotations to create <code>ConcurrentMessageListenerContainer</code> instances for other purposes.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory">Container factory</a> and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-inbound">Message-driven Channel Adapter</a> for examples.</p>
</div>
<div class="sect4">
<h5 id="xml-configuration-5"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#xml-configuration-5"></a>XML Configuration</h5>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">int-kafka:inbound-gateway</span>
        <span class="hljs-attr">id</span>=<span class="hljs-string">"gateway1"</span>
        <span class="hljs-attr">listener-container</span>=<span class="hljs-string">"container1"</span>
        <span class="hljs-attr">kafka-template</span>=<span class="hljs-string">"template"</span>
        <span class="hljs-attr">auto-startup</span>=<span class="hljs-string">"false"</span>
        <span class="hljs-attr">phase</span>=<span class="hljs-string">"100"</span>
        <span class="hljs-attr">request-timeout</span>=<span class="hljs-string">"5000"</span>
        <span class="hljs-attr">request-channel</span>=<span class="hljs-string">"nullChannel"</span>
        <span class="hljs-attr">reply-channel</span>=<span class="hljs-string">"errorChannel"</span>
        <span class="hljs-attr">reply-timeout</span>=<span class="hljs-string">"43"</span>
        <span class="hljs-attr">message-converter</span>=<span class="hljs-string">"messageConverter"</span>
        <span class="hljs-attr">payload-type</span>=<span class="hljs-string">"java.lang.String"</span>
        <span class="hljs-attr">error-message-strategy</span>=<span class="hljs-string">"ems"</span>
        <span class="hljs-attr">retry-template</span>=<span class="hljs-string">"retryTemplate"</span>
        <span class="hljs-attr">recovery-callback</span>=<span class="hljs-string">"recoveryCallback"</span>/&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>See the XML schema for a description of each property.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="message-conversion"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-conversion"></a>6.1.8. Message Conversion</h4>
<div class="paragraph">
<p>A <code>StringJsonMessageConverter</code> is provided.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a> for more information.</p>
</div>
<div class="paragraph">
<p>When using this converter with a message-driven channel adapter, you can specify the type to which you want the incoming payload to be converted.
This is achieved by setting the <code>payload-type</code> attribute (<code>payloadType</code> property) on the adapter.
The following example shows how to do so in XML configuration:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-xml hljs" data-lang="xml"><span class="hljs-tag">&lt;<span class="hljs-name">int-kafka:message-driven-channel-adapter</span>
        <span class="hljs-attr">id</span>=<span class="hljs-string">"kafkaListener"</span>
        <span class="hljs-attr">listener-container</span>=<span class="hljs-string">"container1"</span>
        <span class="hljs-attr">auto-startup</span>=<span class="hljs-string">"false"</span>
        <span class="hljs-attr">phase</span>=<span class="hljs-string">"100"</span>
        <span class="hljs-attr">send-timeout</span>=<span class="hljs-string">"5000"</span>
        <span class="hljs-attr">channel</span>=<span class="hljs-string">"nullChannel"</span>
        <span class="hljs-attr">message-converter</span>=<span class="hljs-string">"messageConverter"</span>
        <span class="hljs-attr">payload-type</span>=<span class="hljs-string">"com.example.Foo"</span>
        <span class="hljs-attr">error-channel</span>=<span class="hljs-string">"errorChannel"</span> /&gt;</span>

<span class="hljs-tag">&lt;<span class="hljs-name">bean</span> <span class="hljs-attr">id</span>=<span class="hljs-string">"messageConverter"</span>
    <span class="hljs-attr">class</span>=<span class="hljs-string">"org.springframework.kafka.support.converter.MessagingMessageConverter"</span>/&gt;</span></code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>The following example shows how to set the <code>payload-type</code> attribute (<code>payloadType</code> property) on the adapter in Java configuration:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> KafkaMessageDrivenChannelAdapter&lt;String, String&gt;
            <span class="hljs-title">adapter</span><span class="hljs-params">(KafkaMessageListenerContainer&lt;String, String&gt; container)</span> </span>{
    KafkaMessageDrivenChannelAdapter&lt;String, String&gt; kafkaMessageDrivenChannelAdapter =
            <span class="hljs-keyword">new</span> KafkaMessageDrivenChannelAdapter&lt;&gt;(container, ListenerMode.record);
    kafkaMessageDrivenChannelAdapter.setOutputChannel(received());
    kafkaMessageDrivenChannelAdapter.setMessageConverter(converter());
    kafkaMessageDrivenChannelAdapter.setPayloadType(Foo.class);
    <span class="hljs-keyword">return</span> kafkaMessageDrivenChannelAdapter;
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="si-tombstones"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#si-tombstones"></a>6.1.9. Null Payloads and Log Compaction 'Tombstone' Records</h4>
<div class="paragraph">
<p>Spring Messaging <code>Message&lt;?&gt;</code> objects cannot have <code>null</code> payloads.
When you use the Kafka endpoints, <code>null</code> payloads (also known as tombstone records) are represented by a payload of type <code>KafkaNull</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#tombstones">Null Payloads and Log Compaction of 'Tombstone' Records</a> for more information.</p>
</div>
<div class="paragraph">
<p>Starting with version 3.1 of Spring Integration Kafka, such records can now be received by Spring Integration POJO methods with a true <code>null</code> value instead.
To do so, mark the parameter with <code>@Payload(required = false)</code>.
The following example shows how to do so:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@ServiceActivator</span>(inputChannel = <span class="hljs-string">"fromSomeKafkaInboundEndpoint"</span>)
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">in</span><span class="hljs-params">(@Header(KafkaHeaders.RECEIVED_MESSAGE_KEY)</span> String key,
               @<span class="hljs-title">Payload</span><span class="hljs-params">(required = <span class="hljs-keyword">false</span>)</span> Customer customer) </span>{
    <span class="hljs-comment">// customer is null if a tombstone record</span>
    ...
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="streams-integration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-integration"></a>6.1.10. Calling a Spring Integration flow from a <code>KStream</code></h4>
<div class="paragraph">
<p>You can use a <code>MessagingTransformer</code> to invoke an integration flow from a <code>KStream</code>:</p>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-java hljs" data-lang="java"><span class="hljs-meta">@Bean</span>
<span class="hljs-keyword">public</span> KStream&lt;<span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[]&gt; kStream(StreamsBuilder kStreamBuilder,
        MessagingTransformer&lt;<span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[]&gt; transformer)  transformer) {
    KStream&lt;<span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[]&gt; stream = kStreamBuilder.stream(STREAMING_TOPIC1);
    stream.mapValues((ValueMapper&lt;<span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[]&gt;) String::toUpperCase)
            ...
            .transform(() -&gt; transformer)
            .to(streamingTopic2);

    stream.print(Printed.toSysOut());

    <span class="hljs-keyword">return</span> stream;
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-meta">@DependsOn</span>(<span class="hljs-string">"flow"</span>)
<span class="hljs-keyword">public</span> MessagingTransformer&lt;<span class="hljs-keyword">byte</span>[], <span class="hljs-keyword">byte</span>[], String&gt; transformer(
        MessagingFunction function) {

    MessagingMessageConverter converter = <span class="hljs-keyword">new</span> MessagingMessageConverter();
    converter.setHeaderMapper(<span class="hljs-keyword">new</span> SimpleKafkaHeaderMapper(<span class="hljs-string">"*"</span>));
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> MessagingTransformer&lt;&gt;(function, converter);
}

<span class="hljs-meta">@Bean</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> IntegrationFlow <span class="hljs-title">flow</span><span class="hljs-params">()</span> </span>{
    <span class="hljs-keyword">return</span> IntegrationFlows.from(MessagingFunction.class)
        ...
        .get();
}</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>When an integration flow starts with an interface, the proxy that is created has the name of the flow bean, appended with ".gateway" so this bean name can be used a a <code>@Qualifier</code> if needed.</p>
</div>
</div>
<div class="sect3">
<h4 id="whats-new-in-spring-integration-for-apache-kafka"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#whats-new-in-spring-integration-for-apache-kafka"></a>6.1.11. What’s New in Spring Integration for Apache Kafka</h4>
<div class="paragraph">
<p>See the <a href="https://projects.spring.io/spring-kafka/">Spring for Apache Kafka Project Page</a> for a matrix of compatible <code>spring-kafka</code> and <code>kafka-clients</code> versions.</p>
</div>
<div class="sect4">
<h5 id="3-2-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-2-x"></a>3.2.x</h5>
<div class="ulist">
<ul>
<li>
<p>The <code>KafkaMessageSource</code> 's <code>Consumer</code> can now be paused and resumed.</p>
</li>
<li>
<p>XML configuration for gateways and the pollable source.</p>
</li>
<li>
<p>The <code>KafkaMessageSource</code> can now be configured to fetch multiple records on each <code>poll()</code>.</p>
</li>
<li>
<p>The <code>MessagingTransformer</code> allows you to invoke a Spring Integration flow from a Kafka streams topology.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="3-1-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-1-x"></a>3.1.x</h5>
<div class="ulist">
<ul>
<li>
<p>Update to <code>spring-kafka</code> 2.2.x and <code>kafka-clients</code> 2.0.0</p>
</li>
<li>
<p>Support tombstones in EIP POJO Methods</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="3-0-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#3-0-x"></a>3.0.x</h5>
<div class="ulist">
<ul>
<li>
<p>Update to <code>spring-kafka</code> 2.1.x and <code>kafka-clients</code> 1.0.0</p>
</li>
<li>
<p>Support <code>ConsumerAwareMessageListener</code> (<code>Consumer</code> is available in a message header)</p>
</li>
<li>
<p>Update to Spring Integration 5.0 and Java 8</p>
</li>
<li>
<p>Moved Java DSL to the main project</p>
</li>
<li>
<p>Added inbound and outbound gateways (3.0.2)</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="2-3-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-3-x"></a>2.3.x</h5>
<div class="paragraph">
<p>The 2.3.x branch introduced the following changes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Update to <code>spring-kafka</code> 1.3.x, including support for transactions and header mapping provided by <code>kafka-clients</code> 0.11.0.0</p>
</li>
<li>
<p>Support for record timestamps</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="2-2-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-2-x"></a>2.2.x</h5>
<div class="paragraph">
<p>The 2.2.x branch introduced the following changes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Update to <code>spring-kafka</code> 1.2.x</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="2-1-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-1-x"></a>2.1.x</h5>
<div class="paragraph">
<p>The 2.1.x branch introduced the following changes:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Update to <code>spring-kafka</code> 1.1.x, including support of batch payloads</p>
</li>
<li>
<p>Support <code>sync</code> outbound requests in XML configuration</p>
</li>
<li>
<p>Support <code>payload-type</code> for inbound channel adapters</p>
</li>
<li>
<p>Support for enhanced error handling for the inbound channel adapter (2.1.1)</p>
</li>
<li>
<p>Support for send success and failure messages (2.1.2)</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="2-0-x"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#2-0-x"></a>2.0.x</h5>
<div class="paragraph">
<p>The 2.0.x version was the first version to be based on Spring for Apache Kafka and the Java clients.
Earlier versions used the scala clients directly.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="resources"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#resources"></a>7. Other Resources</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In addition to this reference documentation, we recommend a number of other resources that may help you learn about Spring and Apache Kafka.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://kafka.apache.org/">Apache Kafka Project Home Page</a></p>
</li>
<li>
<p><a href="https://projects.spring.io/spring-kafka/">Spring for Apache Kafka Home Page</a></p>
</li>
<li>
<p><a href="https://github.com/spring-projects/spring-kafka">Spring for Apache Kafka GitHub Repository</a></p>
</li>
<li>
<p><a href="https://github.com/spring-projects/spring-integration-kafka">Spring Integration Kafka Extension GitHub Repository</a></p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="history"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#history"></a>Appendix A: Change History</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="migration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#migration"></a>A.1. Changes between 2.1 and 2.2</h3>
<div class="sect3">
<h4 id="kafka-client-2.0"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-2.0"></a>A.1.1. Kafka Client Version</h4>
<div class="paragraph">
<p>This version requires the 2.0.0 <code>kafka-clients</code> or higher.</p>
</div>
</div>
<div class="sect3">
<h4 id="class-and-package-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-and-package-changes"></a>A.1.2. Class and Package Changes</h4>
<div class="paragraph">
<p>The <code>ContainerProperties</code> class has been moved from <code>org.springframework.kafka.listener.config</code> to <code>org.springframework.kafka.listener</code>.</p>
</div>
<div class="paragraph">
<p>The <code>AckMode</code> enum has been moved from <code>AbstractMessageListenerContainer</code> to <code>ContainerProperties</code>.</p>
</div>
<div class="paragraph">
<p>The <code>setBatchErrorHandler()</code> and <code>setErrorHandler()</code> methods have been moved from <code>ContainerProperties</code> to both <code>AbstractMessageListenerContainer</code> and <code>AbstractKafkaListenerContainerFactory</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="after-rollback-processing"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback-processing"></a>A.1.3. After Rollback Processing</h4>
<div class="paragraph">
<p>A new <code>AfterRollbackProcessor</code> strategy is provided.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback">After-rollback Processor</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="concurrentkafkalistenercontainerfactory-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#concurrentkafkalistenercontainerfactory-changes"></a>A.1.4. <code>ConcurrentKafkaListenerContainerFactory</code> Changes</h4>
<div class="paragraph">
<p>You can now use the <code>ConcurrentKafkaListenerContainerFactory</code> to create and configure any <code>ConcurrentMessageListenerContainer</code>, not only those for <code>@KafkaListener</code> annotations.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-factory">Container factory</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="listener-container-changes-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#listener-container-changes-2"></a>A.1.5. Listener Container Changes</h4>
<div class="paragraph">
<p>A new container property (<code>missingTopicsFatal</code>) has been added.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-container">Using <code>KafkaMessageListenerContainer</code></a> for more information.</p>
</div>
<div class="paragraph">
<p>A <code>ConsumerStoppedEvent</code> is now emitted when a consumer terminates.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#thread-safety">Thread Safety</a> for more information.</p>
</div>
<div class="paragraph">
<p>Batch listeners can optionally receive the complete <code>ConsumerRecords&lt;?, ?&gt;</code> object instead of a <code>List&lt;ConsumerRecord&lt;?, ?&gt;</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#batch-listeners">Batch listeners</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>DefaultAfterRollbackProcessor</code> and <code>SeekToCurrentErrorHandler</code> can now recover (skip) records that keep failing, and, by default, does so after 10 failures.
They can be configured to publish failed records to a dead-letter topic.</p>
</div>
<div class="paragraph">
<p>Starting with version 2.2.4, the consumer’s group ID can be used while selecting the dead letter topic name.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#after-rollback">After-rollback Processor</a>, <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a>, and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#dead-letters">Publishing Dead-letter Records</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>ConsumerStoppingEvent</code> has been added.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#events">Application Events</a> for more information.</p>
</div>
<div class="paragraph">
<p>The <code>SeekToCurrentErrorHandler</code> can now be configured to commit the offset of a recovered record when the container is configured with <code>AckMode.MANUAL_IMMEDIATE</code> (since 2.2.4).
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-to-current">Seek To Current Container Error Handlers</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafkalistener-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes"></a>A.1.6. @KafkaListener Changes</h4>
<div class="paragraph">
<p>You can now override the <code>concurrency</code> and <code>autoStartup</code> properties of the listener container factory by setting properties on the annotation.
You can now add configuration to determine which headers (if any) are copied to a reply message.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-annotation"><code>@KafkaListener</code> Annotation</a> for more information.</p>
</div>
<div class="paragraph">
<p>You can now use <code>@KafkaListener</code> as a meta-annotation on your own annotations.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-meta"><code>@KafkaListener</code> as a Meta Annotation</a> for more information.</p>
</div>
<div class="paragraph">
<p>It is now easier to configure a <code>Validator</code> for <code>@Payload</code> validation.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-validation"><code>@KafkaListener</code> <code>@Payload</code> Validation</a> for more information.</p>
</div>
<div class="paragraph">
<p>You can now specify kafka consumer properties directly on the annotation; these will override any properties with the same name defined in the consumer factory (since version 2.2.4).
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-properties">Annotation Properties</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="header-mapping-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#header-mapping-changes"></a>A.1.7. Header Mapping Changes</h4>
<div class="paragraph">
<p>Headers of type <code>MimeType</code> and <code>MediaType</code> are now mapped as simple strings in the <code>RecordHeader</code> value.
Previously, they were mapped as JSON and only <code>MimeType</code> was decoded.
<code>MediaType</code> could not be decoded.
They are now simple strings for interoperability.</p>
</div>
<div class="paragraph">
<p>Also, the <code>DefaultKafkaHeaderMapper</code> has a new <code>addToStringClasses</code> method, allowing the specification of types that should be mapped by using <code>toString()</code> instead of JSON.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#headers">Message Headers</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="embedded-kafka-changes"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embedded-kafka-changes"></a>A.1.8. Embedded Kafka Changes</h4>
<div class="paragraph">
<p>The <code>KafkaEmbedded</code> class and its <code>KafkaRule</code> interface have been deprecated in favor of the <code>EmbeddedKafkaBroker</code> and its JUnit 4 <code>EmbeddedKafkaRule</code> wrapper.
The <code>@EmbeddedKafka</code> annotation now populates an <code>EmbeddedKafkaBroker</code> bean instead of the deprecated <code>KafkaEmbedded</code>.
This change allows the use of <code>@EmbeddedKafka</code> in JUnit 5 tests.
The <code>@EmbeddedKafka</code> annotation now has the attribute <code>ports</code> to specify the port that populates the <code>EmbeddedKafkaBroker</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#testing">Testing Applications</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="jsonserializerdeserializer-enhancements"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#jsonserializerdeserializer-enhancements"></a>A.1.9. JsonSerializer/Deserializer Enhancements</h4>
<div class="paragraph">
<p>You can now provide type mapping information by using producer and consumer properties.</p>
</div>
<div class="paragraph">
<p>New constructors are available on the deserializer to allow overriding the type header information with the supplied target type.</p>
</div>
<div class="paragraph">
<p>The <code>JsonDeserializer</code> now removes any type information headers by default.</p>
</div>
<div class="paragraph">
<p>You can now configure the <code>JsonDeserializer</code> to ignore type information headers by using a Kafka property (since 2.2.3).</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafka-streams-changes-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-streams-changes-2"></a>A.1.10. Kafka Streams Changes</h4>
<div class="paragraph">
<p>The streams configuration bean must now be a <code>KafkaStreamsConfiguration</code> object instead of a <code>StreamsConfig</code> object.</p>
</div>
<div class="paragraph">
<p>The <code>StreamsBuilderFactoryBean</code> has been moved from package <code>…​core</code> to <code>…​config</code>.</p>
</div>
<div class="paragraph">
<p>The <code>KafkaStreamBrancher</code> has been introduced for better end-user experience when conditional branches are built on top of <code>KStream</code> instance.</p>
</div>
<div class="paragraph">
<p>See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-kafka-streams">Kafka Streams Support</a> and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#streams-config">Configuration</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="transactional-id"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactional-id"></a>A.1.11. Transactional ID</h4>
<div class="paragraph">
<p>When a transaction is started by the listener container, the <code>transactional.id</code> is now the <code>transactionIdPrefix</code> appended with <code>&lt;group.id&gt;.&lt;topic&gt;.&lt;partition&gt;</code>.
This change allows proper fencing of zombies, <a href="https://www.confluent.io/blog/transactions-apache-kafka/">as described here</a>.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="changes-between-2-0-and-2-1"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-2-0-and-2-1"></a>A.2. Changes between 2.0 and 2.1</h3>
<div class="sect3">
<h4 id="kafka-client-1.0"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client-1.0"></a>A.2.1. Kafka Client Version</h4>
<div class="paragraph">
<p>This version requires the 1.0.0 <code>kafka-clients</code> or higher.</p>
</div>
<div class="admonitionblock note">
<table>
<tbody><tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The 1.1.x client is supported with version 2.1.5, but you need to override dependencies as described in <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#deps-for-11x">[deps-for-11x]</a>.
</td>
</tr>
</tbody></table>
</div>
<div class="paragraph">
<p>The 1.1.x client is supported natively in version 2.2.</p>
</div>
</div>
<div class="sect3">
<h4 id="json-improvements"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#json-improvements"></a>A.2.2. JSON Improvements</h4>
<div class="paragraph">
<p>The <code>StringJsonMessageConverter</code> and <code>JsonSerializer</code> now add type information in <code>Headers</code>, letting the converter and <code>JsonDeserializer</code> create specific types on reception, based on the message itself rather than a fixed configured type.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#serdes">Serialization, Deserialization, and Message Conversion</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="container-stopping-error-handlers-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#container-stopping-error-handlers-2"></a>A.2.3. Container Stopping Error Handlers</h4>
<div class="paragraph">
<p>Container error handlers are now provided for both record and batch listeners that treat any exceptions thrown by the listener as fatal/
They stop the container.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-error-handling">Handling Exceptions</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="pausing-and-resuming-containers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pausing-and-resuming-containers"></a>A.2.4. Pausing and Resuming Containers</h4>
<div class="paragraph">
<p>The listener containers now have <code>pause()</code> and <code>resume()</code> methods (since version 2.1.3).
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#pause-resume">Pausing and Resuming Listener Containers</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="stateful-retry-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry-2"></a>A.2.5. Stateful Retry</h4>
<div class="paragraph">
<p>Starting with version 2.1.3, you can configure stateful retry.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#stateful-retry">Stateful Retry</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="client-id"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#client-id"></a>A.2.6. Client ID</h4>
<div class="paragraph">
<p>Starting with version 2.1.1, you can now set the <code>client.id</code> prefix on <code>@KafkaListener</code>.
Previously, to customize the client ID, you needed a separate consumer factory (and container factory) per listener.
The prefix is suffixed with <code>-n</code> to provide unique client IDs when you use concurrency.</p>
</div>
</div>
<div class="sect3">
<h4 id="logging-offset-commits"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#logging-offset-commits"></a>A.2.7. Logging Offset Commits</h4>
<div class="paragraph">
<p>By default, logging of topic offset commits is performed with the <code>DEBUG</code> logging level.
Starting with version 2.1.2, a new property in <code>ContainerProperties</code> called <code>commitLogLevel</code> lets you specify the log level for these messages.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-container">Using <code>KafkaMessageListenerContainer</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="default-kafkahandler"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#default-kafkahandler"></a>A.2.8. Default @KafkaHandler</h4>
<div class="paragraph">
<p>Starting with version 2.1.3, you can designate one of the <code>@KafkaHandler</code> annotations on a class-level <code>@KafkaListener</code> as the default.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#class-level-kafkalistener"><code>@KafkaListener</code> on a Class</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="replyingkafkatemplate-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replyingkafkatemplate-2"></a>A.2.9. ReplyingKafkaTemplate</h4>
<div class="paragraph">
<p>Starting with version 2.1.3, a subclass of <code>KafkaTemplate</code> is provided to support request/reply semantics.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#replying-template">Using <code>ReplyingKafkaTemplate</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="chainedkafkatransactionmanager"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chainedkafkatransactionmanager"></a>A.2.10. ChainedKafkaTransactionManager</h4>
<div class="paragraph">
<p>Version 2.1.3 introduced the <code>ChainedKafkaTransactionManager</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#chained-transaction-manager">Using <code>ChainedKafkaTransactionManager</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="migration-guide-from-2-0"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#migration-guide-from-2-0"></a>A.2.11. Migration Guide from 2.0</h4>
<div class="paragraph">
<p>See the <a href="https://github.com/spring-projects/spring-kafka/wiki/Spring-for-Apache-Kafka-2.0-to-2.1-Migration-Guide">2.0 to 2.1 Migration</a> guide.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="changes-between-1-3-and-2-0"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-3-and-2-0"></a>A.3. Changes Between 1.3 and 2.0</h3>
<div class="sect3">
<h4 id="spring-framework-and-java-versions"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#spring-framework-and-java-versions"></a>A.3.1. Spring Framework and Java Versions</h4>
<div class="paragraph">
<p>The Spring for Apache Kafka project now requires Spring Framework 5.0 and Java 8.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafkalistener-changes-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes-2"></a>A.3.2. <code>@KafkaListener</code> Changes</h4>
<div class="paragraph">
<p>You can now annotate <code>@KafkaListener</code> methods (and classes and <code>@KafkaHandler</code> methods) with <code>@SendTo</code>.
If the method returns a result, it is forwarded to the specified topic.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-send-to">Forwarding Listener Results using <code>@SendTo</code></a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="message-listeners-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners-2"></a>A.3.3. Message Listeners</h4>
<div class="paragraph">
<p>Message listeners can now be aware of the <code>Consumer</code> object.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#message-listeners">Message Listeners</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="using-consumerawarerebalancelistener"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#using-consumerawarerebalancelistener"></a>A.3.4. Using <code>ConsumerAwareRebalanceListener</code></h4>
<div class="paragraph">
<p>Rebalance listeners can now access the <code>Consumer</code> object during rebalance notifications.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#rebalance-listeners">Rebalancing Listeners</a> for more information.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="changes-between-1-2-and-1-3"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-2-and-1-3"></a>A.4. Changes Between 1.2 and 1.3</h3>
<div class="sect3">
<h4 id="support-for-transactions"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-transactions"></a>A.4.1. Support for Transactions</h4>
<div class="paragraph">
<p>The 0.11.0.0 client library added support for transactions.
The <code>KafkaTransactionManager</code> and other support for transactions have been added.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#transactions">Transactions</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="support-for-headers"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-headers"></a>A.4.2. Support for Headers</h4>
<div class="paragraph">
<p>The 0.11.0.0 client library added support for message headers.
These can now be mapped to and from <code>spring-messaging</code> <code>MessageHeaders</code>.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#headers">Message Headers</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="creating-topics"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#creating-topics"></a>A.4.3. Creating Topics</h4>
<div class="paragraph">
<p>The 0.11.0.0 client library provides an <code>AdminClient</code>, which you can use to create topics.
The <code>KafkaAdmin</code> uses this client to automatically add topics defined as <code>@Bean</code> instances.</p>
</div>
</div>
<div class="sect3">
<h4 id="support-for-kafka-timestamps"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#support-for-kafka-timestamps"></a>A.4.4. Support for Kafka Timestamps</h4>
<div class="paragraph">
<p><code>KafkaTemplate</code> now supports an API to add records with timestamps.
New <code>KafkaHeaders</code> have been introduced regarding <code>timestamp</code> support.
Also, new <code>KafkaConditions.timestamp()</code> and <code>KafkaMatchers.hasTimestamp()</code> testing utilities have been added.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-template">Using <code>KafkaTemplate</code></a>, <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-listener-annotation"><code>@KafkaListener</code> Annotation</a>, and <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#testing">Testing Applications</a> for more details.</p>
</div>
</div>
<div class="sect3">
<h4 id="kafkalistener-changes-3"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafkalistener-changes-3"></a>A.4.5. <code>@KafkaListener</code> Changes</h4>
<div class="paragraph">
<p>You can now configure a <code>KafkaListenerErrorHandler</code> to handle exceptions.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#annotation-error-handling">Handling Exceptions</a> for more information.</p>
</div>
<div class="paragraph">
<p>By default, the <code>@KafkaListener</code> <code>id</code> property is now used as the <code>group.id</code> property, overriding the property configured in the consumer factory (if present).
Further, you can explicitly configure the <code>groupId</code> on the annotation.
Previously, you would have needed a separate container factory (and consumer factory) to use different <code>group.id</code> values for listeners.
To restore the previous behavior of using the factory configured <code>group.id</code>, set the <code>idIsGroup</code> property on the annotation to <code>false</code>.</p>
</div>
</div>
<div class="sect3">
<h4 id="embeddedkafka-annotation"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#embeddedkafka-annotation"></a>A.4.6. <code>@EmbeddedKafka</code> Annotation</h4>
<div class="paragraph">
<p>For convenience, a test class-level <code>@EmbeddedKafka</code> annotation is provided, to register <code>KafkaEmbedded</code> as a bean.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#testing">Testing Applications</a> for more information.</p>
</div>
</div>
<div class="sect3">
<h4 id="kerberos-configuration"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos-configuration"></a>A.4.7. Kerberos Configuration</h4>
<div class="paragraph">
<p>Support for configuring Kerberos is now provided.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kerberos">Kerberos</a> for more information.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="changes-between-1-1-and-1-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-1-and-1-2"></a>A.5. Changes between 1.1 and 1.2</h3>
<div class="paragraph">
<p>This version uses the 0.10.2.x client.</p>
</div>
</div>
<div class="sect2">
<h3 id="changes-between-1-0-and-1-1"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#changes-between-1-0-and-1-1"></a>A.6. Changes between 1.0 and 1.1</h3>
<div class="sect3">
<h4 id="kafka-client"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#kafka-client"></a>A.6.1. Kafka Client</h4>
<div class="paragraph">
<p>This version uses the Apache Kafka 0.10.x.x client.</p>
</div>
</div>
<div class="sect3">
<h4 id="batch-listeners-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#batch-listeners-2"></a>A.6.2. Batch Listeners</h4>
<div class="paragraph">
<p>Listeners can be configured to receive the entire batch of messages returned by the <code>consumer.poll()</code> operation, rather than one at a time.</p>
</div>
</div>
<div class="sect3">
<h4 id="null-payloads"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#null-payloads"></a>A.6.3. Null Payloads</h4>
<div class="paragraph">
<p>Null payloads are used to “delete” keys when you use log compaction.</p>
</div>
</div>
<div class="sect3">
<h4 id="initial-offset"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#initial-offset"></a>A.6.4. Initial Offset</h4>
<div class="paragraph">
<p>When explicitly assigning partitions, you can now configure the initial offset relative to the current position for the consumer group, rather than absolute or relative to the current end.</p>
</div>
</div>
<div class="sect3">
<h4 id="seek-2"><a class="anchor" href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek-2"></a>A.6.5. Seek</h4>
<div class="paragraph">
<p>You can now seek the position of each topic or partition.
You can use this to set the initial position during initialization when group management is in use and Kafka assigns the partitions.
You can also seek when an idle container is detected or at any arbitrary point in your application’s execution.
See <a href="https://docs.spring.io/spring-kafka/docs/2.3.4.RELEASE/reference/html/#seek">Seeking to a Specific Offset</a> for more information.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Version 2.3.4.RELEASE<br>
Last updated 2019-12-04 16:47:47 UTC
</div>
</div>
<script async="" src="./Spring for Apache Kafka_files/analytics.js.download"></script><script type="text/javascript" src="./Spring for Apache Kafka_files/tocbot.min.js.download"></script>
<script type="text/javascript" src="./Spring for Apache Kafka_files/toc.js.download"></script>
<link rel="stylesheet" href="./Spring for Apache Kafka_files/atom-one-dark-reasonable.min.css">
<script src="./Spring for Apache Kafka_files/highlight.min.js.download"></script>
<script>hljs.initHighlighting()</script>
<script>if(window.parent==window){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-2728886-23','auto',{'siteSpeedSampleRate':100});ga('send','pageview');}</script>
<div id="uvpn_rate_us">            <div class="uvpn_wrap">                <div class="uvpn_logo-ext">                    <div class="uvpn_logo-wrap">                        <img src="chrome-extension://gpieacagdjdfbifodokiccinpbacemjf/img/128.png">                    </div>                </div>                <div class="uvpn_title">                    Don’t Forget to Rate Us                </div>                <div class="uvpn_desc">                    If you enjoy our product, give us 5 stars. It helps so much!                </div>                <div class="stars">                    <svg xmlns="http://www.w3.org/2000/svg" width="1235" height="1175" viewBox="0 0 1235 1175">                        <path fill="#cf6218" d="M0,449h1235l-999,726 382-1175 382,1175z"></path>                    </svg>                    <svg xmlns="http://www.w3.org/2000/svg" width="1235" height="1175" viewBox="0 0 1235 1175">                        <path fill="#cf6218" d="M0,449h1235l-999,726 382-1175 382,1175z"></path>                    </svg>                    <svg xmlns="http://www.w3.org/2000/svg" width="1235" height="1175" viewBox="0 0 1235 1175">                        <path fill="#cf6218" d="M0,449h1235l-999,726 382-1175 382,1175z"></path>                    </svg>                    <svg xmlns="http://www.w3.org/2000/svg" width="1235" height="1175" viewBox="0 0 1235 1175">                        <path fill="#cf6218" d="M0,449h1235l-999,726 382-1175 382,1175z"></path>                    </svg>                    <svg xmlns="http://www.w3.org/2000/svg" width="1235" height="1175" viewBox="0 0 1235 1175">                        <path fill="#cf6218" d="M0,449h1235l-999,726 382-1175 382,1175z"></path>                    </svg>                </div>                <a target="_blank" href="https://chrome.google.com/webstore/detail/uvpn-free-and-unlimited-v/gpieacagdjdfbifodokiccinpbacemjf/reviews" id="rate_btn_rateus" class="uvpn_rate-btn uvpn_btn">                    Rate Us                </a>                <div id="close_btn_rateus" class="uvpn_later-btn uvpn_btn">                    Not Now                </div>            </div>        </div></body></html>